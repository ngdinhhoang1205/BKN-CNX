{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime as dt\n",
    "from datetime import time as t\n",
    "import numpy as np\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source\n",
    "## Hoang\n",
    "eps_path = r\"C:\\Users\\dinhhoang.nguyen\\OneDrive - Concentrix Corporation\\WFM-internal\\Data\\EPS Tableau\\EPS Query\"\n",
    "cpi_path = r\"C:\\Users\\dinhhoang.nguyen\\OneDrive - Concentrix Corporation\\WFM-internal\\Data\\Ticket\\CPI Query\"\n",
    "aht_path = r\"C:\\Users\\dinhhoang.nguyen\\OneDrive - Concentrix Corporation\\WFM-internal\\Data\\AHT\\AHT query\"\n",
    "csat_path = r\"C:\\Users\\dinhhoang.nguyen\\OneDrive - Concentrix Corporation\\WFM-internal\\Data\\CSAT RAW\\CSAT Query\"\n",
    "cuic_path = r\"C:\\Users\\dinhhoang.nguyen\\OneDrive - Concentrix Corporation\\WFM-internal\\Data\\CUIC\\CUIC Query\"\n",
    "exception_path = r\"C:\\Users\\dinhhoang.nguyen\\OneDrive - Concentrix Corporation\\WFM-internal\\Data\\Exception\"\n",
    "extension_path = r\"C:\\Users\\dinhhoang.nguyen\\OneDrive - Concentrix Corporation\\WFM-internal\\Data\\Extension\"\n",
    "iex_path = r\"C:\\Users\\dinhhoang.nguyen\\OneDrive - Concentrix Corporation\\WFM-internal\\Data\\IEX\"\n",
    "label_path = r\"C:\\Users\\dinhhoang.nguyen\\OneDrive - Concentrix Corporation\\WFM-internal\\Data\\Labels\"\n",
    "## Tram\n",
    "ioshrinkage_path = r\"C:\\Users\\dinhhoang.nguyen\\OneDrive - Concentrix Corporation\\WFM-internal\\Data\\IO Shrinkage\"\n",
    "ot_path = r\"C:\\Users\\dinhhoang.nguyen\\OneDrive - Concentrix Corporation\\WFM-internal\\Data\\OT\\OT Query\"\n",
    "psat_path = r\"C:\\Users\\dinhhoang.nguyen\\OneDrive - Concentrix Corporation\\WFM-internal\\Data\\PSAT RAW\\PSAT Query\"\n",
    "quality_path = r\"C:\\Users\\dinhhoang.nguyen\\OneDrive - Concentrix Corporation\\WFM-internal\\Data\\Quality.v2\\Quality query\"\n",
    "ramco_path = r\"C:\\Users\\dinhhoang.nguyen\\OneDrive - Concentrix Corporation\\WFM-internal\\Data\\Ramco\\Ramco Query\"\n",
    "ramcoot_path = r\"C:\\Users\\dinhhoang.nguyen\\OneDrive - Concentrix Corporation\\WFM-internal\\Data\\Ramco OT\\Ramco OT Query\"\n",
    "requirement_path = r\"C:\\Users\\dinhhoang.nguyen\\OneDrive - Concentrix Corporation\\WFM-internal\\Data\\Requirement\"\n",
    "## Thanh\n",
    "schedule_path = r\"C:\\Users\\dinhhoang.nguyen\\OneDrive - Concentrix Corporation\\WFM-internal\\Data\\Schedule 2\\Schedule Query\"\n",
    "tl_path = r\"C:\\Users\\dinhhoang.nguyen\\OneDrive - Concentrix Corporation\\WFM-internal\\Data\\TL\"\n",
    "training_path = r\"C:\\Users\\dinhhoang.nguyen\\OneDrive - Concentrix Corporation\\WFM-internal\\Data\\Training\"\n",
    "masterroster_path = r\"C:\\Users\\dinhhoang.nguyen\\OneDrive - Concentrix Corporation\\WFM-internal\\Data\\User\"\n",
    "workplan_path = r\"C:\\Users\\dinhhoang.nguyen\\OneDrive - Concentrix Corporation\\WFM-internal\\Data\\Workplan\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FUNCTION TO IMPORT FOLDERS\n",
    "def import_csv(path):\n",
    "    raw = []\n",
    "    for file in os.listdir(path):\n",
    "        if file.endswith(\".csv\"):\n",
    "            file_path = os.path.join(path, file)\n",
    "            file_data = pd.read_csv(file_path)\n",
    "            file_data[\"filename\"] = file\n",
    "            raw.append(file_data)\n",
    "            final_raw = pd.concat(raw, ignore_index=True)\n",
    "    return final_raw\n",
    "    \n",
    "def import_xlsx(path, sheet_name):\n",
    "    raw = []\n",
    "    for file in os.listdir(path):\n",
    "        if file.endswith(\".xlsx\"):\n",
    "            file_path = os.path.join(path, file)\n",
    "            file_data = pd.read_excel(file_path, engine=\"openpyxl\", sheet_name = sheet_name)\n",
    "            file_data[\"filename\"] = file\n",
    "            raw.append(file_data)\n",
    "            final_raw = pd.concat(raw, ignore_index=True)\n",
    "    return final_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT MASTER ROSTER\n",
    "masterroster = pd.read_excel(r\"C:\\Users\\dinhhoang.nguyen\\OneDrive - Concentrix Corporation\\WFM-internal\\Data\\User\\CNX Global Master Roster.xlsx\", sheet_name=\"Sheet1\")\n",
    "masterroster['Employee_ID'] = masterroster['Employee_ID'].astype(\"Int64\")\n",
    "\n",
    "masterroster.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT EPS\n",
    "eps = import_csv(path = eps_path)\n",
    "eps = eps.drop(columns=['Index', 'filename', 'Date'])\n",
    "eps['Session login VN'] = pd.to_datetime(eps['Session Login'], format ='mixed') + pd.Timedelta(hours=5)\n",
    "eps['Session logout VN'] = pd.to_datetime(eps['Session Logout'], format ='mixed') + pd.Timedelta(hours=5)\n",
    "eps['Session login date'] = pd.to_datetime(eps['Session login VN']).dt.date\n",
    "eps['Session login time'] = pd.to_datetime(eps['Session login VN']).dt.time\n",
    "eps['Session logout date'] = pd.to_datetime(eps['Session logout VN']).dt.date\n",
    "eps['Session logout time'] = pd.to_datetime(eps['Session logout VN']).dt.time\n",
    "eps = eps.drop(columns=['Session login VN', 'Session logout VN', 'Username', 'manager_username', 'sitecode', 'Session Time'])\n",
    "eps.info()\n",
    "eps.to_csv(r\"C:\\Users\\dinhhoang.nguyen\\OneDrive - Concentrix Corporation\\WFM-internal\\DB\\filecsv\\eps_test.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORT CPI\n",
    "cpi = import_csv(path = cpi_path)\n",
    "cpi = cpi.drop(columns=['Region Partner', 'Sitecode', 'Mp Csm Name', 'Mp Team Name'])\n",
    "cpi['Date'] = cpi['filename'].replace(\".csv\", \"\", regex=True)\n",
    "cpi['Date'] = pd.to_datetime(cpi['Date'], format = \"mixed\")\n",
    "\n",
    "\n",
    "masterroster_cpi = masterroster[['Employee_ID', 'TED Name']]\n",
    "cpi = pd.merge(cpi, masterroster_cpi, left_on=\"Staff Name\", right_on=\"TED Name\", how=\"left\")\n",
    "cpi = cpi.drop(columns=['filename', 'TED Name'])\n",
    "\n",
    "cpi.info()\n",
    "print(cpi)\n",
    "cpi.to_csv(r\"C:\\Users\\dinhhoang.nguyen\\OneDrive - Concentrix Corporation\\WFM-internal\\DB\\filecsv\\cpi_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORT AHT\n",
    "aht = import_csv(path = aht_path)\n",
    "aht = aht.drop(columns=['filename'])\n",
    "masterroster_aht = masterroster[['Employee_ID', 'TED Name']]\n",
    "aht = pd.merge(aht, masterroster_aht, left_on='Staff', right_on ='TED Name', how='left')\n",
    "aht = aht.drop(columns=['TED Name'])\n",
    "aht['Date'] = pd.to_datetime(aht['Date'], format='mixed')\n",
    "\n",
    "aht.info()\n",
    "\n",
    "print(aht)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORT CSAT\n",
    "csat = import_csv(path = csat_path)\n",
    "masterroster_csat = masterroster[['Employee_ID', 'TED Name']]\n",
    "\n",
    "\n",
    "csat['Date '] = pd.to_datetime(csat['Date '], format='%m/%d/%Y')\n",
    "csat = pd.merge(csat, masterroster_csat, left_on='Staff', right_on ='TED Name', how='left')\n",
    "\n",
    "csat = csat.drop(columns=['Sort by Dimension', 'Has Comment', '\"Comment\"', 'Reservation Link', 'View comment', 'Sort by Dimension (copy)', 'filename', 'TED Name', 'Max. Sort by Dimension'])\n",
    "print(csat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Emp ID                   Name        Date      Shift           LOB  \\\n",
      "0      102003080           Doan Ai Khue  2023-07-31  1400-2300  Senior VICSP   \n",
      "1      102003080           Doan Ai Khue  2023-08-01        OFF  Senior VICSP   \n",
      "2      102003080           Doan Ai Khue  2023-08-02  1400-2300  Senior VICSP   \n",
      "3      102003080           Doan Ai Khue  2023-08-03  1400-2300  Senior VICSP   \n",
      "4      102003080           Doan Ai Khue  2023-08-04  1400-2300  Senior VICSP   \n",
      "...          ...                    ...         ...        ...           ...   \n",
      "29438  102186582  Nguyen Khanh Dinh Van  2023-09-27        OFF         VICSP   \n",
      "29439  102186582  Nguyen Khanh Dinh Van  2023-09-28  0900-1800         VICSP   \n",
      "29440  102186582  Nguyen Khanh Dinh Van  2023-09-29  0900-1800         VICSP   \n",
      "29441  102186582  Nguyen Khanh Dinh Van  2023-09-30  0900-1800         VICSP   \n",
      "29442  102186582  Nguyen Khanh Dinh Van  2023-10-01  0900-1800         VICSP   \n",
      "\n",
      "      Shift_type  \n",
      "0             DS  \n",
      "1            OFF  \n",
      "2             DS  \n",
      "3             DS  \n",
      "4             DS  \n",
      "...          ...  \n",
      "29438        OFF  \n",
      "29439         DS  \n",
      "29440         DS  \n",
      "29441         DS  \n",
      "29442         DS  \n",
      "\n",
      "[29443 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# IMPORT SCHEDULE\n",
    "schedule = import_xlsx(path = schedule_path,sheet_name='Sheet1')\n",
    "schedule['Attribute'] = pd.to_datetime(schedule['Attribute'],format='mixed').dt.date\n",
    "schedule=schedule.iloc[:,0:8]\n",
    "condition=(schedule['Value']=='OFF')|(schedule['Value']=='AL')|(schedule['Value']=='CO')|(schedule['Value']=='UPL')|(schedule['Value']=='Training')\n",
    "schedule['Shift'] = np.where(condition, 'OFF', schedule['NS Check'])\n",
    "schedule=schedule[['Emp ID','Name','Attribute','Value','LOB','Shift']]\n",
    "schedule=schedule.rename(columns={'Attribute':'Date','Value':'Shift','Shift':'Shift_type'})\n",
    "\n",
    "print(schedule)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORT CUIC\n",
    "cuic = import_xlsx(path = cuic_path,sheet_name=\"Khoa Interval Attendance Check-\")\n",
    "cuic['Date'] = pd.to_datetime(cuic['Interval'], format = \"mixed\").dt.date\n",
    "cuic['Time'] = pd.to_datetime(cuic['Interval'], format = \"mixed\").dt.time\n",
    "cuic = pd.merge(cuic, masterroster, left_on='LoginName', right_on ='Booking Login ID', how='left')\n",
    "cuic=cuic.iloc[:,0:9]\n",
    "cuic = pd.merge(cuic, schedule, left_on=['Employee_ID','Date'], right_on =['Emp ID','Date'], how='left')\n",
    "cuic=cuic[['FullName','LoginName','Interval','AgentAvailTime','AgentLoggedOnTime','Date','Time','Employee_ID','Shift_type','Shift']]\n",
    "cuic['Date-1']=pd.to_datetime(cuic['Date'], format ='mixed') - pd.Timedelta(1,\"d\")\n",
    "cuic['Date-1']=pd.to_datetime(cuic['Date-1'], format ='mixed').dt.date\n",
    "cuic = pd.merge(cuic, schedule, left_on=['Employee_ID','Date-1'], right_on =['Emp ID','Date'], how='left')\n",
    "cuic=cuic[['FullName','LoginName','Interval','AgentAvailTime','AgentLoggedOnTime','Date_x','Time','Employee_ID','Shift_type_x','Shift_x','Date-1','Shift_type_y','Shift_y']]\n",
    "mytime=t(12,0,0)\n",
    "condition=(cuic['Shift_type_x']!='DS')&(cuic['Shift_type_y']=='NS')&(cuic['Time']<mytime)\n",
    "cuic['Session Date'] = np.where(condition, cuic['Date-1'], cuic['Date_x'])\n",
    "cuic=cuic[['FullName','LoginName','Interval','AgentAvailTime','AgentLoggedOnTime','Date_x','Employee_ID','Shift_type_x','Session Date']]\n",
    "cuic=cuic.rename(columns={'Date_x':'Date','Shift_type_x':'Shift_type'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXCEPTION\n",
    "exceptional_hrs = import_xlsx(path= exception_path, sheet_name=\"Sheet1\")\n",
    "exceptional_hrs = exceptional_hrs.rename(columns={'Date \\n(MM/DD/YYYY)':'Date'})\n",
    "exceptional_hrs = exceptional_hrs.drop(columns=['filename'])\n",
    "\n",
    "exceptional_hrs.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORT EXTENSION\n",
    "extension = import_xlsx(path= extension_path, sheet_name=\"Sheet1\")\n",
    "extension = extension[['Emp ID', 'Extension Number']]\n",
    "extension['Extension Number'] = extension['Extension Number'].astype(\"Int64\")\n",
    "print(extension)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORT IEX ID\n",
    "iex = import_xlsx(path = iex_path, sheet_name=\"Sheet1\")\n",
    "iex = iex[['ID Agent', 'Personal ID']]\n",
    "iex = iex.rename(columns={'Personal ID': 'EID'})\n",
    "print(iex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT TL\n",
    "tl = pd.read_excel(os.path.join(tl_path, \"TL List.xlsx\"),sheet_name='Sheet1')\n",
    "tl=tl.iloc[:,0:6]\n",
    "tl=tl.rename(columns={'Supervisor (no need fill)': 'Supervisor'})\n",
    "tl=tl.drop(columns=['Wave', 'Name', 'LOB', 'Full name (VN)'])\n",
    "print(tl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT TRAINING\n",
    "training = import_xlsx(path = training_path,sheet_name='Sheet1')\n",
    "training['Date'] = pd.to_datetime(training['Date'],format='mixed').dt.date\n",
    "training['EID'] = training['EID'].astype(\"int64\")\n",
    "training=training.iloc[:,1:]\n",
    "\n",
    "print(training)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT IOSHRINKAGE\n",
    "ioshrinkage = import_xlsx(path = ioshrinkage_path, sheet_name='Sheet1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT OT\n",
    "\n",
    "ot = import_xlsx(path = ot_path, sheet_name='Sheet2')\n",
    "ot = ot.drop(columns=['Wave', 'Name', 'Value', 'LOB', 'filename'])\n",
    "ot['Date'] = pd.to_datetime(ot['Date'], format=\"mixed\")\n",
    "ot['Date'] = ot['Date'].dt.date\n",
    "\n",
    "\n",
    "display(ot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT PSAT\n",
    "psat = import_csv(path = psat_path)\n",
    "psat['Date'] = pd.to_datetime(psat['Date'],format='mixed').dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT QUALITY\n",
    "quality_raw = import_xlsx(path = quality_path,sheet_name='Sheet1')\n",
    "quality_raw['eval_date'] = pd.to_datetime(quality_raw['eval_date'],format='mixed').dt.date\n",
    "quality=quality_raw.iloc[:,0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT RAMCO\n",
    "ramco = import_csv(path = ramco_path)\n",
    "ramco['Attribute'] = pd.to_datetime(ramco['Attribute'],format='mixed').dt.date\n",
    "ramco=ramco.rename(columns={'Attribute':'Date'})\n",
    "ramco['EID']=ramco['EID'].astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT RAMCOOT\n",
    "ramcoot = import_xlsx(path = ramcoot_path,sheet_name='Sheet1')\n",
    "ramcoot['Attribute'] = pd.to_datetime(ramcoot['Attribute'],format='mixed').dt.date\n",
    "ramcoot=ramcoot.rename(columns={'Attribute':'Date'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT REQUIREMENT\n",
    "requirement = import_xlsx(path = requirement_path,sheet_name='Sheet1')\n",
    "requirement['Date'] = pd.to_datetime(requirement['Date'],format='mixed').dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT WORKPLAN\n",
    "workplan_raw = import_xlsx(path = workplan_path,sheet_name='Sheet1')\n",
    "workplan_raw['Date'] = pd.to_datetime(workplan_raw['Date'],format='mixed').dt.date\n",
    "workplan_merge_iex = pd.merge(workplan_raw,iex, left_on='Agent ID', right_on ='ID Agent', how='left')\n",
    "workplan_merge_iex['EID'] = workplan_merge_iex['EID'].astype(\"Int64\")\n",
    "workplan_merge_iex=workplan_merge_iex.drop(columns=['filename', 'ID Agent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Attendance Code                Description     Type  Schedule  Actual  \\\n",
      "0               AB                     Absent   Absent         9       0   \n",
      "1               CO           Compensatory Off    Leave         0       0   \n",
      "2               HO                    Holiday      Off         0       0   \n",
      "3               PH         Present on Holiday  Present         9       9   \n",
      "4              LWP          Leave Without Pay   Absent         9       0   \n",
      "5             HLWP     Half Leave Without Pay   Absent         9       0   \n",
      "6              MTL            Maternity leave      Off         0       0   \n",
      "7               AL               Annual leave    Leave         0       0   \n",
      "8              HAL  Half Planned Annual Leave    Leave         4       4   \n",
      "9               PR                    Present  Present         9       9   \n",
      "10              SL                 Sick Leave   Absent         9       0   \n",
      "11             HSL            Half Sick Leave   Absent         4       4   \n",
      "12             SPL         Special Paid Leave    Leave         0       0   \n",
      "13              WO                 Weekly Off      Off         0       0   \n",
      "14              PO      Present on Weekly Off       OT         9       9   \n",
      "15              NM                 Not Marked   Absent         9       0   \n",
      "16       0700-1600                        NaN      NaN         9       0   \n",
      "17       1100-2000                        NaN      NaN         9       0   \n",
      "18       1300-2200                        NaN      NaN         9       0   \n",
      "19       2000-0500                        NaN      NaN         9       0   \n",
      "20       2100-0600                        NaN      NaN         9       0   \n",
      "21       2200-0700                        NaN      NaN         9       0   \n",
      "22       0600-1500                        NaN      NaN         9       0   \n",
      "23       0900-1800                        NaN      NaN         9       0   \n",
      "24       1000-1900                        NaN      NaN         9       0   \n",
      "25             UPL            Unplanned Leave      NaN         9       0   \n",
      "26             OFF                        NaN      NaN         0       0   \n",
      "27       0900-1800                        NaN      NaN         9       0   \n",
      "28       1400-2300                        NaN      NaN         9       0   \n",
      "29        Training                        NaN      NaN         0       0   \n",
      "30       0400-1300                        NaN      NaN         9       0   \n",
      "\n",
      "    Planned leaves  Actual leaves    filename  \n",
      "0                0              0  Labels.csv  \n",
      "1                0              0  Labels.csv  \n",
      "2                0              0  Labels.csv  \n",
      "3                0              0  Labels.csv  \n",
      "4                0              0  Labels.csv  \n",
      "5                0              0  Labels.csv  \n",
      "6                0              0  Labels.csv  \n",
      "7                9              9  Labels.csv  \n",
      "8                4              4  Labels.csv  \n",
      "9                0              0  Labels.csv  \n",
      "10               0              0  Labels.csv  \n",
      "11               0              0  Labels.csv  \n",
      "12               9              9  Labels.csv  \n",
      "13               0              0  Labels.csv  \n",
      "14               0              0  Labels.csv  \n",
      "15               0              0  Labels.csv  \n",
      "16               0              0  Labels.csv  \n",
      "17               0              0  Labels.csv  \n",
      "18               0              0  Labels.csv  \n",
      "19               0              0  Labels.csv  \n",
      "20               0              0  Labels.csv  \n",
      "21               0              0  Labels.csv  \n",
      "22               0              0  Labels.csv  \n",
      "23               0              0  Labels.csv  \n",
      "24               0              0  Labels.csv  \n",
      "25               0              0  Labels.csv  \n",
      "26               0              0  Labels.csv  \n",
      "27               0              0  Labels.csv  \n",
      "28               0              0  Labels.csv  \n",
      "29               0              0  Labels.csv  \n",
      "30               0              0  Labels.csv  \n"
     ]
    }
   ],
   "source": [
    "#IMPORT LABELS\n",
    "labels = import_csv(label_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BOOKING ATTENDANCE\n",
    "bkn_att = schedule.drop(columns=['Shift_type'])\n",
    "bkn_att_ramco = ramco[['EID', 'Date', 'Value']]\n",
    "bkn_att = pd.merge(bkn_att, tl, on='Emp ID', how='left')\n",
    "bkn_att = pd.merge(bkn_att, bkn_att_ramco, left_on =['Emp ID', 'Date'], right_on=['EID', 'Date'], how='left')\n",
    "bkn_att = bkn_att.drop(columns=['EID'])\n",
    "bkn_att = bkn_att.rename(columns={'Value': 'Ramco'})\n",
    "#get cuic\n",
    "bkn_att_cuic = cuic[['Employee_ID', 'Session Date','AgentLoggedOnTime']].groupby(['Employee_ID', 'Session Date'], as_index=False).sum()\n",
    "bkn_att = pd.merge(bkn_att, bkn_att_cuic, left_on=['Emp ID', 'Date'], right_on=['Employee_ID', 'Session Date'], how='left')\n",
    "bkn_att = bkn_att.rename(columns={'AgentLoggedOnTime': 'CUIC Actual hrs'})\n",
    "bkn_att['CUIC Actual hrs'] = bkn_att['CUIC Actual hrs']*24\n",
    "#remove Employee_ID no CUIC data\n",
    "bkn_att = bkn_att.drop(columns=['Employee_ID', 'Session Date'])\n",
    "bkn_att = pd.merge(bkn_att, labels, left_on=\"Shift\", right_on=\"Attendance Code\", how=\"left\")\n",
    "\n",
    "#sum OT by agent&ID\n",
    "bkn_att = pd.merge(bkn_att, ot, on=['Emp ID', 'Date'], how=\"left\")\n",
    "bkn_att['OT'] = bkn_att['OT'].fillna(0)\n",
    "bkn_att['CUIC Actual hrs'] = bkn_att['CUIC Actual hrs'].fillna(0)\n",
    "bkn_att['Scheduled hrs'] = bkn_att['OT'] + bkn_att['Schedule']\n",
    "bkn_att = bkn_att.rename(columns={'Planned leaves': 'Planned Leave', 'Actual leaves': 'Actual Leave'})\n",
    "bkn_att['Total scheduled'] = bkn_att['Scheduled hrs'] + bkn_att['Planned Leave']\n",
    "\n",
    "#Add Attendance\n",
    "\n",
    "def attendance_func(x):\n",
    "    if x['Shift'] == 'OFF':\n",
    "        if x['Ramco'] =='PO':\n",
    "            result1 = x['CUIC Actual hrs']\n",
    "        else:\n",
    "            result1 = 0\n",
    "    else:\n",
    "        result1 = x['CUIC Actual hrs']\n",
    "\n",
    "    if result1 > x['Scheduled hrs']:\n",
    "        return x['Scheduled hrs']\n",
    "    else:\n",
    "        return result1\n",
    "    \n",
    "bkn_att['Attendance'] = bkn_att.apply(attendance_func, axis=1)\n",
    "\n",
    "#Drop columns\n",
    "bkn_att = bkn_att.drop(columns=['Description', 'Type', 'filename'])\n",
    "bkn_att['Date'] = pd.to_datetime(bkn_att['Date'], format ='mixed').dt.strftime('%Y-%m-%d')\n",
    "test_cuic = bkn_att.loc[(bkn_att['Shift'] =='OFF') & (bkn_att['Ramco'] =='PO')]\n",
    "display(test_cuic)\n",
    "bkn_att.to_csv(r'C:\\Users\\dinhhoang.nguyen\\OneDrive - Concentrix Corporation\\WFM-internal\\Calculators\\Joey Nguyen\\py\\booking_attendance.csv', index=False)\n",
    "bkn_att.to_json(r'C:\\Users\\dinhhoang.nguyen\\OneDrive - Concentrix Corporation\\WFM-internal\\DB\\filejson\\booking_attendance.json', orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dinhhoang.nguyen\\AppData\\Local\\Temp\\VSCodePortable-x64Temp\\ipykernel_17344\\736108837.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  aht_lob['Date'] = pd.to_datetime(aht_lob['Date'], format ='mixed')\n"
     ]
    }
   ],
   "source": [
    "# 1. AHT\n",
    "ahtrp = aht.drop(columns=['Start Time', 'End Time', '\"Handling Time\"', 'First Email Id'])\n",
    "\n",
    "## add Eliminate Phone\n",
    "def eliminate_phone(x):\n",
    "    if x['Item Channel'] =='Phone' and x['Topic'] =='Unknown':\n",
    "        return \"Notphone\"\n",
    "    else:\n",
    "        return x['Item Channel']\n",
    "ahtrp['Eliminate Phone'] = ahtrp.apply(eliminate_phone, axis=1)\n",
    "\n",
    "aht_mr = masterroster[['Employee_ID', 'PST_Start_Date', 'CUIC Name', 'Full name', 'Role', 'TED Name', 'Wave #']]\n",
    "\n",
    "ahtrp = pd.merge(ahtrp, aht_mr, left_on='Staff', right_on='TED Name', how='left')\n",
    "\n",
    "def TN(x):\n",
    "    if x['Date'] - x['PST_Start_Date'] >= pd.Timedelta(days=90):\n",
    "        return \"TN\"\n",
    "    else:\n",
    "        return \"NH\"\n",
    "    \n",
    "ahtrp['Tenure'] = ahtrp.apply(TN, axis=1)\n",
    "ahtrp = pd.merge(ahtrp, tl, left_on ='Employee_ID_x', right_on = 'Emp ID', how='left')\n",
    "aht_lob = schedule[['Emp ID', 'Date', 'LOB']]\n",
    "aht_lob['Date'] = pd.to_datetime(aht_lob['Date'], format ='mixed')\n",
    "ahtrp = pd.merge(ahtrp, aht_lob, left_on = ['Employee_ID_x', 'Date'], right_on=['Emp ID', 'Date'], how='left')\n",
    "# 2. Add ID, full name, role, Ted name, Wave, Supervisor\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
