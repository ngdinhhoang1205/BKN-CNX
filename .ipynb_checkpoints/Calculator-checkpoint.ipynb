{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime as dt\n",
    "from datetime import time as t\n",
    "import numpy as np\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source\n",
    "identification = r'dinhhoang.nguyen.CONCENTRIX'\n",
    "## Hoang\n",
    "eps_path = r\"C:\\Users\\dinhhoang.nguyen.CONCENTRIX\\OneDrive - Concentrix Corporation\\WFM-internal\\Data\\EPS Tableau\\EPS Query\"\n",
    "cpi_path = r\"C:\\Users\\dinhhoang.nguyen.CONCENTRIX\\OneDrive - Concentrix Corporation\\WFM-internal\\Data\\Ticket\\CPI Query\"\n",
    "aht_path = r\"C:\\Users\\dinhhoang.nguyen.CONCENTRIX\\OneDrive - Concentrix Corporation\\WFM-internal\\Data\\AHT\\AHT query\"\n",
    "csat_path = r\"C:\\Users\\dinhhoang.nguyen.CONCENTRIX\\OneDrive - Concentrix Corporation\\WFM-internal\\Data\\CSAT RAW\\CSAT Query\"\n",
    "cuic_path = r\"C:\\Users\\dinhhoang.nguyen.CONCENTRIX\\OneDrive - Concentrix Corporation\\WFM-internal\\Data\\CUIC\\CUIC Query\"\n",
    "exception_path = r\"C:\\Users\\dinhhoang.nguyen.CONCENTRIX\\OneDrive - Concentrix Corporation\\WFM-internal\\Data\\Exception\"\n",
    "extension_path = r\"C:\\Users\\dinhhoang.nguyen.CONCENTRIX\\OneDrive - Concentrix Corporation\\WFM-internal\\Data\\Extension\"\n",
    "iex_path = r\"C:\\Users\\dinhhoang.nguyen.CONCENTRIX\\OneDrive - Concentrix Corporation\\WFM-internal\\Data\\IEX\"\n",
    "label_path = r\"C:\\Users\\dinhhoang.nguyen.CONCENTRIX\\OneDrive - Concentrix Corporation\\WFM-internal\\Data\\Labels\"\n",
    "## Tram\n",
    "ioshrinkage_path = r\"C:\\Users\\dinhhoang.nguyen.CONCENTRIX\\OneDrive - Concentrix Corporation\\WFM-internal\\Data\\IO Shrinkage\"\n",
    "ot_path = r\"C:\\Users\\dinhhoang.nguyen.CONCENTRIX\\OneDrive - Concentrix Corporation\\WFM-internal\\Data\\OT\\OT Query\"\n",
    "psat_path = r\"C:\\Users\\dinhhoang.nguyen.CONCENTRIX\\OneDrive - Concentrix Corporation\\WFM-internal\\Data\\PSAT RAW\\PSAT Query\"\n",
    "quality_path = r\"C:\\Users\\dinhhoang.nguyen.CONCENTRIX\\OneDrive - Concentrix Corporation\\WFM-internal\\Data\\Quality.v2\\Quality query\"\n",
    "ramco_path = r\"C:\\Users\\dinhhoang.nguyen.CONCENTRIX\\OneDrive - Concentrix Corporation\\WFM-internal\\Data\\Ramco\\Ramco Query\"\n",
    "ramcoot_path = r\"C:\\Users\\dinhhoang.nguyen.CONCENTRIX\\OneDrive - Concentrix Corporation\\WFM-internal\\Data\\Ramco OT\\Ramco OT Query\"\n",
    "requirement_path = r\"C:\\Users\\dinhhoang.nguyen.CONCENTRIX\\OneDrive - Concentrix Corporation\\WFM-internal\\Data\\Requirement\"\n",
    "## Thanh\n",
    "schedule_path = r\"C:\\Users\\dinhhoang.nguyen.CONCENTRIX\\OneDrive - Concentrix Corporation\\WFM-internal\\Data\\Schedule 2\\Schedule Query\"\n",
    "tl_path = r\"C:\\Users\\dinhhoang.nguyen.CONCENTRIX\\OneDrive - Concentrix Corporation\\WFM-internal\\Data\\TL\"\n",
    "training_path = r\"C:\\Users\\dinhhoang.nguyen.CONCENTRIX\\OneDrive - Concentrix Corporation\\WFM-internal\\Data\\Training\"\n",
    "masterroster_path = r\"C:\\Users\\dinhhoang.nguyen.CONCENTRIX\\OneDrive - Concentrix Corporation\\WFM-internal\\Data\\User\"\n",
    "workplan_path = r\"C:\\Users\\dinhhoang.nguyen.CONCENTRIX\\OneDrive - Concentrix Corporation\\WFM-internal\\Data\\Workplan\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FUNCTION TO IMPORT FOLDERS\n",
    "def import_csv(path):\n",
    "    raw = []\n",
    "    for file in os.listdir(path):\n",
    "        if file.endswith(\".csv\"):\n",
    "            file_path = os.path.join(path, file)\n",
    "            file_data = pd.read_csv(file_path)\n",
    "            file_data[\"filename\"] = file\n",
    "            raw.append(file_data)\n",
    "            final_raw = pd.concat(raw, ignore_index=True)\n",
    "    return final_raw\n",
    "    \n",
    "def import_xlsx(path, sheet_name):\n",
    "    raw = []\n",
    "    for file in os.listdir(path):\n",
    "        if file.endswith(\".xlsx\"):\n",
    "            file_path = os.path.join(path, file)\n",
    "            file_data = pd.read_excel(file_path, engine=\"openpyxl\", sheet_name = sheet_name)\n",
    "            file_data[\"filename\"] = file\n",
    "            raw.append(file_data)\n",
    "            final_raw = pd.concat(raw, ignore_index=True)\n",
    "    return final_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT MASTER ROSTER\n",
    "masterroster = pd.read_excel(r\"C:\\Users\\dinhhoang.nguyen\\OneDrive - Concentrix Corporation\\WFM-internal\\Data\\User\\CNX Global Master Roster.xlsx\", sheet_name=\"Sheet1\")\n",
    "masterroster['Employee_ID'] = masterroster['Employee_ID'].astype(\"Int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 179514 entries, 0 to 179513\n",
      "Data columns (total 9 columns):\n",
      " #   Column               Non-Null Count   Dtype \n",
      "---  ------               --------------   ----- \n",
      " 0   EID                  179514 non-null  int64 \n",
      " 1   Session Login        179514 non-null  object\n",
      " 2   Session Logout       179514 non-null  object\n",
      " 3   BPE Code             179514 non-null  object\n",
      " 4   Total Time           179514 non-null  int64 \n",
      " 5   Session login date   179514 non-null  object\n",
      " 6   Session login time   179514 non-null  object\n",
      " 7   Session logout date  179514 non-null  object\n",
      " 8   Session logout time  179514 non-null  object\n",
      "dtypes: int64(2), object(7)\n",
      "memory usage: 12.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# IMPORT EPS\n",
    "eps = import_csv(path = eps_path)\n",
    "eps = eps.drop(columns=['Index', 'filename', 'Date'])\n",
    "eps['Session login VN'] = pd.to_datetime(eps['Session Login'], format ='mixed') + pd.Timedelta(hours=5)\n",
    "eps['Session logout VN'] = pd.to_datetime(eps['Session Logout'], format ='mixed') + pd.Timedelta(hours=5)\n",
    "eps['Session login date'] = pd.to_datetime(eps['Session login VN']).dt.date\n",
    "eps['Session login time'] = pd.to_datetime(eps['Session login VN']).dt.time\n",
    "eps['Session logout date'] = pd.to_datetime(eps['Session logout VN']).dt.date\n",
    "eps['Session logout time'] = pd.to_datetime(eps['Session logout VN']).dt.time\n",
    "eps = eps.drop(columns=['Session login VN', 'Session logout VN', 'Username', 'manager_username', 'sitecode', 'Session Time'])\n",
    "eps.info()\n",
    "eps.to_csv(r\"C:\\Users\\dinhhoang.nguyen\\OneDrive - Concentrix Corporation\\WFM-internal\\DB\\filecsv\\eps_test.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 73913 entries, 0 to 73912\n",
      "Data columns (total 6 columns):\n",
      " #   Column                    Non-Null Count  Dtype         \n",
      "---  ------                    --------------  -----         \n",
      " 0   Staff Name                73913 non-null  object        \n",
      " 1   Channel                   57015 non-null  object        \n",
      " 2   Number of Records         71222 non-null  float64       \n",
      " 3   Nombre d'enregistrements  2691 non-null   float64       \n",
      " 4   Date                      73913 non-null  datetime64[ns]\n",
      " 5   Employee_ID               73306 non-null  Int64         \n",
      "dtypes: Int64(1), datetime64[ns](1), float64(2), object(2)\n",
      "memory usage: 3.5+ MB\n",
      "          Staff Name    Channel  Number of Records  Nombre d'enregistrements  \\\n",
      "0       Mikael Duong      phone                4.0                       NaN   \n",
      "1           Kelly Le      phone                1.0                       NaN   \n",
      "2      Jennie Nguyen      phone                9.0                       NaN   \n",
      "3       Mikael Duong  messaging                7.0                       NaN   \n",
      "4           Kelly Le  messaging                6.0                       NaN   \n",
      "...              ...        ...                ...                       ...   \n",
      "73908     Nas Nguyen        NaN               14.0                       NaN   \n",
      "73909         John N        NaN                9.0                       NaN   \n",
      "73910  Viktor Nguyen  messaging               10.0                       NaN   \n",
      "73911  Viktor Nguyen      email                5.0                       NaN   \n",
      "73912  Viktor Nguyen        NaN               15.0                       NaN   \n",
      "\n",
      "            Date  Employee_ID  \n",
      "0     1990-01-01    102208111  \n",
      "1     1990-01-01    102207120  \n",
      "2     1990-01-01    102207121  \n",
      "3     1990-01-01    102208111  \n",
      "4     1990-01-01    102207120  \n",
      "...          ...          ...  \n",
      "73908 2023-10-07    102155919  \n",
      "73909 2023-10-07    102155897  \n",
      "73910 2023-10-07    102173701  \n",
      "73911 2023-10-07    102173701  \n",
      "73912 2023-10-07    102173701  \n",
      "\n",
      "[73913 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "#IMPORT CPI\n",
    "cpi = import_csv(path = cpi_path)\n",
    "cpi = cpi.drop(columns=['Region Partner', 'Sitecode', 'Mp Csm Name', 'Mp Team Name'])\n",
    "cpi['Date'] = cpi['filename'].replace(\".csv\", \"\", regex=True)\n",
    "cpi['Date'] = pd.to_datetime(cpi['Date'], format = \"mixed\")\n",
    "\n",
    "\n",
    "masterroster_cpi = masterroster[['Employee_ID', 'TED Name']]\n",
    "cpi = pd.merge(cpi, masterroster_cpi, left_on=\"Staff Name\", right_on=\"TED Name\", how=\"left\")\n",
    "cpi = cpi.drop(columns=['filename', 'TED Name'])\n",
    "\n",
    "cpi.info()\n",
    "print(cpi)\n",
    "cpi.to_csv(r\"C:\\Users\\dinhhoang.nguyen\\OneDrive - Concentrix Corporation\\WFM-internal\\DB\\filecsv\\cpi_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dinhhoang.nguyen.CONCENTRIX\\AppData\\Local\\Temp\\VSCodePortable-x64Temp\\ipykernel_13476\\2378756514.py:7: DtypeWarning: Columns (10,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  file_data = pd.read_csv(file_path)\n",
      "C:\\Users\\dinhhoang.nguyen.CONCENTRIX\\AppData\\Local\\Temp\\VSCodePortable-x64Temp\\ipykernel_13476\\2378756514.py:7: DtypeWarning: Columns (10,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  file_data = pd.read_csv(file_path)\n",
      "C:\\Users\\dinhhoang.nguyen.CONCENTRIX\\AppData\\Local\\Temp\\VSCodePortable-x64Temp\\ipykernel_13476\\2378756514.py:7: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  file_data = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 575670 entries, 0 to 575669\n",
      "Data columns (total 15 columns):\n",
      " #   Column                Non-Null Count   Dtype         \n",
      "---  ------                --------------   -----         \n",
      " 0   Date                  398860 non-null  datetime64[ns]\n",
      " 1   Start Time            398860 non-null  object        \n",
      " 2   End Time              398860 non-null  object        \n",
      " 3   Staff                 398860 non-null  object        \n",
      " 4   Language              294665 non-null  object        \n",
      " 5   Item Channel          398860 non-null  object        \n",
      " 6   Topic                 398860 non-null  object        \n",
      " 7   Subtopic              398860 non-null  object        \n",
      " 8   \"Handling Time\"       398860 non-null  object        \n",
      " 9   First Email Id        0 non-null       float64       \n",
      " 10  First Hotel Id        337783 non-null  object        \n",
      " 11  First Reservation Id  324807 non-null  object        \n",
      " 12  Tooltip Phone Time    91168 non-null   object        \n",
      " 13  Handling Time         398860 non-null  float64       \n",
      " 14  Employee_ID           396944 non-null  Int64         \n",
      "dtypes: Int64(1), datetime64[ns](1), float64(2), object(11)\n",
      "memory usage: 66.4+ MB\n",
      "             Date     Start Time       End Time         Staff Language  \\\n",
      "0      2023-08-01  1/8/2023 0:11  1/8/2023 0:12        Min Le      NaN   \n",
      "1      2023-08-01  1/8/2023 0:25  1/8/2023 0:37       Jane Ng  English   \n",
      "2      2023-08-01  1/8/2023 0:31  1/8/2023 0:41       Jane Ng  English   \n",
      "3      2023-08-01  1/8/2023 0:41  1/8/2023 0:56       Jane Ng  English   \n",
      "4      2023-08-01  1/8/2023 1:02  1/8/2023 1:35  Shannah Pham      NaN   \n",
      "...           ...            ...            ...           ...      ...   \n",
      "575665        NaT            NaN            NaN           NaN      NaN   \n",
      "575666        NaT            NaN            NaN           NaN      NaN   \n",
      "575667        NaT            NaN            NaN           NaN      NaN   \n",
      "575668        NaT            NaN            NaN           NaN      NaN   \n",
      "575669        NaT            NaN            NaN           NaN      NaN   \n",
      "\n",
      "       Item Channel         Topic  \\\n",
      "0           Unknown    Relocation   \n",
      "1             Email    Relocation   \n",
      "2             Email    Relocation   \n",
      "3             Email  Modification   \n",
      "4           Unknown       Unknown   \n",
      "...             ...           ...   \n",
      "575665          NaN           NaN   \n",
      "575666          NaN           NaN   \n",
      "575667          NaN           NaN   \n",
      "575668          NaN           NaN   \n",
      "575669          NaN           NaN   \n",
      "\n",
      "                                                 Subtopic \"Handling Time\"  \\\n",
      "0                  accommodation_cannot_accommodate_guest   Handling Time   \n",
      "1                  accommodation_cannot_accommodate_guest   Handling Time   \n",
      "2                  accommodation_cannot_accommodate_guest   Handling Time   \n",
      "3       CS_report_or_request_help_with_incorrectly_loa...   Handling Time   \n",
      "4                                  Customer_level_actions   Handling Time   \n",
      "...                                                   ...             ...   \n",
      "575665                                                NaN             NaN   \n",
      "575666                                                NaN             NaN   \n",
      "575667                                                NaN             NaN   \n",
      "575668                                                NaN             NaN   \n",
      "575669                                                NaN             NaN   \n",
      "\n",
      "        First Email Id First Hotel Id First Reservation Id Tooltip Phone Time  \\\n",
      "0                  NaN        7916582           3709125556                NaN   \n",
      "1                  NaN       10538247           2933359225                NaN   \n",
      "2                  NaN       10010179           2802616410                NaN   \n",
      "3                  NaN        9651702           3889216084                NaN   \n",
      "4                  NaN            NaN                  NaN                NaN   \n",
      "...                ...            ...                  ...                ...   \n",
      "575665             NaN            NaN                  NaN                NaN   \n",
      "575666             NaN            NaN                  NaN                NaN   \n",
      "575667             NaN            NaN                  NaN                NaN   \n",
      "575668             NaN            NaN                  NaN                NaN   \n",
      "575669             NaN            NaN                  NaN                NaN   \n",
      "\n",
      "        Handling Time  Employee_ID  \n",
      "0          299.000000    102219144  \n",
      "1          332.909091    102203539  \n",
      "2          271.909091    102203539  \n",
      "3          740.909091    102203539  \n",
      "4          257.428571    102203562  \n",
      "...               ...          ...  \n",
      "575665            NaN         <NA>  \n",
      "575666            NaN         <NA>  \n",
      "575667            NaN         <NA>  \n",
      "575668            NaN         <NA>  \n",
      "575669            NaN         <NA>  \n",
      "\n",
      "[575670 rows x 15 columns]\n"
     ]
    }
   ],
   "source": [
    "#IMPORT AHT\n",
    "aht = import_csv(path = aht_path)\n",
    "aht = aht.drop(columns=['filename'])\n",
    "masterroster_aht = masterroster[['Employee_ID', 'TED Name']]\n",
    "aht = pd.merge(aht, masterroster_aht, left_on='Staff', right_on ='TED Name', how='left')\n",
    "aht = aht.drop(columns=['TED Name'])\n",
    "aht['Date'] = pd.to_datetime(aht['Date'], format='mixed')\n",
    "\n",
    "aht.info()\n",
    "\n",
    "print(aht)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Survey Id  Reservation          Team    Channel         Staff  \\\n",
      "0      3018426701   3056847985  Duy Hoang Ho      email    Mia Nguyen   \n",
      "1      3018613711   2665820829    Nina Huynh      email    Henry Phan   \n",
      "2      3018623696   3548174839    Nina Huynh  messaging    Henry Phan   \n",
      "3      3018646254   2314992465  Duy Hoang Ho  messaging    Ann Nguyen   \n",
      "4      3018660236   3138227680    Nina Huynh      email    Naomi Tran   \n",
      "...           ...          ...           ...        ...           ...   \n",
      "24900  3443958520   4134327179     Rosa Dang      phone    Jesse Doan   \n",
      "24901  3443992705   4179345842  Duy Hoang Ho      phone    Ceasar Ton   \n",
      "24902  3445373197   4197622059  Duy Hoang Ho      email      Le Chris   \n",
      "24903  3446652398   4024792325     Anna Corn      phone  Jordi Nguyen   \n",
      "24904  3446748298   4178054364    Nina Huynh      phone  Bobby Nguyen   \n",
      "\n",
      "             Type      Date                        Topic of the first Ticket  \\\n",
      "0      touchpoint 2023-06-01             CS_request_cancellation_by_property   \n",
      "1      touchpoint 2023-06-01                         CS_discuss_no_show_fees   \n",
      "2      touchpoint 2023-06-01                        CS_verify_payment_status   \n",
      "3      touchpoint 2023-06-01  CS_request_information_other_free_typing_field   \n",
      "4      touchpoint 2023-06-01                                    CS_claim_bpg   \n",
      "...           ...        ...                                             ...   \n",
      "24900  touchpoint 2023-10-01          accommodation_cannot_accommodate_guest   \n",
      "24901  touchpoint 2023-10-01                                 CS_change_dates   \n",
      "24902  touchpoint 2023-10-01                                    CS_claim_bpg   \n",
      "24903  touchpoint 2023-10-01          accommodation_cannot_accommodate_guest   \n",
      "24904  touchpoint 2023-10-01                         CS_request_cancellation   \n",
      "\n",
      "                      Language     Csat 2.0 Score  Employee_ID  \n",
      "0           English (American)     Very Satisfied    102025366  \n",
      "1                      English  Very Dissatisfied    102198175  \n",
      "2                       Korean     Very Satisfied    102198175  \n",
      "3                       Korean     Very Satisfied    102026221  \n",
      "4           English (American)  Very Dissatisfied    101993687  \n",
      "...                        ...                ...          ...  \n",
      "24900  English (Great Britain)     Very Satisfied    102278475  \n",
      "24901  English (Great Britain)     Very Satisfied    102203551  \n",
      "24902  English (Great Britain)          Satisfied    102159132  \n",
      "24903                 Ukranian     Very Satisfied    102254108  \n",
      "24904                  Spanish  Very Dissatisfied    102242692  \n",
      "\n",
      "[24905 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "#IMPORT CSAT\n",
    "csat = import_csv(path = csat_path)\n",
    "masterroster_csat = masterroster[['Employee_ID', 'TED Name']]\n",
    "\n",
    "\n",
    "csat['Date '] = pd.to_datetime(csat['Date '], format='%m/%d/%Y')\n",
    "csat = pd.merge(csat, masterroster_csat, left_on='Staff', right_on ='TED Name', how='left')\n",
    "\n",
    "csat = csat.drop(columns=['Sort by Dimension', 'Has Comment', '\"Comment\"', 'Reservation Link', 'View comment', 'Sort by Dimension (copy)', 'filename', 'TED Name', 'Max. Sort by Dimension'])\n",
    "print(csat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT SCHEDULE\n",
    "schedule = import_xlsx(path = schedule_path,sheet_name='Sheet1')\n",
    "schedule['Attribute'] = pd.to_datetime(schedule['Attribute'],format='mixed').dt.date\n",
    "schedule=schedule.iloc[:,0:8]\n",
    "condition=(schedule['Value']=='OFF')|(schedule['Value']=='AL')|(schedule['Value']=='CO')|(schedule['Value']=='UPL')|(schedule['Value']=='Training')\n",
    "schedule['Shift'] = np.where(condition, 'OFF', schedule['NS Check'])\n",
    "schedule=schedule[['Emp ID','Name','Attribute','Value','LOB','Shift']]\n",
    "schedule=schedule.rename(columns={'Attribute':'Date','Value':'Shift','Shift':'Shift_type'})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORT CUIC\n",
    "cuic = import_xlsx(path = cuic_path,sheet_name=\"Khoa Interval Attendance Check-\")\n",
    "cuic['Date'] = pd.to_datetime(cuic['Interval'], format = \"mixed\").dt.date\n",
    "cuic['Time'] = pd.to_datetime(cuic['Interval'], format = \"mixed\").dt.time\n",
    "cuic = pd.merge(cuic, masterroster, left_on='LoginName', right_on ='Booking Login ID', how='left')\n",
    "cuic=cuic.iloc[:,0:9]\n",
    "cuic = pd.merge(cuic, schedule, left_on=['Employee_ID','Date'], right_on =['Emp ID','Date'], how='left')\n",
    "cuic=cuic[['FullName','LoginName','Interval','AgentAvailTime','AgentLoggedOnTime','Date','Time','Employee_ID','Shift_type','Shift']]\n",
    "cuic['Date-1']=pd.to_datetime(cuic['Date'], format ='mixed') - pd.Timedelta(1,\"d\")\n",
    "cuic['Date-1']=pd.to_datetime(cuic['Date-1'], format ='mixed').dt.date\n",
    "cuic = pd.merge(cuic, schedule, left_on=['Employee_ID','Date-1'], right_on =['Emp ID','Date'], how='left')\n",
    "cuic=cuic[['FullName','LoginName','Interval','AgentAvailTime','AgentLoggedOnTime','Date_x','Time','Employee_ID','Shift_type_x','Shift_x','Date-1','Shift_type_y','Shift_y']]\n",
    "mytime=t(12,0,0)\n",
    "condition=(cuic['Shift_type_x']!='DS')&(cuic['Shift_type_y']=='NS')&(cuic['Time']<mytime)\n",
    "cuic['Session Date'] = np.where(condition, cuic['Date-1'], cuic['Date_x'])\n",
    "cuic=cuic[['FullName','LoginName','Interval','AgentAvailTime','AgentLoggedOnTime','Date_x','Employee_ID','Shift_type_x','Session Date']]\n",
    "cuic=cuic.rename(columns={'Date_x':'Date','Shift_type_x':'Shift_type'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 226 entries, 0 to 225\n",
      "Data columns (total 6 columns):\n",
      " #   Column                       Non-Null Count  Dtype         \n",
      "---  ------                       --------------  -----         \n",
      " 0   Emp ID                       226 non-null    int64         \n",
      " 1   Date                         226 non-null    datetime64[ns]\n",
      " 2   Exception request \n",
      "(Minute)  224 non-null    float64       \n",
      " 3   Reason                       225 non-null    object        \n",
      " 4   TL                           224 non-null    object        \n",
      " 5   OM                           64 non-null     object        \n",
      "dtypes: datetime64[ns](1), float64(1), int64(1), object(3)\n",
      "memory usage: 10.7+ KB\n"
     ]
    }
   ],
   "source": [
    "#EXCEPTION\n",
    "exceptional_hrs = import_xlsx(path= exception_path, sheet_name=\"Sheet1\")\n",
    "exceptional_hrs = exceptional_hrs.rename(columns={'Date \\n(MM/DD/YYYY)':'Date'})\n",
    "exceptional_hrs = exceptional_hrs.drop(columns=['filename'])\n",
    "\n",
    "exceptional_hrs.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Emp ID  Extension Number\n",
      "0    101754274          72786027\n",
      "1    101758902          72786060\n",
      "2    101758951          72786058\n",
      "3    101758868          72786059\n",
      "4    101631001          72786086\n",
      "..         ...               ...\n",
      "524  102278515          72786990\n",
      "525  102278516          72786860\n",
      "526  102279846          72786973\n",
      "527  102279847          72786988\n",
      "528  102279848          72786563\n",
      "\n",
      "[529 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#IMPORT EXTENSION\n",
    "extension = import_xlsx(path= extension_path, sheet_name=\"Sheet1\")\n",
    "extension = extension[['Emp ID', 'Extension Number']]\n",
    "extension['Extension Number'] = extension['Extension Number'].astype(\"Int64\")\n",
    "print(extension)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ID Agent        EID\n",
      "0     3006158  101988331\n",
      "1     3009891  101754192\n",
      "2     3011158  101631001\n",
      "3     3014249  101769330\n",
      "4     3014252  101769328\n",
      "..        ...        ...\n",
      "587   3069722  102278512\n",
      "588   3069723  102278397\n",
      "589   3069755  102279847\n",
      "590   3069759  102279846\n",
      "591   3069760  102279848\n",
      "\n",
      "[592 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#IMPORT IEX ID\n",
    "iex = import_xlsx(path = iex_path, sheet_name=\"Sheet1\")\n",
    "iex = iex[['ID Agent', 'Personal ID']]\n",
    "iex = iex.rename(columns={'Personal ID': 'EID'})\n",
    "print(iex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Emp ID Supervisor\n",
      "0    101754274       Nina\n",
      "1    101758868       Nina\n",
      "2    101993685   John Luu\n",
      "3    101993760   John Luu\n",
      "4    102177117         An\n",
      "..         ...        ...\n",
      "594  102265696        Gio\n",
      "595  102265697       Rosa\n",
      "596  102267302        Gio\n",
      "597  102267344       Rosa\n",
      "598  102267481        Gio\n",
      "\n",
      "[599 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# IMPORT TL\n",
    "tl = pd.read_excel(os.path.join(tl_path, \"TL List.xlsx\"),sheet_name='Sheet1')\n",
    "tl=tl.iloc[:,0:6]\n",
    "tl=tl.rename(columns={'Supervisor (no need fill)': 'Supervisor'})\n",
    "tl=tl.drop(columns=['Wave', 'Name', 'LOB', 'Full name (VN)'])\n",
    "print(tl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Date        EID    LOB  Duration\n",
      "0    2023-05-16  102198234  VICSG       7.5\n",
      "1    2023-05-16  101993685  VICSG       7.5\n",
      "2    2023-05-16  101993770  VICSG       7.5\n",
      "3    2023-05-16  102168268     NL       7.5\n",
      "4    2023-05-16  102168217    ID4       7.5\n",
      "..          ...        ...    ...       ...\n",
      "177  2023-07-28  102273515     EN       3.0\n",
      "178  2023-07-28  102273437     EN       3.0\n",
      "179  2023-07-28  102273538     EN       3.0\n",
      "180  2023-07-28  102277706     EN       3.0\n",
      "181  2023-07-28  102274819     EN       3.0\n",
      "\n",
      "[182 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# IMPORT TRAINING\n",
    "training = import_xlsx(path = training_path,sheet_name='Sheet1')\n",
    "training['Date'] = pd.to_datetime(training['Date'],format='mixed').dt.date\n",
    "training['EID'] = training['EID'].astype(\"int64\")\n",
    "training=training.iloc[:,1:]\n",
    "\n",
    "print(training)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT IOSHRINKAGE\n",
    "ioshrinkage = import_xlsx(path = ioshrinkage_path, sheet_name='Sheet1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emp ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>OT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101631001</td>\n",
       "      <td>2023-06-26</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101946738</td>\n",
       "      <td>2023-06-19</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101946738</td>\n",
       "      <td>2023-06-20</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101946738</td>\n",
       "      <td>2023-06-21</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101946738</td>\n",
       "      <td>2023-06-22</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39642</th>\n",
       "      <td>102265696</td>\n",
       "      <td>2023-09-20</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39643</th>\n",
       "      <td>102265696</td>\n",
       "      <td>2023-09-21</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39644</th>\n",
       "      <td>102265696</td>\n",
       "      <td>2023-09-22</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39645</th>\n",
       "      <td>102265696</td>\n",
       "      <td>2023-09-23</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39646</th>\n",
       "      <td>102265696</td>\n",
       "      <td>2023-09-24</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39647 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Emp ID        Date    OT\n",
       "0      101631001  2023-06-26  12.0\n",
       "1      101946738  2023-06-19   0.0\n",
       "2      101946738  2023-06-20   0.0\n",
       "3      101946738  2023-06-21   0.0\n",
       "4      101946738  2023-06-22   0.0\n",
       "...          ...         ...   ...\n",
       "39642  102265696  2023-09-20   0.0\n",
       "39643  102265696  2023-09-21   0.0\n",
       "39644  102265696  2023-09-22   0.0\n",
       "39645  102265696  2023-09-23   0.0\n",
       "39646  102265696  2023-09-24   0.0\n",
       "\n",
       "[39647 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# IMPORT OT\n",
    "\n",
    "ot = import_xlsx(path = ot_path, sheet_name='Sheet2')\n",
    "ot = ot.drop(columns=['Wave', 'Name', 'Value', 'LOB', 'filename'])\n",
    "ot['Date'] = pd.to_datetime(ot['Date'], format=\"mixed\")\n",
    "ot['Date'] = ot['Date'].dt.date\n",
    "\n",
    "\n",
    "display(ot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT PSAT\n",
    "psat = import_csv(path = psat_path)\n",
    "psat['Date'] = pd.to_datetime(psat['Date'],format='mixed').dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT QUALITY\n",
    "quality_raw = import_xlsx(path = quality_path,sheet_name='Sheet1')\n",
    "quality_raw['eval_date'] = pd.to_datetime(quality_raw['eval_date'],format='mixed').dt.date\n",
    "quality=quality_raw.iloc[:,0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT RAMCO\n",
    "ramco = import_csv(path = ramco_path)\n",
    "ramco['Attribute'] = pd.to_datetime(ramco['Attribute'],format='mixed').dt.date\n",
    "ramco=ramco.rename(columns={'Attribute':'Date'})\n",
    "ramco['EID']=ramco['EID'].astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT RAMCOOT\n",
    "ramcoot = import_xlsx(path = ramcoot_path,sheet_name='Sheet1')\n",
    "ramcoot['Attribute'] = pd.to_datetime(ramcoot['Attribute'],format='mixed').dt.date\n",
    "ramcoot=ramcoot.rename(columns={'Attribute':'Date'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT REQUIREMENT\n",
    "requirement = import_xlsx(path = requirement_path,sheet_name='Sheet1')\n",
    "requirement['Date'] = pd.to_datetime(requirement['Date'],format='mixed').dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT WORKPLAN\n",
    "workplan_raw = import_xlsx(path = workplan_path,sheet_name='Sheet1')\n",
    "workplan_raw['Date'] = pd.to_datetime(workplan_raw['Date'],format='mixed').dt.date\n",
    "workplan_merge_iex = pd.merge(workplan_raw,iex, left_on='Agent ID', right_on ='ID Agent', how='left')\n",
    "workplan_merge_iex['EID'] = workplan_merge_iex['EID'].astype(\"Int64\")\n",
    "workplan_merge_iex=workplan_merge_iex.drop(columns=['filename', 'ID Agent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORT LABELS\n",
    "labels = import_csv(label_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emp ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Date</th>\n",
       "      <th>Shift</th>\n",
       "      <th>LOB</th>\n",
       "      <th>Supervisor</th>\n",
       "      <th>Ramco</th>\n",
       "      <th>CUIC Actual hrs</th>\n",
       "      <th>Attendance Code</th>\n",
       "      <th>Schedule</th>\n",
       "      <th>Actual</th>\n",
       "      <th>Planned Leave</th>\n",
       "      <th>Actual Leave</th>\n",
       "      <th>OT</th>\n",
       "      <th>Scheduled hrs</th>\n",
       "      <th>Total scheduled</th>\n",
       "      <th>Attendance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>102265180</td>\n",
       "      <td>Nguyen Ho Khanh Vi</td>\n",
       "      <td>2023-08-03</td>\n",
       "      <td>OFF</td>\n",
       "      <td>NL</td>\n",
       "      <td>Gio</td>\n",
       "      <td>PO</td>\n",
       "      <td>8.871389</td>\n",
       "      <td>OFF</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1587</th>\n",
       "      <td>102026217</td>\n",
       "      <td>Hoang Tran Minh Thu</td>\n",
       "      <td>2023-08-05</td>\n",
       "      <td>OFF</td>\n",
       "      <td>NL</td>\n",
       "      <td>Annie</td>\n",
       "      <td>PO</td>\n",
       "      <td>8.018611</td>\n",
       "      <td>OFF</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>102198227</td>\n",
       "      <td>Ngo Thanh Hoa</td>\n",
       "      <td>2023-08-05</td>\n",
       "      <td>OFF</td>\n",
       "      <td>NL</td>\n",
       "      <td>Billy</td>\n",
       "      <td>PO</td>\n",
       "      <td>9.027500</td>\n",
       "      <td>OFF</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1601</th>\n",
       "      <td>102198239</td>\n",
       "      <td>Nguyen Trung Tinh</td>\n",
       "      <td>2023-08-05</td>\n",
       "      <td>OFF</td>\n",
       "      <td>NL</td>\n",
       "      <td>Billy</td>\n",
       "      <td>PO</td>\n",
       "      <td>9.045278</td>\n",
       "      <td>OFF</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1608</th>\n",
       "      <td>102155918</td>\n",
       "      <td>Le Hoang Duy</td>\n",
       "      <td>2023-08-05</td>\n",
       "      <td>OFF</td>\n",
       "      <td>NL</td>\n",
       "      <td>Billy</td>\n",
       "      <td>PO</td>\n",
       "      <td>9.020833</td>\n",
       "      <td>OFF</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25882</th>\n",
       "      <td>102219148</td>\n",
       "      <td>Tran Hoai Huy</td>\n",
       "      <td>2023-09-21</td>\n",
       "      <td>OFF</td>\n",
       "      <td>VICSP</td>\n",
       "      <td>Yin</td>\n",
       "      <td>PO</td>\n",
       "      <td>8.058889</td>\n",
       "      <td>OFF</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26010</th>\n",
       "      <td>102231426</td>\n",
       "      <td>Vu Minh Trung</td>\n",
       "      <td>2023-09-20</td>\n",
       "      <td>OFF</td>\n",
       "      <td>VICSP</td>\n",
       "      <td>Yin</td>\n",
       "      <td>PO</td>\n",
       "      <td>7.998333</td>\n",
       "      <td>OFF</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.998333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26056</th>\n",
       "      <td>102234885</td>\n",
       "      <td>Dang Tien</td>\n",
       "      <td>2023-09-19</td>\n",
       "      <td>OFF</td>\n",
       "      <td>VICSP</td>\n",
       "      <td>Yin</td>\n",
       "      <td>PO</td>\n",
       "      <td>5.041389</td>\n",
       "      <td>OFF</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26094</th>\n",
       "      <td>102234930</td>\n",
       "      <td>Le Minh Trung</td>\n",
       "      <td>2023-09-19</td>\n",
       "      <td>OFF</td>\n",
       "      <td>VICSP</td>\n",
       "      <td>Yin</td>\n",
       "      <td>PO</td>\n",
       "      <td>8.574167</td>\n",
       "      <td>OFF</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27534</th>\n",
       "      <td>102186582</td>\n",
       "      <td>Nguyen Khanh Dinh Van</td>\n",
       "      <td>2023-09-20</td>\n",
       "      <td>OFF</td>\n",
       "      <td>VICSP</td>\n",
       "      <td>Yin</td>\n",
       "      <td>PO</td>\n",
       "      <td>4.330278</td>\n",
       "      <td>OFF</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>275 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Emp ID                   Name        Date Shift    LOB Supervisor  \\\n",
       "773    102265180     Nguyen Ho Khanh Vi  2023-08-03   OFF     NL        Gio   \n",
       "1587   102026217    Hoang Tran Minh Thu  2023-08-05   OFF     NL      Annie   \n",
       "1594   102198227          Ngo Thanh Hoa  2023-08-05   OFF     NL      Billy   \n",
       "1601   102198239      Nguyen Trung Tinh  2023-08-05   OFF     NL      Billy   \n",
       "1608   102155918           Le Hoang Duy  2023-08-05   OFF     NL      Billy   \n",
       "...          ...                    ...         ...   ...    ...        ...   \n",
       "25882  102219148          Tran Hoai Huy  2023-09-21   OFF  VICSP        Yin   \n",
       "26010  102231426          Vu Minh Trung  2023-09-20   OFF  VICSP        Yin   \n",
       "26056  102234885              Dang Tien  2023-09-19   OFF  VICSP        Yin   \n",
       "26094  102234930          Le Minh Trung  2023-09-19   OFF  VICSP        Yin   \n",
       "27534  102186582  Nguyen Khanh Dinh Van  2023-09-20   OFF  VICSP        Yin   \n",
       "\n",
       "      Ramco  CUIC Actual hrs Attendance Code  Schedule  Actual  Planned Leave  \\\n",
       "773      PO         8.871389             OFF       0.0     0.0            0.0   \n",
       "1587     PO         8.018611             OFF       0.0     0.0            0.0   \n",
       "1594     PO         9.027500             OFF       0.0     0.0            0.0   \n",
       "1601     PO         9.045278             OFF       0.0     0.0            0.0   \n",
       "1608     PO         9.020833             OFF       0.0     0.0            0.0   \n",
       "...     ...              ...             ...       ...     ...            ...   \n",
       "25882    PO         8.058889             OFF       0.0     0.0            0.0   \n",
       "26010    PO         7.998333             OFF       0.0     0.0            0.0   \n",
       "26056    PO         5.041389             OFF       0.0     0.0            0.0   \n",
       "26094    PO         8.574167             OFF       0.0     0.0            0.0   \n",
       "27534    PO         4.330278             OFF       0.0     0.0            0.0   \n",
       "\n",
       "       Actual Leave   OT  Scheduled hrs  Total scheduled  Attendance  \n",
       "773             0.0  8.0            8.0              8.0    8.000000  \n",
       "1587            0.0  8.0            8.0              8.0    8.000000  \n",
       "1594            0.0  9.0            9.0              9.0    9.000000  \n",
       "1601            0.0  9.0            9.0              9.0    9.000000  \n",
       "1608            0.0  9.0            9.0              9.0    9.000000  \n",
       "...             ...  ...            ...              ...         ...  \n",
       "25882           0.0  8.0            8.0              8.0    8.000000  \n",
       "26010           0.0  8.0            8.0              8.0    7.998333  \n",
       "26056           0.0  5.0            5.0              5.0    5.000000  \n",
       "26094           0.0  8.0            8.0              8.0    8.000000  \n",
       "27534           0.0  0.0            0.0              0.0    0.000000  \n",
       "\n",
       "[275 rows x 17 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# BOOKING ATTENDANCE\n",
    "bkn_att = schedule.drop(columns=['Shift_type'])\n",
    "bkn_att_ramco = ramco[['EID', 'Date', 'Value']]\n",
    "bkn_att = pd.merge(bkn_att, tl, on='Emp ID', how='left')\n",
    "bkn_att = pd.merge(bkn_att, bkn_att_ramco, left_on =['Emp ID', 'Date'], right_on=['EID', 'Date'], how='left')\n",
    "bkn_att = bkn_att.drop(columns=['EID'])\n",
    "bkn_att = bkn_att.rename(columns={'Value': 'Ramco'})\n",
    "#get cuic\n",
    "bkn_att_cuic = cuic[['Employee_ID', 'Session Date','AgentLoggedOnTime']].groupby(['Employee_ID', 'Session Date'], as_index=False).sum()\n",
    "bkn_att = pd.merge(bkn_att, bkn_att_cuic, left_on=['Emp ID', 'Date'], right_on=['Employee_ID', 'Session Date'], how='left')\n",
    "bkn_att = bkn_att.rename(columns={'AgentLoggedOnTime': 'CUIC Actual hrs'})\n",
    "bkn_att['CUIC Actual hrs'] = bkn_att['CUIC Actual hrs']*24\n",
    "#remove Employee_ID no CUIC data\n",
    "bkn_att = bkn_att.drop(columns=['Employee_ID', 'Session Date'])\n",
    "bkn_att = pd.merge(bkn_att, labels, left_on=\"Shift\", right_on=\"Attendance Code\", how=\"left\")\n",
    "\n",
    "#sum OT by agent&ID\n",
    "bkn_att = pd.merge(bkn_att, ot, on=['Emp ID', 'Date'], how=\"left\")\n",
    "bkn_att['OT'] = bkn_att['OT'].fillna(0)\n",
    "bkn_att['CUIC Actual hrs'] = bkn_att['CUIC Actual hrs'].fillna(0)\n",
    "bkn_att['Scheduled hrs'] = bkn_att['OT'] + bkn_att['Schedule']\n",
    "bkn_att = bkn_att.rename(columns={'Planned leaves': 'Planned Leave', 'Actual leaves': 'Actual Leave'})\n",
    "bkn_att['Total scheduled'] = bkn_att['Scheduled hrs'] + bkn_att['Planned Leave']\n",
    "\n",
    "#Add Attendance\n",
    "\n",
    "def attendance_func(x):\n",
    "    if x['Shift'] == 'OFF':\n",
    "        if x['Ramco'] =='PO':\n",
    "            result1 = x['CUIC Actual hrs']\n",
    "        else:\n",
    "            result1 = 0\n",
    "    else:\n",
    "        result1 = x['CUIC Actual hrs']\n",
    "\n",
    "    if result1 > x['Scheduled hrs']:\n",
    "        return x['Scheduled hrs']\n",
    "    else:\n",
    "        return result1\n",
    "\n",
    "bkn_att['Attendance'] = bkn_att.apply(attendance_func, axis=1)\n",
    "\n",
    "#Drop columns\n",
    "bkn_att = bkn_att.drop(columns=['Description', 'Type', 'filename'])\n",
    "bkn_att['Date'] = pd.to_datetime(bkn_att['Date'], format ='mixed').dt.strftime('%Y-%m-%d')\n",
    "test_cuic = bkn_att.loc[(bkn_att['Shift'] =='OFF') & (bkn_att['Ramco'] =='PO')]\n",
    "display(test_cuic)\n",
    "bkn_att.to_csv(r'C:\\Users\\dinhhoang.nguyen\\OneDrive - Concentrix Corporation\\WFM-internal\\Calculators\\Joey Nguyen\\py\\booking_attendance.csv', index=False)\n",
    "bkn_att.to_json(r'C:\\Users\\dinhhoang.nguyen.CONCENTRIX\\OneDrive - Concentrix Corporation\\WFM-internal\\DB\\filejson\\booking_attendance.json', orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 1. AHT\n",
    "# ahtrp = aht.drop(columns=['Start Time', 'End Time', '\"Handling Time\"', 'First Email Id'])\n",
    "\n",
    "# ## add Eliminate Phone\n",
    "# def eliminate_phone(x):\n",
    "#     if x['Item Channel'] =='Phone' and x['Topic'] =='Unknown':\n",
    "#         return \"Notphone\"\n",
    "#     else:\n",
    "#         return x['Item Channel']\n",
    "# ahtrp['Eliminate Phone'] = ahtrp.apply(eliminate_phone, axis=1)\n",
    "\n",
    "# aht_mr = masterroster[['Employee_ID', 'PST_Start_Date', 'CUIC Name', 'Full name', 'Role', 'TED Name', 'Wave #']]\n",
    "\n",
    "# ahtrp = pd.merge(ahtrp, aht_mr, left_on='Staff', right_on='TED Name', how='left')\n",
    "\n",
    "# def TN(x):\n",
    "#     if x['Date'] - x['PST_Start_Date'] >= pd.Timedelta(days=90):\n",
    "#         return \"TN\"\n",
    "#     else:\n",
    "#         return \"NH\"\n",
    "    \n",
    "# ahtrp['Tenure'] = ahtrp.apply(TN, axis=1)\n",
    "# ahtrp = pd.merge(ahtrp, tl, left_on ='Employee_ID_x', right_on = 'Emp ID', how='left')\n",
    "# aht_lob = schedule[['Emp ID', 'Date', 'LOB']]\n",
    "# aht_lob['Date'] = pd.to_datetime(aht_lob['Date'], format ='mixed')\n",
    "# ahtrp = pd.merge(ahtrp, aht_lob, left_on = ['Employee_ID_x', 'Date'], right_on=['Emp ID', 'Date'], how='left')\n",
    "# ahtrp = ahtrp.drop(columns=['Employee_ID_y', 'Emp ID_x', 'Emp ID_y'])\n",
    "# ahtrp = ahtrp.rename(columns={'Employee_ID_x':'Employee_ID'})\n",
    "# #Add talk time\n",
    "# def talk_time(x):\n",
    "#     try:\n",
    "#         from_left = 11\n",
    "#         to_right = str(x['Tooltip Phone Time']).find(' Wrap Time')\n",
    "#         return int(x['Tooltip Phone Time'][from_left:to_right])\n",
    "#     except:\n",
    "#         return 0\n",
    "# def wrap_time(x):\n",
    "#     try:\n",
    "#         from_left = int(str(x['Tooltip Phone Time']).find('Wrap Time'))+11\n",
    "#         to_right = str(x['Tooltip Phone Time']).find(' Hold Time')\n",
    "#         return int(x['Tooltip Phone Time'][from_left:to_right])\n",
    "#     except:\n",
    "#         return 0\n",
    "# def hold_time(x):\n",
    "#     try:\n",
    "#         from_left = int(str(x['Tooltip Phone Time']).find('Hold Time'))+10\n",
    "#         return int(x['Tooltip Phone Time'][from_left:])\n",
    "#     except:\n",
    "#         return 0    \n",
    "# ahtrp['Talk Time'] = ahtrp.apply(talk_time, axis=1)\n",
    "# ahtrp['Wrap Time'] = ahtrp.apply(wrap_time, axis=1)\n",
    "# ahtrp['Hold Time'] = ahtrp.apply(hold_time, axis=1)\n",
    "\n",
    "# def act_handling_time(x):\n",
    "#     if x['Eliminate Phone'] =='Phone':\n",
    "#         return x['Talk Time'] + x['Wrap Time'] + x['Hold Time']\n",
    "#     else:\n",
    "#         return x['Handling Time']\n",
    "\n",
    "# #add Act handling time\n",
    "# ahtrp['Act Handling Time'] = ahtrp.apply(act_handling_time, axis=1)\n",
    "# #Date to_datetime\n",
    "# ahtrp['Date'] = pd.to_datetime(ahtrp['Date'], format='mixed').dt.strftime('%Y-%m-%d')\n",
    "# ahtrp['PST_Start_Date'] = pd.to_datetime(ahtrp['PST_Start_Date'], format='mixed').dt.strftime('%Y-%m-%d')\n",
    "\n",
    "\n",
    "# #export to json\n",
    "# ahtrp.to_csv(r'C:\\Users\\dinhhoang.nguyen\\OneDrive - Concentrix Corporation\\WFM-internal\\Calculators\\Joey Nguyen\\py\\aht.csv', index=False)\n",
    "# ahtrp.to_json(r'C:\\Users\\dinhhoang.nguyen\\OneDrive - Concentrix Corporation\\WFM-internal\\DB\\filejson\\aht.json', orient='records')\n",
    "\n",
    "\n",
    "# # 3. FACT_Ticket\n",
    "\n",
    "# # 4. FACT_Schedule\n",
    "\n",
    "# # 5. DIM_Calendar\n",
    "\n",
    "# # 6. DIM_User\n",
    "\n",
    "# # 7. DIM_LOB\n",
    "\n",
    "# # 8. DIM_Tenure\n",
    "\n",
    "# # 9. TL\n",
    "\n",
    "# # 10. OM\n",
    "\n",
    "# # 11. CUIC Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 2. FACT_EPS Tableau\n",
    "\n",
    "# aht_eps = eps.drop(columns=['Session Login', 'Session Logout'])\n",
    "# ## subset schedule\n",
    "# aht_schedule = schedule[['Emp ID', 'Date', 'Shift', 'LOB', 'Shift_type']]\n",
    "# ## add schedule\n",
    "# aht_eps = pd.merge(aht_eps, aht_schedule, left_on = ['EID', 'Session login date'], right_on=['Emp ID', 'Date'], how='left')\n",
    "# ## change schedule Shift_type to Shift_type_date\n",
    "# aht_eps = aht_eps.rename(columns={'Shift_type': 'Shift_type_date'})\n",
    "# ## add column: current date - 1\n",
    "# aht_eps['Date-1'] = pd.to_datetime(aht_eps['Session login date'], format='mixed') - pd.Timedelta(1, 'd')\n",
    "# ## add shift type in date - 1\n",
    "# ## minimize schedule\n",
    "# aht_schedule = aht_schedule[['Emp ID', 'Date', 'Shift_type']]\n",
    "# ## convert date on schedule to datetime\n",
    "# aht_schedule['Date'] = pd.to_datetime(aht_schedule['Date'], format='mixed')\n",
    "# aht_eps = pd.merge(aht_eps, aht_schedule, left_on = ['EID', 'Date-1'], right_on=['Emp ID', 'Date'], how='left')\n",
    "# ## drop redundant cols\n",
    "# aht_eps = aht_eps.drop(columns=['Emp ID_x', 'Emp ID_y', 'Date_x', 'Date_y'])\n",
    "# aht_eps = aht_eps.rename(columns={'Shift_type': 'Shift_type_date-1'})\n",
    "# ## define current shift_type\n",
    "# conditions = (aht_eps['Shift_type_date']!= 'DS')&(aht_eps['Shift_type_date-1']=='NS')&(aht_eps['Session login time']<t(12,0,0))\n",
    "# aht_eps['Session login date'] = pd.to_datetime(aht_eps['Session login date'], format='mixed')\n",
    "# aht_eps['Session Date'] = np.where(conditions, aht_eps['Date-1'], aht_eps['Session login date'])\n",
    "\n",
    "# ## drop dedundant cols\n",
    "# aht_eps = aht_eps.drop(columns=['Date-1', 'Shift_type_date-1'])\n",
    "# aht_eps.info()\n",
    "\n",
    "# ## get master roster\n",
    "# aht_eps = pd.merge(aht_eps, aht_mr, left_on='EID', right_on='Employee_ID', how='left')\n",
    "# ## add TN\n",
    "# def TN(x):\n",
    "#     if x['Session Date'] - x['PST_Start_Date'] >= pd.Timedelta(days=90):\n",
    "#         return \"TN\"\n",
    "#     else:\n",
    "#         return \"NH\"\n",
    "# aht_eps['Tenure'] = aht_eps.apply(TN, axis=1)\n",
    "# ## rename shifttype\n",
    "# aht_eps = aht_eps.rename(columns={'Shift_type_date': 'Shifttype'})\n",
    "\n",
    "# ## export to json\n",
    "# aht_eps.to_json(r\"C:\\Users\\dinhhoang.nguyen.CONCENTRIX\\OneDrive - Concentrix Corporation\\WFM-internal\\DB\\filejson\\aht_eps.json\", orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 3. FACT_Ticket\n",
    "# aht_cpi = cpi\n",
    "\n",
    "# ## add LOB\n",
    "# aht_cpi_schedule = schedule[['Emp ID', 'Date', 'LOB']]\n",
    "# aht_cpi_schedule['Date'] = pd.to_datetime(aht_cpi_schedule['Date'], format = 'mixed')\n",
    "# aht_cpi = pd.merge(aht_cpi, aht_cpi_schedule, left_on = ['Employee_ID', 'Date'], right_on=['Emp ID', 'Date'], how='left')\n",
    "# aht_cpi = aht_cpi.drop(columns={'Emp ID'})\n",
    "\n",
    "# ## add Ted + CUIC + PST Start date\n",
    "# aht_eps_mr = masterroster[['Employee_ID', 'PST_Start_Date', 'CUIC Name', 'TED Name']]\n",
    "# aht_cpi = pd.merge(aht_cpi, aht_eps_mr, on = 'Employee_ID', how='left')\n",
    "# ## add Tenure\n",
    "# aht_cpi = aht_cpi.rename(columns={'Date': 'Session Date'})\n",
    "# aht_cpi['Tenure'] = aht_cpi.apply(TN, axis=1)\n",
    "# aht_cpi = aht_cpi.rename(columns={'Session Date': 'Date'})\n",
    "# ## export to json\n",
    "# aht_cpi.to_csv(r'C:\\Users\\dinhhoang.nguyen.CONCENTRIX\\OneDrive - Concentrix Corporation\\WFM-internal\\Calculators\\Joey Nguyen\\py\\aht_cpi.csv', index=False)\n",
    "# aht_cpi.to_json(r\"C:\\Users\\dinhhoang.nguyen.CONCENTRIX\\OneDrive - Concentrix Corporation\\WFM-internal\\DB\\filejson\\aht_cpi.json\", orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 4. FACT_Schedule\n",
    "# aht_schedule = schedule[['Emp ID', 'Date', 'Shift', 'LOB', 'Shift_type']]\n",
    "\n",
    "# ## add TED Name, CUIC\n",
    "# aht_schedule_mr = masterroster[['Employee_ID','CUIC Name', 'TED Name']]\n",
    "# aht_schedule = pd.merge(aht_schedule, aht_schedule_mr, left_on = 'Emp ID', right_on = 'Employee_ID', how='left')\n",
    "# ## export to json\n",
    "# aht_schedule.to_json(r'C:\\Users\\dinhhoang.nguyen.CONCENTRIX\\OneDrive - Concentrix Corporation\\WFM-internal\\DB\\filejson\\aht_schedule.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 5. DIM_Calendar\n",
    "# aht_calendar = aht_eps[['Session Date']].drop_duplicates(subset='Session Date')\n",
    "# aht_calendar.to_json(r'C:\\Users\\dinhhoang.nguyen.CONCENTRIX\\OneDrive - Concentrix Corporation\\WFM-internal\\DB\\filejson\\aht_calendar.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 6. DIM_User\n",
    "# aht_mr = masterroster\n",
    "# aht_mr.to_json(r'C:\\Users\\dinhhoang.nguyen.CONCENTRIX\\OneDrive - Concentrix Corporation\\WFM-internal\\DB\\filejson\\masterroster.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 7. DIM_LOB\n",
    "# aht_lob = schedule[['LOB']].drop_duplicates(subset='LOB')\n",
    "# aht_lob.to_json(r'C:\\Users\\dinhhoang.nguyen.CONCENTRIX\\OneDrive - Concentrix Corporation\\WFM-internal\\DB\\filejson\\dim_lob.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 8. DIM_Tenure\n",
    "# aht_tenure = {'Tenure': ['NH', 'TN']}\n",
    "# aht_tenure = pd.DataFrame.from_dict(aht_tenure)\n",
    "\n",
    "# aht_tenure.to_json(r\"C:\\Users\\dinhhoang.nguyen.CONCENTRIX\\OneDrive - Concentrix Corporation\\WFM-internal\\DB\\filejson\\dim_tenure.json\", orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 9. TL\n",
    "# aht_tl = tl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 10. CUIC Query\n",
    "# aht_cuic = cuic\n",
    "# aht_cuic = pd.merge(aht_cuic, schedule[['Emp ID', 'Date', 'LOB']], left_on=['Employee_ID', 'Session Date'], right_on=['Emp ID', 'Date'], how='left')\n",
    "# aht_cuic = aht_cuic.drop(columns={'Date_x', 'Date_y'})\n",
    "# ## add PST_Start_Date\n",
    "# aht_cuic_mr = masterroster[['Employee_ID', 'PST_Start_Date']]\n",
    "# aht_cuic = pd.merge(aht_cuic, aht_cuic_mr, on = 'Employee_ID', how='left')\n",
    "# aht_cuic['PST_Start_Date'] = pd.to_datetime(aht_cuic['PST_Start_Date'], format='mixed')\n",
    "# aht_cuic['Session Date'] = pd.to_datetime(aht_cuic['Session Date'], format='mixed')\n",
    "# aht_cuic.info()\n",
    "# ## add tenure\n",
    "# aht_cuic['Tenure'] = aht_cuic.apply(TN, axis=1)\n",
    "# ## export to json\n",
    "# aht_cuic.to_json(r'C:\\Users\\dinhhoang.nguyen.CONCENTRIX\\OneDrive - Concentrix Corporation\\WFM-internal\\DB\\filejson\\aht_cuic.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
