{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ae32ce3-3d55-4e23-815b-09b824609d00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime as dt\n",
    "from datetime import time as t\n",
    "from datetime import timedelta\n",
    "from pandas.tseries.offsets import MonthEnd\n",
    "from IPython.display import display\n",
    "import sqlite3\n",
    "import json\n",
    "import numpy as np\n",
    "import re\n",
    "from openpyxl import load_workbook\n",
    "import xlsxwriter\n",
    "import requests\n",
    "from requests.auth import HTTPBasicAuth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfb472b5-2204-461b-bf5f-9a8cfd867110",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FUNCTION TO IMPORT FOLDERS\n",
    "def import_csv(path):\n",
    "    raw = []\n",
    "    for file in os.listdir(path):\n",
    "        if file.endswith(\".csv\"):\n",
    "            file_path = os.path.join(path, file)\n",
    "            file_data = pd.read_csv(file_path)\n",
    "            file_data[\"filename\"] = file\n",
    "            raw.append(file_data)\n",
    "            final_raw = pd.concat(raw, ignore_index=True)\n",
    "    return final_raw\n",
    "    \n",
    "def import_xlsx(path, sheet_name):\n",
    "    raw = []\n",
    "    for file in os.listdir(path):\n",
    "        if file.endswith(\".xlsx\"):\n",
    "            file_path = os.path.join(path, file)\n",
    "            file_data = pd.read_excel(file_path, engine=\"openpyxl\", sheet_name = sheet_name)\n",
    "            file_data[\"filename\"] = file\n",
    "            raw.append(file_data)\n",
    "            final_raw = pd.concat(raw, ignore_index=True)\n",
    "    return final_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3d1b915-ff20-47d6-bb75-631d76a6ad75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# source\n",
    "personal_path = os.environ['USERPROFILE']\n",

    "if personal_path in ['C:\\\\Users\\\\dinhhoang.nguyen.CONCENTRIX', 'C:\\\\Users\\\\ADMIN']:\n",

    "    middle_path = r'OneDrive - Concentrix Corporation\\WFM-internal'\n",
    "else:\n",
    "    middle_path = r'Concentrix Corporation\\Dinh Hoang Nguyen - WFM-internal'\n",
    "user_credential = os.path.join(os.environ['USERPROFILE'], middle_path)\n",

    "# Adherence file path\n",
    "adherence_path=os.path.join(user_credential, r\"Dispatch files\\Adherence & Daily Tracking\\Adherence.xlsx\")\n",
    "# Revenue Estimation file path\n",
    "revenue_path=os.path.join(user_credential, r\"Dispatch files\\Adherence & Daily Tracking\\Revenue Estimation.xlsx\")\n",
    "# Daily Tracking file path\n",
    "dailytracking_path=os.path.join(user_credential, r\"Dispatch files\\Adherence & Daily Tracking\\Daily Tracking.xlsx\")\n",
    "# EPS path\n",
    "eps_path = os.path.join(user_credential, r\"Data\\EPS Tableau\\EPS Query\")\n",
    "# Budget path\n",
    "budget_path = os.path.join(user_credential, r\"Data\\Budget\")\n",
    "# Define billable\n",
    "define_path=os.path.join(user_credential, r\"Data\\Define.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "502761f8-debf-4c7b-b9f1-a7c100ff99d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT DEFINE\n",
    "define = pd.read_excel(define_path, sheet_name=\"DEFINE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d3d4d5a-7336-418e-91c7-fae0a4962133",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_23096\\242608621.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  masterroster_daily['Employee_ID'] = masterroster_daily['Employee_ID'].astype(\"Int64\")\n"
     ]
    }
   ],
   "source": [
    "# IMPORT MASTER ROSTER\n",
    "masterroster = pd.read_json(os.path.join(user_credential, r'DB\\filejson\\masterroster.json'))\n",
    "masterroster_daily=masterroster[['Employee_ID','TED Name', 'PST_Start_Date', 'Role','Booking Login ID','Full name','Wave #']]\n",
    "masterroster_daily['Employee_ID'] = masterroster_daily['Employee_ID'].astype(\"Int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5194b706-8b6c-4068-a856-25ec608a1896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT OT\n",
    "ot = pd.read_json(os.path.join(user_credential, r'DB\\filejson\\ot.json'))\n",
    "ot_daily=ot[['Emp ID','Date','OT']]\n",
    "ot_daily=ot_daily.groupby(['Emp ID','Date'], as_index=False).sum()\n",
    "ot_daily['Emp ID']=ot_daily['Emp ID'].astype(\"Int64\")\n",
    "ot_daily['Date'] = pd.to_datetime(ot_daily['Date'], format=\"mixed\").dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91103c03-eb6a-45fb-ac19-80c75abbcfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT RAMCO\n",
    "ramco_daily = pd.read_json(os.path.join(user_credential, r'DB\\filejson\\ramco.json'))\n",
    "ramco_daily['Date']=pd.to_datetime(ramco_daily['Date'],format='mixed').dt.date\n",
    "ramco_daily['EID'] = ramco_daily['EID'].astype(\"Int64\")\n",
    "ramco_daily['Value']=ramco_daily['Value'].fillna(0)\n",
    "ramco_daily=ramco_daily.rename(columns={'Value':'RAMCO'})\n",
    "ramco_ot_daily=pd.merge(ramco_daily,ot_daily,left_on=['EID','Date'],right_on=['Emp ID','Date'],how='left')\n",
    "def OTREGISTERED_func(x):\n",
    "    if x['RAMCO'] =='PO' or x['RAMCO'] =='PH' :\n",
    "        return x['OT']/24\n",
    "    elif x['RAMCO'] =='WO' or x['RAMCO'] =='AL' or x['RAMCO'] =='SL' or x['RAMCO'] =='HO':\n",
    "        return 0 \n",
    "    elif x['RAMCO'] =='HAL' :\n",
    "        return 3.75/24\n",
    "    else:\n",
    "        return x['OT']/24+7.5/24\n",
    "ramco_ot_daily['OT Registered'] = ramco_ot_daily.apply(OTREGISTERED_func, axis=1)\n",
    "ramco_ot_daily=ramco_ot_daily[['EID','Date','RAMCO','OT','OT Registered']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b2075d5-e146-4373-8ddb-a9d658ec38ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT RAMCOOT\n",
    "ramcoot = pd.read_json(os.path.join(user_credential, r'DB\\filejson\\ramcoot.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab1aee0d-54e8-46d2-90bf-d55a28e00126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT SCHEDULE\n",
    "schedule = pd.read_json(os.path.join(user_credential, r'DB\\filejson\\schedule.json'))\n",
    "schedule['Date']=pd.to_datetime(schedule['Date']).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "948f082a-2766-4f51-a409-43b873183d92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#IMPORT CUIC\n",
    "cuic = pd.read_json(os.path.join(user_credential, r'DB\\filejson\\cuic.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6f12ca0-a388-4e30-9183-1b318dcbbc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORT CPI\n",
    "cpi = pd.read_json(os.path.join(user_credential, r'DB\\filejson\\cpi.json'))\n",
    "# Clean\n",
    "cpi_daily=cpi[['Staff Name', 'Employee_ID', 'Date', 'Channel', 'Number of Records']]\n",
    "condition_phone=(cpi['Channel']=='phone')\n",
    "cpi_daily['Phone Cases #']= np.where(condition_phone, cpi['Number of Records'], 0)\n",
    "condition_nonphone=(cpi['Channel']=='email')|(cpi['Channel']=='messaging')|(cpi['Channel']=='Live Chat')\n",
    "cpi_daily['Non-phone Cases #']= np.where(condition_nonphone, cpi['Number of Records'], 0)\n",
    "cpi_daily=cpi_daily.rename(columns={'Number of Records':'Cases #'})\n",
    "cpi_daily=cpi_daily[['Date','Employee_ID','Cases #','Phone Cases #','Non-phone Cases #']]\n",
    "cpi_daily['Date']=pd.to_datetime(cpi_daily['Date'],format='mixed').dt.date\n",
    "cpi_daily=cpi_daily.groupby(['Employee_ID','Date'], as_index=False).sum()\n",
    "cpi_daily['Employee_ID'] = cpi_daily['Employee_ID'].astype(\"Int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2aa144ad-6215-4c85-8b10-288f5e0beece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT TL\n",
    "tl = pd.read_json(os.path.join(user_credential, r'DB\\filejson\\tl.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e5c8dd2-3ef7-4d30-82d9-3cb44321f1ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_23096\\508952134.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  exception_daily['Exception request \\n(Minute)'] = exception_daily['Exception request \\n(Minute)'].astype(\"float\")\n",
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_23096\\508952134.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  exception_daily['Exception request \\n(Minute)']=exception['Exception request \\n(Minute)'].fillna(0)\n"
     ]
    }
   ],
   "source": [
    "# IMPORT EXCEPTION\n",
    "exception = pd.read_json(os.path.join(user_credential, r'DB\\filejson\\exceptional_hrs.json'))\n",
    "exception['Date']=pd.to_datetime(exception['Date'],format='mixed').dt.date\n",
    "exception_daily=exception[['Emp ID','Date','Exception request \\n(Minute)']]\n",
    "exception_daily['Exception request \\n(Minute)'] = exception_daily['Exception request \\n(Minute)'].astype(\"float\")\n",
    "exception_daily['Exception request \\n(Minute)']=exception['Exception request \\n(Minute)'].fillna(0)\n",
    "exception_daily=exception_daily.rename(columns={'Exception request \\n(Minute)':'Exception request'})\n",
    "exception_daily=exception_daily.groupby(['Emp ID','Date'], as_index=False).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae4091d7-c48d-44ba-9d0e-99ba635b840a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#IMPORT EPS\n",
    "eps_raw = import_csv(path = eps_path)\n",
    "eps = eps_raw.drop(columns=['Index', 'filename', 'Date'])\n",
    "eps['Session Login'] = pd.to_datetime(eps['Session Login'], errors='coerce')\n",
    "eps['Session Login'] = eps['Session Login'].dt.tz_localize('Europe/Berlin', ambiguous=True).dt.tz_convert('UTC')\n",
    "eps['Session Logout'] = pd.to_datetime(eps['Session Logout'], errors='coerce')\n",
    "eps['Session Logout'] = eps['Session Logout'].dt.tz_localize('Europe/Berlin', ambiguous=True).dt.tz_convert('UTC')\n",
    "eps['Session Login'] =pd.to_datetime(eps['Session Login'], errors='coerce').dt.tz_localize(None)\n",
    "eps['Session Logout'] =pd.to_datetime(eps['Session Logout'], errors='coerce').dt.tz_localize(None)\n",
    "\n",
    "eps['Session login VN'] = pd.to_datetime(eps['Session Login'], format ='mixed') + pd.Timedelta(hours=7)\n",
    "eps['Session logout VN'] = pd.to_datetime(eps['Session Logout'], format ='mixed') + pd.Timedelta(hours=7)\n",
    "eps['Session login date'] = pd.to_datetime(eps['Session login VN'], format ='mixed').dt.date\n",
    "eps['Session login time'] = pd.to_datetime(eps['Session login VN'], format ='mixed').dt.time\n",
    "eps['Session login hour'] = pd.to_datetime(eps['Session login VN'], format ='mixed').dt.strftime('%H')\n",
    "eps['Session logout date'] = pd.to_datetime(eps['Session logout VN'], format ='mixed').dt.date\n",
    "eps['Session logout time'] = pd.to_datetime(eps['Session logout VN'], format ='mixed').dt.time\n",
    "eps['Session logout hour'] = pd.to_datetime(eps['Session logout VN'], format ='mixed').dt.strftime('%H')\n",
    "eps['Session login hour']=eps['Session login hour'].astype(\"Int64\")\n",
    "eps['Session logout hour']=eps['Session logout hour'].astype(\"Int64\")\n",
    "nighthour_23h=\"23:00:00\"\n",
    "nighthour_7h=\"07:00:00\"\n",
    "nighthour_24h=\"00:00:00\"\n",
    "eps['Session login 23h'] = pd.to_datetime(eps['Session login date'].astype(str) + nighthour_23h, format = '%Y-%m-%d%H:%M:%S', errors='coerce')\n",
    "eps['Session logout 23h'] = pd.to_datetime(eps['Session logout date'].astype(str) + nighthour_23h, format = '%Y-%m-%d%H:%M:%S', errors='coerce')\n",
    "eps['Session login 7h'] = pd.to_datetime(eps['Session login date'].astype(str) + nighthour_7h, format = '%Y-%m-%d%H:%M:%S', errors='coerce')\n",
    "eps['Session logout 7h'] = pd.to_datetime(eps['Session logout date'].astype(str) + nighthour_7h, format = '%Y-%m-%d%H:%M:%S', errors='coerce')\n",
    "eps['Session login 24h'] = pd.to_datetime(eps['Session login date'].astype(str) + nighthour_24h, format = '%Y-%m-%d%H:%M:%S', errors='coerce')+pd.Timedelta(days=1)\n",
    "eps['Session logout 24h'] = pd.to_datetime(eps['Session logout date'].astype(str) + nighthour_24h, format = '%Y-%m-%d%H:%M:%S', errors='coerce')+pd.Timedelta(days=0)\n",
    "eps=eps[eps['EID'].isnull() == False]\n",
    "def night_func(x):\n",
    "    if (x['Session login hour']>=23 and x['Session logout hour']>=23) or (x['Session login hour']>=23 and x['Session logout hour']<7) or (x['Session login hour']<7 and x['Session logout hour']<7):\n",
    "        return x['Total Time']\n",
    "    elif x['Session login hour']>=23 and x['Session logout hour']>=7:\n",
    "        if ((x['Session login 24h']-x['Session login VN'])+pd.Timedelta(hours=7)).total_seconds()<x['Total Time']:\n",
    "            return ((x['Session login 24h']-x['Session login VN'])+pd.Timedelta(hours=7)).total_seconds()\n",
    "        else :\n",
    "            return x['Total Time']\n",
    "    elif x['Session login hour']<7 and x['Session logout hour']>=7 and x['Session logout hour']<23:\n",
    "        if (x['Session login 7h']-x['Session login VN']).total_seconds()<x['Total Time']:\n",
    "            return (x['Session login 7h']-x['Session login VN']).total_seconds()\n",
    "        else :\n",
    "            return x['Total Time']\n",
    "    elif x['Session login hour']<7 and x['Session logout hour']>=23:\n",
    "        if ((x['Session login 7h']-x['Session login VN'])+(x['Session logout VN']-x['Session logout 23h'])).total_seconds()<x['Total Time']:\n",
    "            return ((x['Session login 7h']-x['Session login VN'])+(x['Session logout VN']-x['Session logout 23h'])).total_seconds()\n",
    "        else :\n",
    "            return x['Total Time']\n",
    "    elif x['Session login hour']<23 and x['Session logout hour']>=23:\n",
    "        if (x['Session logout VN']-x['Session logout 23h']).total_seconds()<x['Total Time']:\n",
    "            return (x['Session logout VN']-x['Session logout 23h']).total_seconds()\n",
    "        else :\n",
    "            return x['Total Time']\n",
    "    elif x['Session login hour']<23 and x['Session logout hour']<7:\n",
    "        if (x['Session logout VN']-x['Session login 23h']).total_seconds()<x['Total Time']:\n",
    "            return (x['Session logout VN']-x['Session login 23h']).total_seconds()\n",
    "        else :\n",
    "            return x['Total Time']\n",
    "    else:\n",
    "        return (x['Session login VN']-x['Session login VN']).total_seconds()\n",
    "eps['night']= eps.apply(night_func, axis=1)\n",
    "\n",
    "eps = eps.drop(columns=['Session login VN', 'Session logout VN', 'Username', 'manager_username', 'sitecode', 'Session Time',\n",
    "                        'Session login hour','Session logout hour','Session login 23h','Session login 7h','Session login 24h'\n",
    "                       ,'Session logout 23h','Session logout 7h','Session logout 24h'])\n",
    "eps['EID']=eps['EID'].astype(\"Int64\")\n",
    "# 1. Merge EPS and Schedule on EID and Date to get Shift_type, Shift, Session Date and Duration and change Date into VN Date\n",
    "eps_schedule=pd.merge(eps, schedule, left_on=['EID','Session login date'], right_on=['Emp ID','Date'], how='left')\n",
    "eps_schedule=eps_schedule[['EID','Session Login','Session Logout','BPE Code','Total Time','Session login date','Session login time',\n",
    "                           'Session logout date','Session logout time','LOB','Shift_type','Shift','night']]\n",
    "eps_schedule['Date-1']=pd.to_datetime(eps_schedule['Session login date'], format ='mixed') - pd.Timedelta(1,\"d\")\n",
    "eps_schedule['Date-1']=pd.to_datetime(eps_schedule['Date-1'], format ='mixed').dt.date\n",
    "eps_schedule = pd.merge(eps_schedule, schedule, left_on=['EID','Date-1'], right_on =['Emp ID','Date'], how='left')\n",
    "mytime=t(12,0,0)\n",
    "condition=(eps_schedule['Shift_type_x']!='DS')&(eps_schedule['Shift_type_y']=='NS')&(eps_schedule['Session login time']<mytime)\n",
    "eps_schedule=eps_schedule.rename(columns={'LOB_x': 'LOB','Shift_type_x':'Shift_type','Shift_x':'Shift'})\n",
    "eps_schedule['Session Date'] = np.where(condition, eps_schedule['Date-1'], eps_schedule['Session login date'])\n",
    "eps_schedule['Duration']=eps_schedule['Total Time']/86400\n",
    "eps_schedule['night']=eps_schedule['night']/86400\n",
    "eps_schedule=eps_schedule[['EID','Session Login','Session Logout','BPE Code','Total Time','Session login date','Session login time',\n",
    "                           'Session logout date','Session logout time','LOB','Session Date','Duration','night']]\n",
    "eps_schedule = pd.merge(eps_schedule, schedule, left_on=['EID','Session Date'], right_on =['Emp ID','Date'], how='left')\n",
    "eps_schedule=eps_schedule.rename(columns={'LOB_y': 'LOB'})\n",
    "eps_schedule=eps_schedule[['EID','Session Login','Session Logout','BPE Code','Total Time','Session login date','Session login time',\n",
    "                           'Session logout date','Session logout time','LOB','Shift_type','Session Date','Duration','Shift','night']]\n",
    "\n",
    "# 2. Add Week & Day Name and BPE Code Duration and then group by EID, Session Date\n",
    "eps_dailytracking=eps_schedule\n",
    "eps_dailytracking['Session Date'] = pd.to_datetime(eps_dailytracking['Session Date'],errors ='coerce')\n",
    "# Add Week & Day Name column\n",
    "eps_dailytracking['Week'] = eps_dailytracking['Session Date'].dt.strftime('%Y%W')\n",
    "eps_dailytracking['Day Name'] = eps_dailytracking['Session Date'].dt.day_name()\n",
    "\n",
    "# Add Picklist,Ready or Talking,..BPE Code\n",
    "condition_picklist=(eps_dailytracking['BPE Code']=='Picklist - off Phone')\n",
    "eps_dailytracking['Picklist - off Phone']= np.where(condition_picklist, eps_dailytracking['Duration'], 0)\n",
    "\n",
    "condition_readyortalking=(eps_dailytracking['BPE Code']=='Ready or Talking')\n",
    "eps_dailytracking['Ready or Talking']= np.where(condition_readyortalking, eps_dailytracking['Duration'], 0)\n",
    "\n",
    "condition_finalizecall=(eps_dailytracking['BPE Code']=='Finalize Call')\n",
    "eps_dailytracking['Finalize Call']= np.where(condition_finalizecall, eps_dailytracking['Duration'], 0)\n",
    "\n",
    "condition_meeting=(eps_dailytracking['BPE Code']=='Meeting')\n",
    "eps_dailytracking['Meeting']= np.where(condition_meeting, eps_dailytracking['Duration'], 0)\n",
    "\n",
    "condition_training=(eps_dailytracking['BPE Code']=='Training')\n",
    "eps_dailytracking['Training']= np.where(condition_training, eps_dailytracking['Duration'], 0)\n",
    "\n",
    "condition_newhiretraining=(eps_dailytracking['BPE Code']=='New Hire Training')\n",
    "eps_dailytracking['New Hire Training']= np.where(condition_newhiretraining, eps_dailytracking['Duration'], 0)\n",
    "\n",
    "condition_lunch=(eps_dailytracking['BPE Code']=='Lunch')\n",
    "eps_dailytracking['Lunch Time']= np.where(condition_lunch, eps_dailytracking['Duration'], 0)\n",
    "\n",
    "condition_break=(eps_dailytracking['BPE Code']=='Break')\n",
    "eps_dailytracking['Break Time']= np.where(condition_break, eps_dailytracking['Duration'], 0)\n",
    "\n",
    "condition_rona=(eps_dailytracking['BPE Code']=='RONA')\n",
    "eps_dailytracking['RONA']= np.where(condition_rona, eps_dailytracking['Duration'], 0)\n",
    "\n",
    "condition_othercodecph=(eps_dailytracking['BPE Code']=='Unscheduled Picklist')|(eps_dailytracking['BPE Code']=='Payment Processing')|(eps_dailytracking['BPE Code']=='Social Media')|(eps_dailytracking['BPE Code']=='Mass Issue')|(eps_dailytracking['BPE Code']=='Project')\n",
    "eps_dailytracking['Other code CPH']= np.where(condition_othercodecph, eps_dailytracking['Duration'], 0)\n",
    "\n",
    "condition_others=(eps_dailytracking['BPE Code']!='Picklist - off Phone') & (eps_dailytracking['BPE Code']!='Ready or Talking') & (eps_dailytracking['BPE Code']!='Meeting')& (eps_dailytracking['BPE Code']!='Training') & (eps_dailytracking['BPE Code']!='Lunch') & (eps_dailytracking['BPE Code']!='Break')& (eps_dailytracking['BPE Code']!='New Hire Training')& (eps_dailytracking['BPE Code']!='RONA')\n",
    "eps_dailytracking['Other codes']= np.where(condition_others, eps_dailytracking['Duration'], 0)\n",
    "\n",
    "condition_nightproductivehours_x=(eps_dailytracking['BPE Code']=='Picklist - off Phone')\n",
    "eps_dailytracking['Night Picklist - off Phone']= np.where(condition_nightproductivehours_x, eps_dailytracking['night'], 0)\n",
    "\n",
    "condition_nightproductivehours_y=(eps_dailytracking['BPE Code']=='Ready or Talking')\n",
    "eps_dailytracking['Night Ready or Talking']= np.where(condition_nightproductivehours_y, eps_dailytracking['night'], 0)\n",
    "\n",
    "condition_nightproductivehours_z=(eps_dailytracking['BPE Code']=='Finalize Call')\n",
    "eps_dailytracking['Night Finalize Call']= np.where(condition_nightproductivehours_z, eps_dailytracking['night'], 0)\n",
    "\n",
    "condition_nightdowntimehours_x=(eps_dailytracking['BPE Code']=='Training')\n",
    "eps_dailytracking['Night Training']= np.where(condition_nightdowntimehours_x, eps_dailytracking['night'], 0)\n",
    "\n",
    "condition_nightdowntimehours_y=(eps_dailytracking['BPE Code']=='Meeting')\n",
    "eps_dailytracking['Night Meeting']= np.where(condition_nightdowntimehours_y, eps_dailytracking['night'], 0)\n",
    "\n",
    "eps_dailytracking['Night Productive Hours']=eps_dailytracking['Night Picklist - off Phone']+eps_dailytracking['Night Ready or Talking']+eps_dailytracking['Night Finalize Call']\n",
    "eps_dailytracking['Night Downtime Hours']=eps_dailytracking['Night Training']+eps_dailytracking['Night Meeting']\n",
    "eps_dailytracking=eps_dailytracking[['EID','LOB','Shift_type','Session Date','Duration','Shift','Week','Day Name',\n",
    "                                     'Picklist - off Phone','Ready or Talking','Meeting','Training','New Hire Training','Lunch Time','Break Time',\n",
    "                                     'Other codes','Night Productive Hours','Night Downtime Hours','Finalize Call','Other code CPH','RONA']]\n",
    "eps_dailytracking=eps_dailytracking.groupby(['EID','LOB','Shift_type','Session Date','Shift','Week','Day Name'], as_index=False).sum()\n",
    "eps_dailytracking['Session Date']=pd.to_datetime(eps_dailytracking['Session Date'],format='mixed').dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57cfa0b9-130f-45db-8143-8237cb2e12b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Login_Logout Time\n",
    "login_logout=eps_schedule[['EID','Session Date','Shift_type','Session login time','Session logout time']]\n",
    "\n",
    "# Login_Logout Time: filter !=NS\n",
    "login_logout_ds=login_logout.loc[(login_logout['Shift_type'] !='NS')]\n",
    "login_logout_ds=login_logout_ds.groupby(['EID','Session Date','Shift_type'], as_index=False).agg(min=('Session login time', 'min'), max=('Session logout time', 'max'))\n",
    "login_logout_ds=login_logout_ds.rename(columns={'min':'Login Time','max':'Logout Time'})\n",
    "\n",
    "# Login_Logout Time: filter NS (condition: login sau 15h & logout >15h)\n",
    "validate_time=t(15,0,0)\n",
    "login_ns=login_logout.loc[(login_logout['Shift_type'] =='NS')&(login_logout['Session login time'] > validate_time)]\n",
    "login_ns=login_ns.groupby(['EID','Session Date','Shift_type'], as_index=False).agg(min=('Session login time', 'min'))\n",
    "logout_ns=login_logout.loc[(login_logout['Shift_type'] =='NS')&(login_logout['Session logout time'] < validate_time)]\n",
    "logout_ns=logout_ns.groupby(['EID','Session Date','Shift_type'], as_index=False).agg(max=('Session logout time', 'max'))\n",
    "login_logout_ns=pd.merge(login_ns,logout_ns,left_on=['EID','Session Date','Shift_type'],right_on=['EID','Session Date','Shift_type'],how='left')\n",
    "login_logout_ns=login_logout_ns.rename(columns={'min':'Login Time','max':'Logout Time'})\n",
    "\n",
    "# Login_Logout Time:Combine DS & NS login logout time\n",
    "login_logout=pd.concat([login_logout_ds, login_logout_ns], ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98ac5314-490c-4fa7-972e-9aa7472b8a0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Daily tracking\n",
    "# Merge CPI to get Case #\n",
    "dailytracking=pd.merge(eps_dailytracking,cpi_daily,left_on=['EID','Session Date'],right_on=['Employee_ID','Date'],how='left')\n",
    "dailytracking=dailytracking.drop(columns=['Employee_ID','Date'])\n",
    "\n",
    "# Merge Exception to get Exception minute\n",
    "dailytracking=pd.merge(dailytracking,exception_daily,left_on=['EID','Session Date'],right_on=['Emp ID','Date'],how='left')\n",
    "dailytracking=dailytracking.drop(columns=['Emp ID','Date'])\n",
    "\n",
    "# Merge Ramco & OT to get Ramco, OT, OT Registered\n",
    "dailytracking=pd.merge(dailytracking,ramco_ot_daily,left_on=['EID','Session Date'],right_on=['EID','Date'],how='left')\n",
    "dailytracking=dailytracking.drop(columns=['Date'])\n",
    "\n",
    "# Merge Master Roster to get Full name, Booking Login ID, TED Name, Wave #, Employee_ID\n",
    "dailytracking=pd.merge(dailytracking,masterroster_daily,left_on=['EID'],right_on=['Employee_ID'],how='left')\n",
    "dailytracking=dailytracking.drop(columns=['Employee_ID'])\n",
    "\n",
    "# Merge TL to get Supervisor\n",
    "dailytracking=pd.merge(dailytracking,tl,left_on=['EID'],right_on=['Emp ID'],how='left')\n",
    "dailytracking=dailytracking.drop(columns=['Emp ID'])\n",
    "\n",
    "# Merge Login Logout Time\n",
    "login_logout['Session Date']=pd.to_datetime(login_logout['Session Date']).dt.date\n",
    "dailytracking=pd.merge(dailytracking,login_logout,left_on=['EID','Session Date','Shift_type'],right_on=['EID','Session Date','Shift_type'],how='left')\n",
    "\n",
    "dailytracking['Cases #']=dailytracking['Cases #'].fillna(0)\n",
    "dailytracking['Phone Cases #']=dailytracking['Phone Cases #'].fillna(0)\n",
    "dailytracking['Non-phone Cases #']=dailytracking['Non-phone Cases #'].fillna(0)\n",
    "dailytracking['RAMCO']=dailytracking['RAMCO'].fillna(0)\n",
    "dailytracking['OT']=dailytracking['OT'].fillna(0)\n",
    "dailytracking['Exception request']=dailytracking['Exception request'].fillna(0)\n",
    "\n",
    "dailytracking['Productive hours']=dailytracking['Picklist - off Phone']+dailytracking['Ready or Talking']+dailytracking['Finalize Call']\n",
    "dailytracking['Downtime']=dailytracking['Meeting']+dailytracking['Training']\n",
    "dailytracking['Delivery hours']=dailytracking['Productive hours']+dailytracking['Downtime']+dailytracking['New Hire Training']\n",
    "dailytracking=dailytracking.rename(columns={'Duration':'Staffed Hours'})\n",
    "dailytracking['CPH - Agent']=dailytracking['Cases #']/((dailytracking['Productive hours']+dailytracking['RONA']+dailytracking['Other code CPH'])*24)\n",
    "dailytracking['Phone CPH']=dailytracking['Phone Cases #']/((dailytracking['Ready or Talking']+dailytracking['Finalize Call'])*24)\n",
    "dailytracking['Non-phone CPH']=dailytracking['Non-phone Cases #']/(dailytracking['Picklist - off Phone']*24)\n",
    "dailytracking['Picklist %']=(dailytracking['Picklist - off Phone']/dailytracking['Delivery hours']).mul(100).round(2).astype(str).add('%')\n",
    "def standardtime_func(x):\n",
    "    if x['RAMCO'] =='PR' or x['RAMCO'] =='PH' :\n",
    "        return x['OT']+8\n",
    "    elif x['RAMCO'] =='PO':\n",
    "        return x['OT']\n",
    "    else:\n",
    "        return 0\n",
    "dailytracking['Standard time']= dailytracking.apply(standardtime_func, axis=1)\n",
    "dailytracking['Extra rendered hours']=(dailytracking['Delivery hours']+dailytracking['Break Time']+(dailytracking['Exception request']/(60*24)))*24-dailytracking['Standard time']\n",
    "def approvedovertime_func(x):\n",
    "    if x['OT']<=0:\n",
    "        return 0\n",
    "    elif x['RAMCO'] not in ['PR','PO','PH']:\n",
    "        return 0\n",
    "    elif x['Extra rendered hours'] >= 0:\n",
    "        return  x['OT']\n",
    "    elif (x['OT']+x['Extra rendered hours']-0.25) < 0 :\n",
    "        return  0\n",
    "    else:         \n",
    "        return x['OT']+x['Extra rendered hours']-0.25\n",
    "dailytracking['Approved Overtime']= dailytracking.apply(approvedovertime_func, axis=1)\n",
    "dailytracking['Approved Overtime']=dailytracking['Approved Overtime'].round(0)\n",
    "def convert_to_hours(delta):\n",
    "    total_seconds = delta.total_seconds()\n",
    "    hours = str(int(total_seconds // 3600)).zfill(2)\n",
    "    minutes = str(int((total_seconds % 3600) // 60)).zfill(2)\n",
    "    seconds = str(int(total_seconds % 60)).zfill(2)\n",
    "    return f\"{hours}:{minutes}:{seconds}\"\n",
    "validate_date=dt(1970,1,1,0,0,0)\n",
    "dailytracking['Day Productive Hours']=dailytracking['Productive hours']-dailytracking['Night Productive Hours']\n",
    "dailytracking['Day Downtime Hours']=dailytracking['Downtime']-dailytracking['Night Downtime Hours']\n",
    "dailytracking=dailytracking[['Week','Session Date','Day Name','EID','Full name','Booking Login ID','TED Name','Wave #','RAMCO','LOB','Shift','Shift_type',\n",
    "                             'Supervisor','Login Time','Logout Time','Picklist - off Phone','Ready or Talking','Productive hours','Meeting','Training',\n",
    "                             'Downtime','Delivery hours','Lunch Time','Break Time','RONA','Other codes','Staffed Hours','Exception request','Cases #',\n",
    "                             'CPH - Agent','Phone Cases #','Phone CPH','Non-phone Cases #','Non-phone CPH','Picklist %','OT','Approved Overtime','New Hire Training',\n",
    "                             'Night Productive Hours','Night Downtime Hours','Day Productive Hours','Day Downtime Hours']]\n",
    "dailytracking['Session Date'] = pd.to_datetime(dailytracking['Session Date'])\n",
    "dailytracking=dailytracking.sort_values(by='Session Date',ascending=True)\n",
    "#ATD MM\n",
    "def atdmm_shift_func(x):\n",
    "    if x['Shift'] in ['0400-1300','0500-1400','0600-1500','0700-1600','0800-1700','0900-1800','1000-1900','1100-2000',\n",
    "                      '1200-2100','1300-2200','1400-2300','1500-2400','1600-0100','1700-0200',\n",
    "                      '1800-0300','1900-0400','2000-0500','2100-0600','2200-0700','HAL','Training','PEGA']:\n",
    "        return 'WORK'\n",
    "    else:         \n",
    "        return 'OFF'\n",
    "dailytracking['ATD MM Shift']= dailytracking.apply(atdmm_shift_func, axis=1)\n",
    "def atdmm_ramco_func(x):\n",
    "    if x['RAMCO'] in ['PH','PO','PR','PI','POWH','HAL','HLWP','HSL']:\n",
    "        return 'WORK'\n",
    "    else:         \n",
    "        return 'OFF'\n",
    "dailytracking['ATD MM Ramco']= dailytracking.apply(atdmm_ramco_func, axis=1)\n",
    "def atdmm_func(x):\n",
    "    if x['EID'] =='':\n",
    "        return ''\n",
    "    elif x['RAMCO']=='PO' and x['Shift']=='OFF':\n",
    "        return 'Valid'   \n",
    "    elif x['RAMCO']=='' and x['Shift']!='':\n",
    "        return '' \n",
    "    elif x['RAMCO']!='' and x['Shift']=='':\n",
    "        return ''     \n",
    "    elif x['RAMCO']=='' and x['Shift']=='':\n",
    "        return 'Valid'  \n",
    "    elif x['RAMCO']=='AB' and x['ATD MM Shift']=='WORK':\n",
    "        return 'Valid' \n",
    "    elif x['ATD MM Ramco'] == x['ATD MM Shift']:\n",
    "        return 'Valid' \n",
    "    else:         \n",
    "        return 'ATD MM'\n",
    "dailytracking['ATD MM']= dailytracking.apply(atdmm_func, axis=1)\n",
    "#PO (MTD)\n",
    "def po_func(x):\n",
    "    if x['RAMCO'] in ['PO']:\n",
    "        return 1\n",
    "    else:         \n",
    "        return 0\n",
    "dailytracking['PO']= dailytracking.apply(po_func, axis=1)\n",
    "dailytracking['Session Date'] = pd.to_datetime(dailytracking['Session Date'])\n",
    "dailytracking['#PO (MTD)'] = dailytracking.groupby([dailytracking['Session Date'].dt.to_period('m'),'EID'])['PO'].cumsum()\n",
    "#POHrs (MTD)\n",
    "def pohour_func(x):\n",
    "    if x['RAMCO'] in ['PO']:\n",
    "        return x['Approved Overtime']\n",
    "    else:         \n",
    "        return 0\n",
    "dailytracking['PO Hour']= dailytracking.apply(pohour_func, axis=1)\n",
    "dailytracking['POHrs(MTD)'] = dailytracking.groupby([dailytracking['Session Date'].dt.to_period('m'),'EID'])['PO Hour'].cumsum()\n",
    "#OT (MTD)\n",
    "dailytracking['OT (MTD)'] = dailytracking.groupby([dailytracking['Session Date'].dt.to_period('m'),'EID'])['Approved Overtime'].cumsum()\n",
    "# Final OT\n",
    "def finalOT_func(x):\n",
    "    if x['OT (MTD)'] <= 40 :\n",
    "        return x['Approved Overtime']\n",
    "    else:         \n",
    "        return 0\n",
    "dailytracking['Final OT']= dailytracking.apply(finalOT_func, axis=1)\n",
    "#OT OTP\n",
    "def OT_OTP_func(x):\n",
    "    if x['OT (MTD)'] > 40 :\n",
    "        return x['Approved Overtime']\n",
    "    else:         \n",
    "        return 0\n",
    "dailytracking['OT OTP']= dailytracking.apply(OT_OTP_func, axis=1)\n",
    "#OT-LessDelivery\n",
    "def OT_LessDelivery_func(x):\n",
    "    if x['Approved Overtime'] > x['OT'] :\n",
    "        return 1\n",
    "    else:         \n",
    "        return 0\n",
    "dailytracking['OT-LessDelivery']= dailytracking.apply(OT_LessDelivery_func, axis=1)\n",
    "#OT>4Hrs On PR & OT>8Hrs On PO\n",
    "def OT_on_PO_func(x):\n",
    "    if x['RAMCO'] =='PR' and x['Approved Overtime']>4 :\n",
    "        return 1\n",
    "    elif x['RAMCO'] =='PO' and x['Approved Overtime']>8 :\n",
    "        return 1 \n",
    "    else:         \n",
    "        return 0\n",
    "dailytracking['OT>4Hrs On PR \\n OT>8Hrs On PO']= dailytracking.apply(OT_on_PO_func, axis=1)\n",
    "#PR<8.75\n",
    "def PR_func(x):\n",
    "    if (x['Staffed Hours']*24 + x['Exception request']*24)<8.75 :\n",
    "        return 1\n",
    "    else:         \n",
    "        return 0\n",
    "dailytracking['PR < 8.75']= dailytracking.apply(PR_func, axis=1)\n",
    "#PR (MTD)\n",
    "def PRMTD_func(x):\n",
    "    if x['EID']=='' :\n",
    "        return 0\n",
    "    else:         \n",
    "        return 1\n",
    "dailytracking['PR count']= dailytracking.apply(PRMTD_func, axis=1)\n",
    "dailytracking['PR (MTD)'] = dailytracking.groupby([dailytracking['Session Date'].dt.to_period('m'),'EID'])['PR count'].cumsum()\n",
    "#Low PerF\n",
    "def LowPerF_func(x):\n",
    "    if x['CPH - Agent']<2 :\n",
    "        return 1\n",
    "    else:         \n",
    "        return 0\n",
    "dailytracking['Low PerF']= dailytracking.apply(LowPerF_func, axis=1)\n",
    "#Login On Dayoff\n",
    "def LoginonDayoff_func(x):\n",
    "    if x['ATD MM Shift'] =='OFF' and x['ATD MM Ramco']=='OFF' and x['Staffed Hours']>0:\n",
    "        return 1\n",
    "    else:         \n",
    "        return 0\n",
    "dailytracking['Login on Dayoff']= dailytracking.apply(LoginonDayoff_func, axis=1)\n",
    "\n",
    "#Not Logout\n",
    "import re\n",
    "def split1_it(startshift):\n",
    "    return re.findall('(\\d{4})-', startshift)\n",
    "dailytracking['Shift1'] = dailytracking['Shift'].apply(split1_it)\n",
    "dailytracking['Shift1']=dailytracking['Shift1'].astype(str)\n",
    "dailytracking['Shift1'] = dailytracking['Shift1'] .str.replace(\"['\", \"\")\n",
    "dailytracking['Shift1'] =dailytracking['Shift1'] .str.replace(\"']\", \"\")\n",
    "dailytracking['Shift1'] =dailytracking['Shift1'] .str.replace(\"00\", \"\")\n",
    "dailytracking['Shift1'] =dailytracking['Shift1'] .str.replace(\"[]\", '')\n",
    "def split_it(endshift):\n",
    "    return re.findall('\\d{4}-(\\d{4})', endshift)\n",
    "dailytracking['Shift2'] = dailytracking['Shift'].apply(split_it)\n",
    "dailytracking['Shift2']=dailytracking['Shift2'].astype(str)\n",
    "dailytracking['Shift2'] = dailytracking['Shift2'] .str.replace(\"['\", \"\")\n",
    "dailytracking['Shift2'] =dailytracking['Shift2'] .str.replace(\"']\", \"\")\n",
    "dailytracking['Shift2'] =dailytracking['Shift2'] .str.replace(\"00\", \"\")\n",
    "dailytracking['Shift2'] =dailytracking['Shift2'] .str.replace(\"[]\", '')\n",
    "def shift1_func(x):\n",
    "    if x['Shift1'] =='':\n",
    "        return 0\n",
    "    else:         \n",
    "        return x['Shift1']\n",
    "dailytracking['Shift1']= dailytracking.apply(shift1_func, axis=1)\n",
    "dailytracking['Shift1']=dailytracking['Shift1'].astype('Float64')\n",
    "dailytracking['Shift1']=dailytracking['Shift1'].astype('Int64')\n",
    "def shift2_func(x):\n",
    "    if x['Shift2'] =='':\n",
    "        return 0\n",
    "    else:         \n",
    "        return x['Shift2']\n",
    "dailytracking['Shift2']= dailytracking.apply(shift2_func, axis=1)\n",
    "dailytracking['Shift2']=dailytracking['Shift2'].astype('Float64')\n",
    "dailytracking['Shift2']=dailytracking['Shift2'].astype('Int64')\n",
    "def time1_func(x):\n",
    "    if x['Shift1'] =='':\n",
    "        return t(0,0,0)\n",
    "    elif x['Shift1'] ==24:\n",
    "        return t(23,59,59)\n",
    "    else:         \n",
    "        return t(x['Shift1'],0,0)\n",
    "dailytracking['Time1']= dailytracking.apply(time1_func, axis=1)\n",
    "def time_func(x):\n",
    "    if x['Shift2'] =='':\n",
    "        return t(0,0,0)\n",
    "    elif x['Shift2'] ==24:\n",
    "        return t(23,59,59)\n",
    "    else:         \n",
    "        return t(x['Shift2'],0,0)\n",
    "dailytracking['Time2']= dailytracking.apply(time_func, axis=1)\n",
    "dailytracking['Time1'] = pd.to_datetime(dailytracking['Time1'], format='%H:%M:%S', errors='coerce').dt.time\n",
    "dailytracking['Time2'] = pd.to_datetime(dailytracking['Time2'], format='%H:%M:%S', errors='coerce').dt.time\n",
    "def nightshift_func(x):\n",
    "    if x['Shift_type'] ==\"OFF\":\n",
    "        return x['Session Date']\n",
    "    elif x['Shift2'] < 12:\n",
    "        return x['Session Date']+ pd.Timedelta(days=1)\n",
    "    else:         \n",
    "        return x['Session Date']\n",
    "dailytracking['Date']= dailytracking.apply(nightshift_func, axis=1) \n",
    "dailytracking['datetime1'] = pd.to_datetime(dailytracking['Session Date'].astype(str) + dailytracking['Time1'].astype(str), format = '%Y-%m-%d%H:%M:%S')\n",
    "dailytracking['datetime2'] = pd.to_datetime(dailytracking['Date'].astype(str) + dailytracking['Time2'].astype(str), format = '%Y-%m-%d%H:%M:%S')\n",
    "dailytracking['Approved Overtime1']=dailytracking['Approved Overtime'].astype('Float64')\n",
    "dailytracking['Approved Overtime1']=dailytracking['Approved Overtime1'].apply(np.ceil)\n",
    "dailytracking['datetime2'] = pd.to_datetime(dailytracking['datetime2'])\n",
    "dailytracking['Approved Overtime1'] = pd.to_timedelta(dailytracking['Approved Overtime1'],'h')\n",
    "dailytracking['datetime2'] = dailytracking['datetime2']+dailytracking['Approved Overtime1']\n",
    "dailytracking['datetime2'] = dailytracking['datetime2']+ pd.Timedelta(minutes=5)\n",
    "dailytracking['datetime1'] = pd.to_datetime(dailytracking['datetime1'])+ pd.Timedelta(minutes=5)\n",
    "dailytracking['Logout Time']=dailytracking['Logout Time'].fillna(0)\n",
    "dailytracking['datetime_logout'] = pd.to_datetime(dailytracking['Date'].astype(str) + dailytracking['Logout Time'].astype(str), format = '%Y-%m-%d%H:%M:%S', errors='coerce')\n",
    "dailytracking['Login Time']=dailytracking['Login Time'].fillna(0)\n",
    "dailytracking['datetime_login'] = pd.to_datetime(dailytracking['Session Date'].astype(str) + dailytracking['Login Time'].astype(str), format = '%Y-%m-%d%H:%M:%S', errors='coerce')\n",
    "def notlogout_func(x):\n",
    "    if x['Shift'] in {'AL','OFF','Training','HAL','CO','UPL'}:\n",
    "        return \"\"\n",
    "    elif x['datetime_logout'] > x['datetime2']:\n",
    "        return \"not logout after shift end\"       \n",
    "    else:         \n",
    "        return \"\"\n",
    "dailytracking['Not Logout']= dailytracking.apply(notlogout_func, axis=1)\n",
    "\n",
    "# Late-Soon Login Logout\n",
    "def late_func(x):\n",
    "    if x['Shift'] in {'AL','OFF','Training','HAL','CO','UPL'}:\n",
    "        return \"\"\n",
    "    elif x['datetime_login'] > x['datetime1']:\n",
    "        return \"Late\"       \n",
    "    else:         \n",
    "        return \"\"\n",
    "dailytracking['Late']= dailytracking.apply(late_func, axis=1)\n",
    "def soon_func(x):\n",
    "    if x['Shift'] in {'AL','OFF','Training','HAL','CO','UPL'}:\n",
    "        return \"\"\n",
    "    elif x['datetime_logout'] < x['datetime2']- pd.Timedelta(minutes=5):\n",
    "        return \"Soon\"       \n",
    "    else:         \n",
    "        return \"\"\n",
    "dailytracking['Soon']= dailytracking.apply(soon_func, axis=1)\n",
    "def latesoon_func(x):\n",
    "    if x['Late'] ==\"\" and x['Soon']==\"\":\n",
    "        return \"\"\n",
    "    elif x['Late']!=\"\" and x['Soon']==\"\":\n",
    "        return x['Late']       \n",
    "    elif x['Late']==\"\" and x['Soon']!=\"\":\n",
    "        return x['Soon']   \n",
    "    else:         \n",
    "        return x['Late']+'-'+x['Soon']\n",
    "dailytracking['Late-Soon']= dailytracking.apply(latesoon_func, axis=1)\n",
    "\n",
    "# Overconsecutive\n",
    "dailytracking= dailytracking.sort_values(by = ['EID', 'Session Date'])\n",
    "dailytracking['level_1']=(dailytracking['Session Date'] - dailytracking['Session Date'].shift(1)).astype('int64')/86400000000000 #to get the discrepancy between current and previous visible working day\n",
    "dailytracking['pre_ramco']=dailytracking['RAMCO'].shift(1)\n",
    "def level1_func(x):\n",
    "    if x['RAMCO'] in {'MTLX', 'MTLA', 'LWP', 'AL', 'AB', 'WO', 'SL', 'NM', 'MTL', 'CSLA', 'MOE', 'NCH', 'CSLB', 'PTL', 'PTL', 'PNL', 'CAL', 'HO', 'CDH', 'CO', 'CM', 'GM', 'MSL', 'VDH', 'MOC', 'CMLF'}:\n",
    "        return 2\n",
    "    elif x['level_1']==1 and x['pre_ramco'] in {'MTLX', 'MTLA', 'LWP', 'AL', 'AB', 'WO', 'SL', 'NM', 'MTL', 'CSLA', 'MOE', 'NCH', 'CSLB', 'PTL', 'PTL', 'PNL', 'CAL', 'HO', 'CDH', 'CO', 'CM', 'GM', 'MSL', 'VDH', 'MOC', 'CMLF'}:\n",
    "        return 2\n",
    "    else:         \n",
    "        return x['level_1']\n",
    "dailytracking['level_1']= dailytracking.apply(level1_func, axis=1)\n",
    "\n",
    "dailytracking['check_eid'] = (dailytracking['EID'] - dailytracking['EID'].shift(1))\n",
    "\n",
    "dailytracking[ 'level_2'] = ((dailytracking['level_1']!=1) | (dailytracking['check_eid'].isna()) | (dailytracking['check_eid']!=0)).cumsum()\n",
    "\n",
    "dailytracking['OverConsecutive'] = (\n",
    "    dailytracking[['level_2']]\n",
    "    .assign(OverConsecutive=1)\n",
    "    .groupby('level_2')['OverConsecutive']\n",
    "    .transform('cumsum')\n",
    ")\n",
    "dailytracking['OverConsecutive'] = dailytracking.apply(lambda x: 'OverConsecutive' if x['OverConsecutive'] > 6 else x['OverConsecutive'], axis=1)\n",
    "dailytracking['Staffed Hours']=dailytracking['Staffed Hours']*24\n",
    "dailytracking['Exception request']=dailytracking['Exception request']/60\n",
    "\n",
    "limit_date = max(pd.to_datetime(dailytracking['Session Date'], format ='mixed')) - pd.Timedelta(days=1)\n",
    "dailytracking=dailytracking.loc[dailytracking['Session Date'] <= limit_date]\n",
    "\n",
    "dailytracking['Session Date'] = pd.to_datetime(dailytracking['Session Date'], format='mixed').dt.date\n",
    "dailytracking_raw = dailytracking.drop(columns=['ATD MM Shift','ATD MM Ramco','PO','PO Hour','PR count','level_1','pre_ramco','check_eid',\n",
    "                                            'level_2','Shift1','Shift2','Time1','Time2','Date','datetime1','datetime2','Approved Overtime1',\n",
    "                                            'datetime_logout','datetime_login','Late','Soon'])\n",
    "dailytracking_raw['Session Date'] = pd.to_datetime(dailytracking_raw['Session Date'], format='mixed').dt.date\n",
    "dailytracking_raw['Productive hours']=dailytracking_raw['Productive hours']*24\n",
    "dailytracking_raw['Downtime']=dailytracking_raw['Downtime']*24\n",
    "dailytracking_raw['Delivery hours']=dailytracking_raw['Delivery hours']*24\n",
    "dailytracking_raw['Other codes']=dailytracking_raw['Other codes']*24\n",
    "dailytracking_raw['New Hire Training']=dailytracking_raw['New Hire Training']*24\n",
    "dailytracking_raw['Lunch Time']=dailytracking_raw['Lunch Time']*24\n",
    "dailytracking_raw['Break Time']=dailytracking_raw['Break Time']*24\n",
    "dailytracking_raw['Picklist - off Phone']=dailytracking_raw['Picklist - off Phone']*24\n",
    "dailytracking_raw['Ready or Talking']=dailytracking_raw['Ready or Talking']*24\n",
    "dailytracking_raw['Meeting']=dailytracking_raw['Meeting']*24\n",
    "dailytracking_raw['Training']=dailytracking_raw['Training']*24\n",
    "dailytracking_raw['Night Productive Hours']=dailytracking_raw['Night Productive Hours']*24\n",
    "dailytracking_raw['Day Productive Hours']=dailytracking_raw['Day Productive Hours']*24\n",
    "dailytracking_raw['Night Downtime Hours']=dailytracking_raw['Night Downtime Hours']*24\n",
    "dailytracking_raw['Day Downtime Hours']=dailytracking_raw['Day Downtime Hours']*24\n",
    "dailytracking_raw.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "dailytracking_full=dailytracking_raw\n",
    "# dailytracking_full['Session Date'] = pd.to_datetime(dailytracking_full['Session Date'],format='mixed').dt.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8e1bbdbd-1ba0-433d-9b5f-0966a10b6ccf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_23096\\2806513175.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pivot['Session Date']=pd.to_datetime(pivot['Session Date'],format='mixed')\n",
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_23096\\2806513175.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pivot['Month']=pivot['Session Date'].dt.strftime('%Y-%m')\n",
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_23096\\2806513175.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pivot.loc[atdmm, 'MM'] = 1\n",
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_23096\\2806513175.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pivot['MM'] = pivot['MM'].fillna(0)\n",
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_23096\\2806513175.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pivot.loc[notlogout, 'Not Logout after shift end'] = 1\n",
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_23096\\2806513175.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pivot['Not Logout after shift end'] = pivot['Not Logout after shift end'].fillna(0)\n",
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_23096\\2806513175.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pivot.loc[late, 'Late'] = 1\n",
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_23096\\2806513175.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pivot['Late'] = pivot['Late'].fillna(0)\n",
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_23096\\2806513175.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pivot.loc[soon, 'Soon'] = 1\n",
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_23096\\2806513175.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pivot['Soon'] = pivot['Soon'].fillna(0)\n",
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_23096\\2806513175.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pivot.loc[latesoon, 'Late-Soon '] = 1\n",
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_23096\\2806513175.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pivot['Late-Soon '] = pivot['Late-Soon '].fillna(0)\n",
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_23096\\2806513175.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pivot.loc[ot40, 'OT > 40'] = 1\n",
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_23096\\2806513175.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pivot['OT > 40'] = pivot['OT > 40'].fillna(0)\n",
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_23096\\2806513175.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pivot.loc[po4, 'PO > 4'] = 1\n",
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_23096\\2806513175.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pivot['PO > 4'] = pivot['PO > 4'].fillna(0)\n",
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_23096\\2806513175.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pivot.loc[pohrs32, 'PO hrs > 32'] = 1\n",
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_23096\\2806513175.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pivot['PO hrs > 32'] = pivot['PO hrs > 32'].fillna(0)\n"
     ]
    }
   ],
   "source": [
    "## DEFECT\n",
    "pivot=dailytracking[['Session Date','EID','Supervisor','ATD MM','#PO (MTD)','POHrs(MTD)','OT (MTD)','OT-LessDelivery',\n",
    "                     'OT>4Hrs On PR \\n OT>8Hrs On PO','PR < 8.75','Low PerF','Login on Dayoff','Not Logout','Late-Soon']]\n",
    "pivot['Session Date']=pd.to_datetime(pivot['Session Date'],format='mixed')\n",
    "pivot['Month']=pivot['Session Date'].dt.strftime('%Y-%m')\n",
    "    #MM\n",
    "atdmm=pivot['ATD MM']=='ATD MM'\n",
    "pivot.loc[atdmm, 'MM'] = 1\n",
    "pivot['MM'] = pivot['MM'].fillna(0)\n",
    "\n",
    "    #Not Logout after shift end\n",
    "notlogout=pivot['Not Logout']=='not logout after shift end'\n",
    "pivot.loc[notlogout, 'Not Logout after shift end'] = 1\n",
    "pivot['Not Logout after shift end'] = pivot['Not Logout after shift end'].fillna(0)\n",
    "\n",
    "    #Late\n",
    "late=pivot['Late-Soon']=='Late'\n",
    "pivot.loc[late, 'Late'] = 1\n",
    "pivot['Late'] = pivot['Late'].fillna(0)\n",
    "\n",
    "    #Soon\n",
    "soon=pivot['Late-Soon']=='Soon'\n",
    "pivot.loc[soon, 'Soon'] = 1\n",
    "pivot['Soon'] = pivot['Soon'].fillna(0)\n",
    "\n",
    "    #Late\n",
    "latesoon=pivot['Late-Soon']=='Late-Soon'\n",
    "pivot.loc[latesoon, 'Late-Soon '] = 1\n",
    "pivot['Late-Soon '] = pivot['Late-Soon '].fillna(0)\n",
    "\n",
    "    #OT MTD > 40\n",
    "ot40=pivot['OT (MTD)'] > 40\n",
    "pivot.loc[ot40, 'OT > 40'] = 1\n",
    "pivot['OT > 40'] = pivot['OT > 40'].fillna(0)\n",
    "    \n",
    "    #PO MTD >4\n",
    "po4=pivot['#PO (MTD)'] > 4\n",
    "pivot.loc[po4, 'PO > 4'] = 1\n",
    "pivot['PO > 4'] = pivot['PO > 4'].fillna(0)\n",
    "\n",
    "    #PO Hrs >32\n",
    "pohrs32=pivot['POHrs(MTD)'] > 32\n",
    "pivot.loc[pohrs32, 'PO hrs > 32'] = 1\n",
    "pivot['PO hrs > 32'] = pivot['PO hrs > 32'].fillna(0)\n",
    "\n",
    "pivot=pivot[['Supervisor','Month','MM','PR < 8.75','OT-LessDelivery','Low PerF','OT>4Hrs On PR \\n OT>8Hrs On PO', 'Login on Dayoff',\n",
    "             'Not Logout after shift end','Late','Soon','Late-Soon ','OT > 40','PO > 4','PO hrs > 32']]\n",
    "pivot=pivot.groupby(['Supervisor','Month'], as_index=False).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a8873228-7b5b-4bde-81a1-6e4dc5e55b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT BUDGET AND RATE\n",
    "budget = pd.read_json(os.path.join(user_credential, r'DB\\filejson\\requirement.json'))\n",
    "budget['Budget Downtime Hrs']=budget['Daily Requirement']-budget['Prod Requirement']\n",
    "budget=budget.rename(columns={'Prod Requirement':'Budget Productive Hrs'})\n",
    "rate = import_csv(path = budget_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "985aee25-b2d7-4d00-936e-e20f077e6cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORT ACTUAL INVOICE\n",
    "actual = import_xlsx(path = budget_path,sheet_name = 'Sheet1')\n",
    "actual=actual[['LOB','Month','Hours','Revenue']]\n",
    "actual=actual.groupby(['LOB','Month'], as_index=False).sum()\n",
    "\n",
    "actual_hour=actual.drop(columns=['Revenue'])\n",
    "actual_hour_total=actual[['Month','Hours']]\n",
    "actual_hour_total=actual_hour_total.groupby('Month', as_index=False).sum()\n",
    "actual_hour_total['LOB']=actual_hour_total.apply(lambda x: 'Total Hour' if x['Month'] !='' else 0, axis=1)\n",
    "\n",
    "actual_revenue=actual.drop(columns=['Hours'])\n",
    "actual_revenue_total=actual[['Month','Revenue']]\n",
    "actual_revenue_total=actual_revenue_total.groupby('Month', as_index=False).sum()\n",
    "actual_revenue_total['LOB']=actual_revenue_total.apply(lambda x: 'Total Revenue' if x['Month'] !='' else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5fed37c7-0a76-470f-ba3c-c7cf3903447a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_23096\\1967466067.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  max_date['Session Date']=pd.to_datetime(max_date['Session Date'],format='mixed')\n",
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_23096\\1967466067.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  max_date['Month']=max_date['Session Date'].dt.strftime('%Y-%m')\n",
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_23096\\1967466067.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  max_date['Day']=max_date['Session Date'].dt.day\n",
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_23096\\1967466067.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  estimate['Session Date']=pd.to_datetime(estimate['Session Date'],format='mixed')\n",
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_23096\\1967466067.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  estimate['Month']=estimate['Session Date'].dt.strftime('%Y-%m')\n",
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_23096\\1967466067.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  estimate.loc[not_holiday, 'Productive Hours (Core)'] = estimate['Day Productive Hours']*24-estimate['Approved Overtime']\n",
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_23096\\1967466067.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  estimate['Productive Hours (Core)'] = estimate['Productive Hours (Core)'].fillna(0)\n",
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_23096\\1967466067.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  estimate.loc[not_holiday, 'Productive Hours (Night)'] = estimate['Night Productive Hours']*24\n",
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_23096\\1967466067.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  estimate['Productive Hours (Night)'] = estimate['Productive Hours (Night)'].fillna(0)\n",
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_23096\\1967466067.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  estimate.loc[not_holiday, 'Downtime Hours (Core)'] = estimate['Day Downtime Hours']*24\n",
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_23096\\1967466067.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  estimate['Downtime Hours (Core)'] = estimate['Downtime Hours (Core)'].fillna(0)\n",
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_23096\\1967466067.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  estimate.loc[not_holiday, 'Downtime Hours (Night)'] = estimate['Night Downtime Hours']*24\n",
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_23096\\1967466067.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  estimate['Downtime Hours (Night)'] = estimate['Downtime Hours (Night)'].fillna(0)\n",
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_23096\\1967466067.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  estimate.loc[not_holiday, 'New Hire Training Hours'] = estimate['New Hire Training']*24\n",
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_23096\\1967466067.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  estimate['New Hire Training Hours'] = estimate['New Hire Training Hours'].fillna(0)\n",
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_23096\\1967466067.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  estimate.loc[public_holiday, 'Public Holiday Hours'] =estimate['Delivery hours']*24\n",
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_23096\\1967466067.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  estimate['Public Holiday Hours'] = estimate['Public Holiday Hours'].fillna(0)\n"
     ]
    }
   ],
   "source": [
    "# ESTIMATE HOUR\n",
    "max_date=dailytracking[['Session Date']]\n",
    "max_date['Session Date']=pd.to_datetime(max_date['Session Date'],format='mixed')\n",
    "max_date['Month']=max_date['Session Date'].dt.strftime('%Y-%m')\n",
    "max_date['Day']=max_date['Session Date'].dt.day\n",
    "max_date=max_date[['Month','Day','Session Date']]\n",
    "max_date=max_date.groupby(['Month'], as_index=False).max()\n",
    "max_date['EndOfMonth'] = pd.to_datetime(max_date['Session Date'], format=\"mixed\") + MonthEnd(0)\n",
    "max_date['EndDate']=max_date['EndOfMonth'].dt.day\n",
    "max_date=max_date[['Month','Day','EndDate']]\n",
    "estimate=dailytracking[['Session Date','LOB','RAMCO','Delivery hours','New Hire Training','Night Productive Hours',\n",
    "               'Day Productive Hours','Night Downtime Hours','Day Downtime Hours','Approved Overtime']]\n",
    "estimate['Session Date']=pd.to_datetime(estimate['Session Date'],format='mixed')\n",
    "estimate['Month']=estimate['Session Date'].dt.strftime('%Y-%m')\n",
    "\n",
    "not_holiday=estimate['RAMCO'] !='PH'\n",
    "public_holiday=estimate['RAMCO'] =='PH'\n",
    "estimate.loc[not_holiday, 'Productive Hours (Core)'] = estimate['Day Productive Hours']*24-estimate['Approved Overtime']\n",
    "estimate['Productive Hours (Core)'] = estimate['Productive Hours (Core)'].fillna(0)\n",
    "\n",
    "estimate.loc[not_holiday, 'Productive Hours (Night)'] = estimate['Night Productive Hours']*24\n",
    "estimate['Productive Hours (Night)'] = estimate['Productive Hours (Night)'].fillna(0)\n",
    "\n",
    "estimate.loc[not_holiday, 'Downtime Hours (Core)'] = estimate['Day Downtime Hours']*24\n",
    "estimate['Downtime Hours (Core)'] = estimate['Downtime Hours (Core)'].fillna(0)\n",
    "\n",
    "estimate.loc[not_holiday, 'Downtime Hours (Night)'] = estimate['Night Downtime Hours']*24\n",
    "estimate['Downtime Hours (Night)'] = estimate['Downtime Hours (Night)'].fillna(0)\n",
    "\n",
    "estimate.loc[not_holiday, 'New Hire Training Hours'] = estimate['New Hire Training']*24\n",
    "estimate['New Hire Training Hours'] = estimate['New Hire Training Hours'].fillna(0)\n",
    "\n",
    "estimate.loc[public_holiday, 'Public Holiday Hours'] =estimate['Delivery hours']*24\n",
    "estimate['Public Holiday Hours'] = estimate['Public Holiday Hours'].fillna(0)\n",
    "\n",
    "estimate_hour=estimate[['Month','LOB','Productive Hours (Core)','Productive Hours (Night)','Approved Overtime',\n",
    "                        'Public Holiday Hours','Downtime Hours (Core)','Downtime Hours (Night)','New Hire Training Hours']]\n",
    "estimate_hour=estimate_hour.groupby(['Month','LOB'], as_index=False).sum()\n",
    "estimate_hour['Total Hours']=estimate_hour['Productive Hours (Core)']+estimate_hour['Productive Hours (Night)']+estimate_hour['Approved Overtime']+estimate_hour['Downtime Hours (Core)']+estimate_hour['Downtime Hours (Night)']+estimate_hour['New Hire Training Hours']+estimate_hour['Public Holiday Hours']\n",
    "estimate_hour=pd.merge(estimate_hour,max_date,left_on='Month',right_on='Month',how='left')\n",
    "estimate_hour['Forecast to EOM']=(estimate_hour['Total Hours']/estimate_hour['Day'])*estimate_hour['EndDate']\n",
    "estimate_hour=estimate_hour.drop(columns=['Day', 'EndDate'])\n",
    "estimate_hour=estimate_hour.rename(columns={'Approved Overtime':'OT Hours'})\n",
    "actual_hour=actual[['LOB','Month','Hours']]\n",
    "estimate_hour=pd.merge(estimate_hour,actual_hour,left_on=['Month','LOB'],right_on=['Month','LOB'],how='left')\n",
    "\n",
    "# ESTIMATE REVENUE\n",
    "estimate_revenue=estimate[['Month','LOB','Productive Hours (Core)','Productive Hours (Night)','Approved Overtime',\n",
    "                                           'Public Holiday Hours','Downtime Hours (Core)','Downtime Hours (Night)',\n",
    "                                           'New Hire Training Hours']]\n",
    "estimate_revenue=pd.merge(estimate_revenue,rate,left_on='Month',right_on='Month',how='left')\n",
    "estimate_revenue['Productive Hours (Core)'] = estimate_revenue['Productive Hours (Core)']*estimate_revenue['Conversion']*estimate_revenue['Productive hours (Core)']\n",
    "estimate_revenue['Productive Hours (Night)'] = estimate_revenue['Productive Hours (Night)']*estimate_revenue['Conversion']*estimate_revenue['Productive hours (Night)']\n",
    "estimate_revenue['Downtime Hours (Core)'] = estimate_revenue['Downtime Hours (Core)']*estimate_revenue['Conversion']*estimate_revenue['Downtime (Core)']\n",
    "estimate_revenue['Downtime Hours (Night)'] = estimate_revenue['Downtime Hours (Night)']*estimate_revenue['Conversion']*estimate_revenue['Downtime (Night)']\n",
    "estimate_revenue['New Hire Training Hours'] = estimate_revenue['New Hire Training Hours']*estimate_revenue['Conversion']*estimate_revenue['New hire']\n",
    "estimate_revenue['Public Holiday Hours'] = estimate_revenue['Public Holiday Hours']*estimate_revenue['Conversion']*estimate_revenue['PH']\n",
    "estimate_revenue['Approved Overtime'] = estimate_revenue['Approved Overtime']*estimate_revenue['Conversion']*estimate_revenue['OT']\n",
    "\n",
    "estimate_revenue=estimate_revenue.groupby(['Month','LOB'], as_index=False).sum()\n",
    "\n",
    "estimate_revenue['Total Revenue']=estimate_revenue['Productive Hours (Core)']+estimate_revenue['Productive Hours (Night)']+estimate_revenue['Approved Overtime']+estimate_revenue['Downtime Hours (Core)']+estimate_revenue['Downtime Hours (Night)']+estimate_revenue['New Hire Training Hours']+estimate_revenue['Public Holiday Hours']\n",
    "\n",
    "estimate_revenue=pd.merge(estimate_revenue,max_date,left_on='Month',right_on='Month',how='left')\n",
    "\n",
    "estimate_revenue['Forecast to EOM']=(estimate_revenue['Total Revenue']/estimate_revenue['Day'])*estimate_revenue['EndDate']\n",
    "\n",
    "estimate_revenue=estimate_revenue.drop(columns=['Day', 'EndDate'])\n",
    "estimate_revenue=estimate_revenue.rename(columns={'Approved Overtime':'OT Revenue','Productive Hours (Core)':'Productive Revenue (Core)',\n",
    "                                                 'Productive Hours (Night)':'Productive Revenue (Night)',\n",
    "                                                 'Public Holiday Hours':'Public Holiday Revenue','Downtime Hours (Core)':'Downtime Revenue (Core)',\n",
    "                                                 'Downtime Hours (Night)':'Downtime Revenue (Night)','New Hire Training Hours':'New Hire Training Revenue'})\n",
    "actual_revenue=actual[['LOB','Month','Revenue']]\n",
    "estimate_revenue=pd.merge(estimate_revenue,actual_revenue,left_on=['Month','LOB'],right_on=['Month','LOB'],how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "625011de-58b1-4753-b60f-0e7d69f8711e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_23096\\1200638067.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  budget_hour['Month']=budget_hour['Date'].dt.strftime('%Y-%m')\n",
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_23096\\1200638067.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  budget_revenue['Month']=budget_revenue['Date'].dt.strftime('%Y-%m')\n"
     ]
    }
   ],
   "source": [
    "# BUDGET HOUR\n",
    "budget_hour=budget[['Date','LOB','Budget Productive Hrs','Budget Downtime Hrs']]\n",
    "budget_hour['Month']=budget_hour['Date'].dt.strftime('%Y-%m')\n",
    "budget_hour['Budget Hours']=budget_hour['Budget Productive Hrs']+budget_hour['Budget Downtime Hrs']\n",
    "budget_hour=budget_hour.drop(columns=['Date','Budget Productive Hrs','Budget Downtime Hrs'])\n",
    "budget_hour=budget_hour.groupby(['Month','LOB'], as_index=False).sum()\n",
    "\n",
    "# BUDGET REVENUE\n",
    "budget_revenue=budget[['Date','LOB','Budget Productive Hrs','Budget Downtime Hrs']]\n",
    "budget_revenue['Month']=budget_revenue['Date'].dt.strftime('%Y-%m')\n",
    "budget_revenue=budget_revenue.drop(columns=['Date'])\n",
    "budget_revenue=budget_revenue.groupby(['Month','LOB'], as_index=False).sum()\n",
    "\n",
    "estimate_hour_budget=estimate_hour\n",
    "estimate_hour_budget['% Productive Night']=(estimate_hour_budget['Productive Hours (Night)']/estimate_hour_budget['Productive Hours (Core)'])*0.7\n",
    "estimate_hour_budget['% Downtime Night']=(estimate_hour_budget['Downtime Hours (Night)']/estimate_hour_budget['Downtime Hours (Core)'])*0.7\n",
    "estimate_hour_budget=estimate_hour_budget[['Month','LOB','% Productive Night','% Downtime Night','OT Hours','Public Holiday Hours']]\n",
    "\n",
    "budget_revenue=pd.merge(budget_revenue,estimate_hour_budget,left_on=['Month','LOB'],right_on=['Month','LOB'],how='left')\n",
    "budget_revenue['Budget Productive Hrs']=budget_revenue['Budget Productive Hrs']-(budget_revenue['OT Hours']*0.95)\n",
    "budget_revenue['Budget Downtime Hrs']=budget_revenue['Budget Downtime Hrs']-(budget_revenue['OT Hours']*0.05)\n",
    "budget_revenue['Budget Productive Hrs']=budget_revenue['Budget Productive Hrs']-(budget_revenue['Public Holiday Hours']*0.95)\n",
    "budget_revenue['Budget Downtime Hrs']=budget_revenue['Budget Downtime Hrs']-(budget_revenue['Public Holiday Hours']*0.05)\n",
    "\n",
    "budget_revenue['Productive Hours (Night)']=budget_revenue['Budget Productive Hrs']*budget_revenue['% Productive Night']\n",
    "budget_revenue['Productive Hours (Core)']=budget_revenue['Budget Productive Hrs']-budget_revenue['Productive Hours (Night)']\n",
    "budget_revenue['Downtime Hours (Night)']=budget_revenue['Budget Downtime Hrs']*budget_revenue['% Downtime Night']\n",
    "budget_revenue['Downtime Hours (Core)']=budget_revenue['Budget Downtime Hrs']-budget_revenue['Downtime Hours (Night)']\n",
    "budget_revenue=pd.merge(budget_revenue,rate,left_on='Month',right_on='Month',how='left')\n",
    "budget_revenue['Productive Revenue (Core)']=budget_revenue['Productive Hours (Core)']*budget_revenue['Productive hours (Core)']\n",
    "budget_revenue['Productive Revenue (Night)']=budget_revenue['Productive Hours (Night)']*budget_revenue['Productive hours (Night)']\n",
    "budget_revenue['Downtime Revenue (Core)']=budget_revenue['Downtime Hours (Core)']*budget_revenue['Downtime (Core)']\n",
    "budget_revenue['Downtime Revenue (Night)']=budget_revenue['Downtime Hours (Night)']*budget_revenue['Downtime (Night)']\n",
    "budget_revenue['OT Revenue']=budget_revenue['OT Hours']*budget_revenue['OT']\n",
    "budget_revenue['PH Revenue']=budget_revenue['Public Holiday Hours']*budget_revenue['PH']\n",
    "budget_revenue['Budget Revenue']=budget_revenue['Productive Revenue (Core)']+budget_revenue['Productive Revenue (Night)']+budget_revenue['Downtime Revenue (Core)']+budget_revenue['Downtime Revenue (Night)']+budget_revenue['OT Revenue']+budget_revenue['PH Revenue']\n",
    "budget_revenue=budget_revenue[['Month','LOB','Budget Revenue']]\n",
    "\n",
    "# FINAL ESTIMATION\n",
    "estimate_hour=pd.merge(estimate_hour,budget_hour,left_on=['Month','LOB'],right_on=['Month','LOB'],how='left')\n",
    "estimate_hour=estimate_hour[['Month','LOB','Productive Hours (Core)','Productive Hours (Night)','OT Hours','Public Holiday Hours','Downtime Hours (Core)','Downtime Hours (Night)','New Hire Training Hours','Budget Hours','Total Hours','Forecast to EOM']]\n",
    "estimate_hour=pd.merge(estimate_hour,actual_hour,left_on=['Month','LOB'],right_on=['Month','LOB'],how='left')\n",
    "estimate_hour_total=estimate_hour.drop(columns=['LOB'])\n",
    "estimate_hour_total=estimate_hour_total.groupby(['Month'], as_index=False).sum()\n",
    "estimate_hour_total['LOB']=estimate_hour_total.apply(lambda x: 'Total Hour' if x['Month'] !='' else 0, axis=1)\n",
    "estimate_hour_total=pd.merge(estimate_hour_total,actual_hour_total,left_on=['Month','LOB'],right_on=['Month','LOB'],how='left')\n",
    "estimate_hour_total=estimate_hour_total.rename(columns={'Hours_x':'Hours'})\n",
    "estimate_hour =pd.concat([estimate_hour, estimate_hour_total], sort=False)\n",
    "estimate_hour=estimate_hour.drop(columns=['Hours_y'])\n",
    "\n",
    "estimate_revenue=pd.merge(estimate_revenue,budget_revenue,left_on=['Month','LOB'],right_on=['Month','LOB'],how='left')\n",
    "estimate_revenue=estimate_revenue[['Month','LOB','Productive Revenue (Core)','Productive Revenue (Night)','OT Revenue','Public Holiday Revenue','Downtime Revenue (Core)','Downtime Revenue (Night)','New Hire Training Revenue','Budget Revenue','Total Revenue','Forecast to EOM']]\n",
    "estimate_revenue=pd.merge(estimate_revenue,actual_revenue,left_on=['Month','LOB'],right_on=['Month','LOB'],how='left')\n",
    "estimate_revenue_total=estimate_revenue.drop(columns=['LOB'])\n",
    "estimate_revenue_total=estimate_revenue_total.groupby(['Month'], as_index=False).sum()\n",
    "estimate_revenue_total['LOB']=estimate_revenue_total.apply(lambda x: 'Total Revenue' if x['Month'] !='' else 0, axis=1)\n",
    "estimate_revenue_total=pd.merge(estimate_revenue_total,actual_revenue_total,left_on=['Month','LOB'],right_on=['Month','LOB'],how='left')\n",
    "estimate_revenue_total=estimate_revenue_total.rename(columns={'Revenue_x':'Revenue'})\n",
    "estimate_revenue =pd.concat([estimate_revenue, estimate_revenue_total], sort=False)\n",
    "estimate_revenue=estimate_revenue.drop(columns=['Revenue_y'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "775f53ee-a42c-46de-9c3f-b757571beb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format Daily Tracking\n",
    "import xlsxwriter\n",
    "import openpyxl\n",
    "writer = pd.ExcelWriter(dailytracking_path, engine=\"xlsxwriter\")\n",
    "dailytracking_raw.to_excel(writer, sheet_name=\"Daily Tracking\", startrow=0, index=False)\n",
    "pivot.to_excel(writer, sheet_name=\"DEFECT\", startrow=0, index=False)\n",
    "workbook = writer.book\n",
    "dailytracking_sheet= writer.sheets[\"Daily Tracking\"]\n",
    "defect = writer.sheets[\"DEFECT\"]\n",
    "\n",
    "#Add format for Daily Tracking sheet\n",
    "dailytracking_sheet.autofilter(0, 0, dailytracking_raw.shape[0], dailytracking_raw.shape[1]-1)\n",
    "dailytracking_sheet.freeze_panes(1, 0)\n",
    "# Add format for DEFECT sheet\n",
    "header_defect = workbook.add_format(\n",
    "    {\n",
    "        \"bold\": True,\n",
    "        \"text_wrap\": True,\n",
    "        \"valign\": \"top\",\n",
    "        \"fg_color\": \"#4472C4\",\n",
    "        \"border\": 0,\n",
    "        'font_color': 'white'\n",
    "    }\n",
    ")\n",
    "for col_num, value in enumerate(pivot.columns.values):\n",
    "    defect.write(0, col_num, value, header_defect)\n",
    "defect.autofilter(0, 0, pivot.shape[0], pivot.shape[1]-1)\n",
    "defect.freeze_panes(1, 0)\n",
    "defect.set_column('A:O', 11)\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e18d1146-73f7-48fa-a99a-33ab9f3139c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format Revenue Estimation\n",
    "import xlsxwriter\n",
    "import openpyxl\n",
    "writer = pd.ExcelWriter(revenue_path, engine=\"xlsxwriter\")\n",
    "dailytracking_raw.to_excel(writer, sheet_name=\"DailyTracking\", startrow=0, index=False)\n",
    "pivot.to_excel(writer, sheet_name=\"DEFECT\", startrow=0, index=False)\n",
    "estimate_hour.to_excel(writer, sheet_name=\"ESTIMATE_HOUR\", startrow=0, index=False)\n",
    "estimate_revenue.to_excel(writer, sheet_name=\"ESTIMATE_REVENUE\", startrow=0, index=False)\n",
    "rate.to_excel(writer, sheet_name=\"Rate\", startrow=0, index=False)\n",
    "define.to_excel(writer, sheet_name=\"DEFINE\", startrow=0, index=False)\n",
    "\n",
    "workbook = writer.book\n",
    "dailytracking_sheet= writer.sheets[\"DailyTracking\"]\n",
    "defect = writer.sheets[\"DEFECT\"]\n",
    "estimatehour_sheet=writer.sheets[\"ESTIMATE_HOUR\"]\n",
    "estimaterevenue_sheet=writer.sheets[\"ESTIMATE_REVENUE\"]\n",
    "estimation=workbook.add_worksheet(\"ESTIMATION\")\n",
    "rate=writer.sheets[\"Rate\"]\n",
    "define=writer.sheets[\"DEFINE\"]\n",
    "#Add format for Daily Tracking sheet\n",
    "dailytracking_sheet.autofilter(0, 0, dailytracking_raw.shape[0], dailytracking_raw.shape[1]-1)\n",
    "dailytracking_sheet.freeze_panes(1, 0)\n",
    "# Add format for DEFECT sheet\n",
    "header_defect = workbook.add_format(\n",
    "    {\n",
    "        \"bold\": True,\n",
    "        \"text_wrap\": True,\n",
    "        \"valign\": \"top\",\n",
    "        \"fg_color\": \"#4472C4\",\n",
    "        \"border\": 0,\n",
    "        'font_color': 'white'\n",
    "    }\n",
    ")\n",
    "for col_num, value in enumerate(pivot.columns.values):\n",
    "    defect.write(0, col_num, value, header_defect)\n",
    "defect.autofilter(0, 0, pivot.shape[0], pivot.shape[1]-1)\n",
    "defect.freeze_panes(1, 0)\n",
    "defect.set_column('A:O', 11)\n",
    "\n",
    "#Hide estimate hour and estimate revenue sheet\n",
    "dailytracking_sheet.hide()\n",
    "estimatehour_sheet.hide()\n",
    "estimaterevenue_sheet.hide()\n",
    "defect.hide()\n",
    "rate.hide()\n",
    "# Add value for ESTIMATION Sheet\n",
    "first_format = workbook.add_format({\"bold\": True,\"text_wrap\": True,\"valign\": \"middle\",\"fg_color\": \"#833C0C\",\"border\": 2,'font_color': 'white'})\n",
    "second_format = workbook.add_format({\"bold\": True,\"text_wrap\": True,\"valign\": \"middle\",\"fg_color\": \"#161616\",\"border\": 2,'font_color': 'white','num_format': '$#,##0.##'})\n",
    "third_format = workbook.add_format({\"bold\": True,\"text_wrap\": True,\"valign\": \"middle\",\"align\":\"center\",\"fg_color\": \"#375623\",\"border\": 2,'font_color': 'white'})\n",
    "third_format.set_align('vcenter')\n",
    "\n",
    "thisyear= (pd.Timestamp.today().date()).year\n",
    "thismonth= (pd.Timestamp.today().date()).month                        \n",
    "estimation.write('A1', 'YEAR',first_format)\n",
    "estimation.write('B1', thisyear,first_format)\n",
    "estimation.write('D1', 'MONTH',first_format)\n",
    "estimation.write('E1', thismonth,first_format)\n",
    "estimation.write('G1', 'Viewed by',first_format)\n",
    "estimation.data_validation('H1', {'validate': 'list',\n",
    "                                  'source': ['Revenue ($)', 'Hour']}) \n",
    "estimation.write('H1', 'Revenue ($)',first_format)\n",
    "\n",
    "estimation.write('A3', 'Rate',second_format)\n",
    "estimation.write_formula('B3', '=XLOOKUP($B1&\"-\"&$E1,Rate!$A:$A,Rate!$B:$B)*XLOOKUP($B1&\"-\"&$E1,Rate!$A:$A,Rate!C:C)',second_format)\n",
    "estimation.write_formula('C3', '=XLOOKUP($B1&\"-\"&$E1,Rate!$A:$A,Rate!$B:$B)*XLOOKUP($B1&\"-\"&$E1,Rate!$A:$A,Rate!D:D)',second_format)\n",
    "estimation.write_formula('D3', '=XLOOKUP($B1&\"-\"&$E1,Rate!$A:$A,Rate!$B:$B)*XLOOKUP($B1&\"-\"&$E1,Rate!$A:$A,Rate!E:E)',second_format)\n",
    "estimation.write_formula('E3', '=XLOOKUP($B1&\"-\"&$E1,Rate!$A:$A,Rate!$B:$B)*XLOOKUP($B1&\"-\"&$E1,Rate!$A:$A,Rate!F:F)',second_format)\n",
    "estimation.write_formula('F3', '=XLOOKUP($B1&\"-\"&$E1,Rate!$A:$A,Rate!$B:$B)*XLOOKUP($B1&\"-\"&$E1,Rate!$A:$A,Rate!G:G)',second_format)\n",
    "estimation.write_formula('G3', '=XLOOKUP($B1&\"-\"&$E1,Rate!$A:$A,Rate!$B:$B)*XLOOKUP($B1&\"-\"&$E1,Rate!$A:$A,Rate!H:H)',second_format)\n",
    "estimation.write_formula('H3', '=XLOOKUP($B1&\"-\"&$E1,Rate!$A:$A,Rate!$B:$B)*XLOOKUP($B1&\"-\"&$E1,Rate!$A:$A,Rate!I:I)',second_format) \n",
    "estimation.write('I3', '',second_format)\n",
    "estimation.write('J3', '',second_format)\n",
    "estimation.write('K3', '',second_format)\n",
    "estimation.write('L3', '',second_format)\n",
    "                                  \n",
    "estimation.write('A4', 'LOB',third_format)\n",
    "estimation.write('B4', 'Producted (Core)',third_format)\n",
    "estimation.write('C4', 'Producted (Night)',third_format)\n",
    "estimation.write('D4', 'OT',third_format)\n",
    "estimation.write('E4', 'Public Holiday',third_format)\n",
    "estimation.write('F4', 'Downtime (Core)',third_format)\n",
    "estimation.write('G4', 'Downtime (Night)',third_format)\n",
    "estimation.write('H4', 'New Hire Training',third_format)\n",
    "estimation.write('I4', 'Budget to EOM',third_format)\n",
    "estimation.write_formula('J4', '=\"Total to \"&CHAR(10)&TEXT(MAXIFS(DailyTracking!B:B,DailyTracking!B:B,\"<=\"&EOMONTH(DATE(B1,E1,1),0),DailyTracking!B:B,\">=\"&DATE(ESTIMATION!B1,ESTIMATION!E1,1)),\"dd-mmm\")',third_format)\n",
    "estimation.write('K4', 'Forecast to EOM',third_format)\n",
    "estimation.write('L4', 'Actual Invoice',third_format)\n",
    "\n",
    "estimation.write_formula('A5', '=IFS(H1=\"Hour\",FILTER(ESTIMATE_HOUR!B2:M1000000,ESTIMATE_REVENUE!A2:A1000000=B1&\"-\"&E1),H1=\"Revenue ($)\",FILTER(ESTIMATE_REVENUE!B2:M1000000,ESTIMATE_REVENUE!A2:A1000000=B1&\"-\"&E1))')\n",
    "\n",
    "first_row=4\n",
    "last_row=99\n",
    "first_col=0\n",
    "last_col=11\n",
    "currency_format = workbook.add_format({'num_format': '$#,##0'})\n",
    "number_format = workbook.add_format({'num_format': '#,##0'})\n",
    "total_format= workbook.add_format({\"bold\": True,\"text_wrap\": True,\"valign\": \"middle\",\"align\":\"center\",\"border\": 0,'font_color': 'black'})\n",
    "estimation.conditional_format(first_row, first_col, last_row, last_col,\n",
    "                             {'type': 'formula','criteria': '=$H$1=\"Revenue ($)\"','format': currency_format})\n",
    "estimation.conditional_format(first_row, first_col, last_row, last_col,\n",
    "                             {'type': 'formula','criteria': '=$H$1=\"Hour\"','format': number_format})\n",
    "estimation.conditional_format(first_row, first_col, last_row, last_col,\n",
    "                             {'type': 'formula','criteria': '=$A5:$A100=\"Total Hour\"','format': total_format})\n",
    "estimation.conditional_format(first_row, first_col, last_row, last_col,\n",
    "                             {'type': 'formula','criteria': '=$A5:$A100=\"Total Revenue\"','format': total_format})\n",
    "estimation.set_column('A:K', 13.86)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6f4e8343-0804-4cc7-9e48-3781c9be874f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_23096\\4278659990.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  eps_adherence['Actual Downtime']=eps_adherence['Meeting']+eps_adherence['Training']\n",
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_23096\\4278659990.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  eps_adherence['Session Date']=pd.to_datetime(eps_adherence['Session Date']).dt.date\n",
      "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openpyxl\\worksheet\\_reader.py:329: UserWarning: Unknown extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openpyxl\\worksheet\\_reader.py:329: UserWarning: Conditional Formatting extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# ADHERENCE\n",
    "workplan = pd.read_json(os.path.join(user_credential, r'DB\\filejson\\workplan_merge_iex.json'))\n",
    "workplan=workplan[['Date','Agent ID','Scheduled Activity','Length','EID']]\n",
    "workplan['Date']=pd.to_datetime(workplan['Date']).dt.date\n",
    "workplan['EID']=workplan['EID'].astype(\"Int64\")\n",
    "\n",
    "workplan['Plotted Downtime']=workplan.apply(lambda x: x['Length'] if x['Scheduled Activity'] in {'Coaching 1:1','Team Meeting'} else 0, axis=1)\n",
    "workplan['Plotted Phone']=workplan.apply(lambda x: x['Length'] if x['Scheduled Activity']=='Open Time' else 0, axis=1)\n",
    "workplan['Plotted Picklist']=workplan.apply(lambda x: x['Length'] if x['Scheduled Activity'] =='Email 1' else 0, axis=1)\n",
    "workplan['Plotted Lunch']=workplan.apply(lambda x: x['Length'] if x['Scheduled Activity'] =='Lunch' else 0, axis=1)\n",
    "workplan['Plotted Break']=workplan.apply(lambda x: x['Length'] if x['Scheduled Activity'] =='Break Offline' else 0, axis=1)\n",
    "\n",
    "workplan=workplan.groupby(['Date','Agent ID','EID'], as_index=False).sum()\n",
    "workplan['Plotted Productive Hour']=workplan['Plotted Phone']+workplan['Plotted Picklist']\n",
    "\n",
    "eps_adherence=dailytracking[['Session Date','EID','Full name','Booking Login ID','LOB','Supervisor','Wave #',\n",
    "                                 'Picklist - off Phone','Ready or Talking','Meeting','Training','Lunch Time','Break Time']]\n",
    "eps_adherence['Actual Downtime']=eps_adherence['Meeting']+eps_adherence['Training']\n",
    "eps_adherence['Session Date']=pd.to_datetime(eps_adherence['Session Date']).dt.date\n",
    "adherence=pd.merge(eps_adherence,workplan,left_on=['Session Date','EID'],right_on=['Date','EID'],how='left')\n",
    "adherence['Actual Productive Hour']=adherence['Picklist - off Phone']+adherence['Ready or Talking']\n",
    "adherence=adherence.rename(columns={'Agent ID':'IEX ID','Picklist - off Phone':'Actual Picklist','Ready or Talking':'Actual Phone',\n",
    "                                    'Lunch Time':'Actual Lunch','Break Time':'Actual Break'})\n",
    "adherence=adherence[['Session Date','EID','Full name','IEX ID','Booking Login ID','LOB','Supervisor','Wave #',\n",
    "                     'Plotted Downtime','Actual Downtime','Plotted Productive Hour','Actual Productive Hour',\n",
    "                     'Plotted Phone','Actual Phone','Plotted Picklist','Actual Picklist',\n",
    "                     'Plotted Lunch','Actual Lunch','Plotted Break','Actual Break']]\n",
    "def downtimedeliveryper(x):\n",
    "    if x['Plotted Downtime']==0 and x['Actual Downtime']!=0:\n",
    "        return 0\n",
    "    elif x['Plotted Downtime']==0 and x['Actual Downtime']==0:\n",
    "        return 1\n",
    "    else:         \n",
    "        return x['Actual Downtime']/x['Plotted Downtime']\n",
    "adherence['%Downtime Delivery']= adherence.apply(downtimedeliveryper, axis=1)\n",
    "\n",
    "def producteddeliveryper(x):\n",
    "    if x['Plotted Productive Hour']==0 and x['Actual Productive Hour']!=0:\n",
    "        return 0\n",
    "    elif x['Plotted Productive Hour']==0 and x['Actual Productive Hour']==0:\n",
    "        return 1\n",
    "    else:         \n",
    "        return x['Actual Productive Hour']/x['Plotted Productive Hour']\n",
    "adherence['%Productive Delivery']= adherence.apply(producteddeliveryper, axis=1)\n",
    "adherence['Lunch variance']=(adherence['Actual Lunch']-adherence['Plotted Lunch'])/adherence['Plotted Lunch']\n",
    "adherence['Break variance']=(adherence['Actual Break']-adherence['Plotted Break'])/adherence['Plotted Break']\n",
    "adherence=adherence[['Session Date','EID','Full name','IEX ID','Booking Login ID','LOB','Supervisor','Wave #',\n",
    "                     'Plotted Downtime','Actual Downtime','%Downtime Delivery','Plotted Productive Hour','Actual Productive Hour',\n",
    "                     '%Productive Delivery','Plotted Phone','Actual Phone','Plotted Picklist','Actual Picklist',\n",
    "                     'Plotted Lunch','Actual Lunch','Lunch variance','Plotted Break','Actual Break','Break variance']]\n",
    "adherence.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "# export to a sheet in Adherence workbook\n",
    "with pd.ExcelWriter(adherence_path, mode=\"a\", engine=\"openpyxl\",if_sheet_exists=\"replace\") as writer1:\n",
    "    adherence.to_excel(writer1, sheet_name=\"process\",index=False)\n",
    "# adherence.to_excel(r\"C:\\Users\\thibaotram.nguyen\\Concentrix Corporation\\Dinh Hoang Nguyen - WFM-internal\\Dispatch files\\Adherence & Daily Tracking\\adherence_test.xlsx\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
