{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime as dt\n",
    "from datetime import time as t\n",
    "from dateutil import relativedelta\n",
    "import numpy as np\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},

   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dinhhoang.nguyen.CONCENTRIX\\OneDrive - Concentrix Corporation\\WFM-internal\n"
     ]
    }
   ],
   "source": [
    "personal_path = os.environ['USERPROFILE']\n",
    "if personal_path == 'C:\\\\Users\\\\dinhhoang.nguyen.CONCENTRIX':\n",
    "    middle_path = r'OneDrive - Concentrix Corporation\\WFM-internal'\n",
    "else:\n",
    "    middle_path = r'Concentrix Corporation\\Dinh Hoang Nguyen - WFM-internal'\n",
    "user_credential = os.path.join(os.environ['USERPROFILE'], middle_path)"

   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_reset = dt(year=2023, month=8, day=1)\n",
    "update_less = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT MASTER ROSTER\n",
    "masterroster = pd.read_json(os.path.join(user_credential, r'DB\\filejson\\masterroster.json'))\n",
    "masterroster['Employee_ID'] = masterroster['Employee_ID'].astype(\"Int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT EPS\n",
    "eps = pd.read_json(os.path.join(r'C:', user_credential, r'DB\\filejson\\eps_full.json'))\n",
    "if update_less is True:\n",
    "    eps = pd.read_json(os.path.join(user_credential, r'DB\\filejson\\eps.json'))\n",
    "else:\n",
    "    eps = pd.read_json(os.path.join(user_credential, r'DB\\filejson\\eps_full.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORT CPI\n",
    "if update_less is True:\n",
    "    cpi = pd.read_json(os.path.join(user_credential, r'DB\\filejson\\cpi.json'))\n",
    "else:\n",
    "    cpi = pd.read_json(os.path.join(user_credential, r'DB\\filejson\\cpi_full.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORT AHT\n",
    "if update_less is True:\n",
    "    aht = pd.read_json(os.path.join(user_credential, r'DB\\filejson\\aht.json'))\n",
    "else:\n",
    "    aht = pd.read_json(os.path.join(user_credential, r'DB\\filejson\\aht_full.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT SCHEDULE\n",
    "if update_less is True:\n",
    "    schedule = pd.read_json(os.path.join(user_credential, r'DB\\filejson\\schedule.json'))\n",
    "else:\n",
    "    schedule = pd.read_json(os.path.join(user_credential, r'DB\\filejson\\schedule_full.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT CUIC\n",
    "if update_less is True:\n",
    "    cuic = pd.read_json(os.path.join(user_credential, r'DB\\filejson\\cuic.json'))\n",
    "else:\n",
    "    cuic = pd.read_json(os.path.join(user_credential, r'DB\\filejson\\cuic_full.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT TL\n",
    "tl = pd.read_json(os.path.join(user_credential, r'DB\\filejson\\tl.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quality\n",
    "if update_less == True:\n",
    "    quality = pd.read_json(os.path.join(user_credential, r'DB\\filejson\\quality.json'))\n",
    "else:\n",
    "    quality = pd.read_json(os.path.join(user_credential, r'DB\\filejson\\quality_full.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frame\n",
    "main_frame = schedule\n",
    "\n",
    "## add Week\n",
    "main_frame['Date'] = pd.to_datetime(main_frame['Date'], errors='coerce')\n",
    "main_frame['Week'] = main_frame['Date'].dt.strftime('%Y%W')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frame\n",
    "main_frame = schedule\n",
    "\n",
    "## add Week\n",
    "main_frame['Date'] = pd.to_datetime(main_frame['Date'], errors='coerce')\n",
    "main_frame['Week'] = main_frame['Date'].dt.strftime('%Y%W')\n",
    "main_frame['Date'] = main_frame['Date'].dt.date\n",
    "\n",
    "## Add LOB Group\n",
    "lob_map = {'EN': 'English', 'VICSP': 'Vietnamese CSP', 'VICSG': 'Vietnamese CSG', 'Senior VICSP': 'Senior CSP', 'NL': 'Unbabel', 'ID4': 'Unbabel', 'HE4': 'Unbabel', 'XT4': 'Unbabel', 'EL': 'Unbabel', 'TR': 'Unbabel', 'KO': 'Unbabel', 'UB CS': 'Unbabel', 'HU': 'Unbabel', 'FR': 'Unbabel', 'ZH': 'Unbabel', 'RU': 'Unbabel', 'UB PL': 'Unbabel', 'PT': 'Unbabel'}\n",
    "## add tenure\n",
    "main_frame['LOB Group'] = main_frame['LOB'].map(lob_map)\n",
    "\n",
    "main_frame = pd.merge(main_frame, masterroster[['Employee_ID', 'Booking Login ID', 'TED Name', 'CUIC Name', 'PST_Start_Date', 'Wave #', 'Role']], left_on='Emp ID', right_on='Employee_ID', how='left')\n",
    "main_frame['PST_Start_Date'] = pd.to_datetime(main_frame['PST_Start_Date'], format='mixed').dt.date\n",
    "def TN(x):\n",
    "    if x['PST_Start_Date'] is pd.NaT:\n",
    "        return 'unknown'\n",
    "    else:\n",
    "        if x['Date'] - x['PST_Start_Date'] >= pd.Timedelta(days=90):\n",
    "            return \"TN\"\n",
    "        else:\n",
    "            return \"NH\"\n",
    "    \n",
    "def tenure_days(x):\n",
    "    if x['PST_Start_Date'] is pd.NaT:\n",
    "        return 'unknown'\n",
    "    else:\n",
    "        days = x['Date'] - x['PST_Start_Date']\n",
    "        if days <= pd.Timedelta(days=30):\n",
    "            return '0-30'\n",
    "        elif days <= pd.Timedelta(days=60):\n",
    "            return '31-60'\n",
    "        elif days <= pd.Timedelta(days=90):\n",
    "            return '61-90'\n",
    "        elif days <= pd.Timedelta(days=120):\n",
    "            return '91-120'\n",
    "        else:\n",
    "            return '120+'\n",
    "    \n",
    "main_frame['Tenure'] = main_frame.apply(TN, axis=1)\n",
    "main_frame['Tenure days'] = main_frame.apply(tenure_days, axis=1)\n",
    "main_frame = main_frame.drop(columns=['Employee_ID'])\n",
    "## add supervisor\n",
    "main_frame = pd.merge(main_frame, tl[['Emp ID', 'Supervisor']], on='Emp ID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "## cpi processing\n",
    "aht_cpi = cpi\n",
    "\n",
    "## add phone cases\n",
    "aht_cpi['#phone'] = aht_cpi.apply(lambda x: x['Number of Records'] if x['Channel'] == 'phone' else 0, axis=1)\n",
    "aht_cpi['#non-phone'] = aht_cpi.apply(lambda x: x['Number of Records'] if x['Channel'] != 'phone' else 0, axis=1)\n",
    "\n",
    "aht_cpi = aht_cpi.groupby(['Employee_ID', 'Date'], as_index=False)[['#phone', '#non-phone']].sum()\n",
    "aht_cpi['total_cases'] = aht_cpi['#phone'] + aht_cpi['#non-phone']\n",
    "### add to main frame\n",
    "aht_cpi['Date'] = aht_cpi['Date'].dt.date\n",
    "main_frame = pd.merge(main_frame, aht_cpi, left_on=['Emp ID', 'Date'], right_on=['Employee_ID', 'Date'], how='left')\n",
    "main_frame = main_frame.drop(columns={'Employee_ID'})\n",
    "main_frame[['#phone', '#non-phone', 'total_cases']] = main_frame[['#phone', '#non-phone', 'total_cases']].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dinhhoang.nguyen.CONCENTRIX\\AppData\\Local\\Temp\\VSCodePortable-x64Temp\\ipykernel_14348\\1391897611.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  aht_lob['Date'] = pd.to_datetime(aht_lob['Date'], format ='mixed')\n"
     ]
    }
   ],
   "source": [
    "## AHT\n",
    "aht_aht = aht.drop(columns=['Start Time', 'End Time', '\"Handling Time\"', 'First Email Id'])\n",
    "\n",
    "## add Eliminate Phone\n",
    "def eliminate_phone(x):\n",
    "    if x['Item Channel'] =='Phone' and x['Topic'] =='Unknown':\n",
    "        return \"Notphone\"\n",
    "    else:\n",
    "        return x['Item Channel']\n",
    "aht_aht['Eliminate Phone'] = aht_aht.apply(eliminate_phone, axis=1)\n",
    "\n",
    "aht_mr = masterroster[['Employee_ID', 'PST_Start_Date', 'CUIC Name', 'Full name', 'Role', 'TED Name', 'Wave #']]\n",
    "\n",
    "aht_aht = pd.merge(aht_aht, aht_mr, left_on='Staff', right_on='TED Name', how='left')\n",
    "\n",
    "aht_aht = pd.merge(aht_aht, tl, left_on ='Employee_ID_x', right_on = 'Emp ID', how='left')\n",
    "aht_lob = schedule[['Emp ID', 'Date', 'LOB']]\n",
    "aht_lob['Date'] = pd.to_datetime(aht_lob['Date'], format ='mixed')\n",
    "aht_aht = pd.merge(aht_aht, aht_lob, left_on = ['Employee_ID_x', 'Date'], right_on=['Emp ID', 'Date'], how='left')\n",
    "aht_aht = aht_aht.drop(columns=['Employee_ID_y', 'Emp ID_x', 'Emp ID_y'])\n",
    "aht_aht = aht_aht.rename(columns={'Employee_ID_x':'Employee_ID'})\n",
    "#Add talk time\n",
    "def talk_time(x):\n",
    "    try:\n",
    "        from_left = 11\n",
    "        to_right = str(x['Tooltip Phone Time']).find(' Wrap Time')\n",
    "        return int(x['Tooltip Phone Time'][from_left:to_right])\n",
    "    except:\n",
    "        return 0\n",
    "def wrap_time(x):\n",
    "    try:\n",
    "        from_left = int(str(x['Tooltip Phone Time']).find('Wrap Time'))+11\n",
    "        to_right = str(x['Tooltip Phone Time']).find(' Hold Time')\n",
    "        return int(x['Tooltip Phone Time'][from_left:to_right])\n",
    "    except:\n",
    "        return 0\n",
    "def hold_time(x):\n",
    "    try:\n",
    "        from_left = int(str(x['Tooltip Phone Time']).find('Hold Time'))+10\n",
    "        return int(x['Tooltip Phone Time'][from_left:])\n",
    "    except:\n",
    "        return 0    \n",
    "aht_aht['Talk Time'] = aht_aht.apply(talk_time, axis=1)\n",
    "aht_aht['Wrap Time'] = aht_aht.apply(wrap_time, axis=1)\n",
    "aht_aht['Hold Time'] = aht_aht.apply(hold_time, axis=1)\n",
    "\n",
    "def act_handling_time(x):\n",
    "    if x['Eliminate Phone'] =='Phone':\n",
    "        return x['Talk Time'] + x['Wrap Time'] + x['Hold Time']\n",
    "    else:\n",
    "        return x['Handling Time']\n",
    "\n",
    "# add realchannel\n",
    "def realchannel(x):\n",
    "    if x['Item Channel'] == 'Phone' and x['Topic'] == 'Unknown':\n",
    "        return \"Phone1\"\n",
    "    else:\n",
    "        return x['Item Channel']\n",
    "aht_aht['Real Channel'] = aht_aht.apply(realchannel, axis=1)\n",
    "\n",
    "# add total inbound\n",
    "def totalinbound(x):\n",
    "    if x['Item Channel'] in ['Email', 'Live Chat', 'Messaging', 'Unknown']:\n",
    "        return x['Handling Time']\n",
    "    else:\n",
    "        return x['Talk Time'] + x['Wrap Time'] + x['Hold Time']\n",
    "\n",
    "aht_aht['Total Inbound'] = aht_aht.apply(totalinbound, axis=1)\n",
    "\n",
    "#add Act handling time\n",
    "aht_aht['Act Handling Time'] = aht_aht.apply(act_handling_time, axis=1)\n",
    "#Date to_datetime\n",
    "aht_aht['Date'] = pd.to_datetime(aht_aht['Date'], format='mixed').dt.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time & count for AHT\n",
    "aht_aht['AHT Phone time'] = aht_aht.apply(lambda x: x['Act Handling Time'] if x['Eliminate Phone'] == 'Phone' else 0, axis=1)\n",
    "aht_aht['AHT Phone count'] = aht_aht.apply(lambda x: 1 if x['Eliminate Phone'] == 'Phone' else 0, axis=1)\n",
    "\n",
    "aht_aht['AHT Non-phone time'] = aht_aht.apply(lambda x: x['Act Handling Time'] if x['Eliminate Phone'] in ['Email', 'Unknown', 'Messaging', 'SNR', 'BH'] else 0, axis=1)\n",
    "aht_aht['AHT Non-phone count'] = aht_aht.apply(lambda x: 1 if x['Eliminate Phone'] in ['Email', 'Unknown', 'Messaging', 'SNR', 'BH'] else 0, axis=1)\n",
    "\n",
    "aht_aht['Overall AHT time'] = aht_aht.apply(lambda x: x['Act Handling Time'] if x['Eliminate Phone'] != 'Notphone' else 0, axis=1)\n",
    "aht_aht['Overall AHT count'] = aht_aht.apply(lambda x: 1 if x['Eliminate Phone'] != 'Notphone' else 0, axis=1)\n",
    "\n",
    "aht_aht['Hold (phone) time'] = aht_aht.apply(lambda x: x['Hold Time'] if x['Eliminate Phone'] == 'Phone' else 0, axis=1)\n",
    "aht_aht['Hold (phone) count'] = aht_aht.apply(lambda x: 1 if x['Eliminate Phone'] == 'Phone' else 0, axis=1)\n",
    "\n",
    "aht_aht['AACW (phone) time'] = aht_aht.apply(lambda x: x['Wrap Time'] if x['Eliminate Phone'] == 'Phone' else 0, axis=1)\n",
    "aht_aht['AACW (phone) count'] = aht_aht.apply(lambda x: 1 if x['Eliminate Phone'] == 'Phone' else 0, axis=1)\n",
    "\n",
    "aht_aht['Avg Talk Time time'] = aht_aht.apply(lambda x: x['Talk Time'] if x['Eliminate Phone'] == 'Phone' else 0, axis=1)\n",
    "aht_aht['Avg Talk Time count'] = aht_aht.apply(lambda x: 1 if x['Eliminate Phone'] == 'Phone' else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by AHT\n",
    "aht_aht = aht_aht.groupby(['Date', 'Employee_ID'], as_index=False)[['AHT Phone time', 'AHT Phone count', 'AHT Non-phone time', 'AHT Non-phone count', 'Overall AHT time', 'Overall AHT count', 'Hold (phone) time', 'Hold (phone) count', 'AACW (phone) time', 'AACW (phone) count', 'Avg Talk Time time', 'Avg Talk Time count']].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add aht_aht to main frame\n",
    "main_frame['Date'] = pd.to_datetime(main_frame['Date'], format='mixed').dt.strftime('%Y-%m-%d')\n",
    "main_frame = pd.merge(main_frame, aht_aht, left_on =['Emp ID', 'Date'], right_on=['Employee_ID', 'Date'], how='left')\n",
    "main_frame = main_frame.drop(columns={'Employee_ID'})\n",
    "main_frame['AHT Phone time'] = main_frame['AHT Phone time'].fillna(0)\n",
    "main_frame['AHT Phone count'] = main_frame['AHT Phone count'].fillna(0)\n",
    "\n",
    "main_frame['AHT Non-phone time'] = main_frame['AHT Non-phone time'].fillna(0)\n",
    "main_frame['AHT Non-phone count'] = main_frame['AHT Non-phone count'].fillna(0)\n",
    "\n",
    "main_frame['Overall AHT time'] = main_frame['Overall AHT time'].fillna(0)\n",
    "main_frame['Overall AHT count'] = main_frame['Overall AHT count'].fillna(0)\n",
    "\n",
    "main_frame['Hold (phone) time'] = main_frame['Hold (phone) time'].fillna(0)\n",
    "main_frame['Hold (phone) count'] = main_frame['Hold (phone) count'].fillna(0)\n",
    "\n",
    "main_frame['AACW (phone) time'] = main_frame['AACW (phone) time'].fillna(0)\n",
    "main_frame['AACW (phone) count'] = main_frame['AACW (phone) count'].fillna(0)\n",
    "\n",
    "main_frame['Avg Talk Time time'] = main_frame['Avg Talk Time time'].fillna(0)\n",
    "main_frame['Avg Talk Time count'] = main_frame['Avg Talk Time count'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cuic\n",
    "aht_cuic = cuic\n",
    "aht_cuic = aht_cuic.groupby(['Employee_ID', 'Session Date'], as_index=False)[['AgentAvailTime']].sum()\n",
    "aht_cuic['AgentAvailTime']=aht_cuic['AgentAvailTime']*24\n",
    "aht_cuic['Session Date'] = pd.to_datetime(aht_cuic['Session Date'], format='mixed').dt.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add cuic to main frame\n",
    "main_frame = pd.merge(main_frame, aht_cuic, left_on =['Emp ID', 'Date'], right_on=['Employee_ID', 'Session Date'], how='left')\n",
    "main_frame = main_frame.drop(columns={'Employee_ID', 'Session Date'})\n",
    "main_frame['AgentAvailTime'] = main_frame['AgentAvailTime'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eps\n",
    "aht_eps = eps\n",
    "# calculate time\n",
    "aht_eps['phone_time'] = aht_eps.apply(lambda x: x['Total Time'] if x['BPE Code'] in ['Ready or Talking','Finalize Call'] else 0, axis=1)/3600\n",
    "aht_eps['nonphone_time'] = aht_eps.apply(lambda x: x['Total Time'] if x['BPE Code'] == 'Picklist - off Phone' else 0, axis=1)/3600\n",
    "aht_eps['productive_time'] = aht_eps.apply(lambda x: x['Total Time'] if x['BPE Code'] in ['Picklist - off Phone', 'Ready or Talking''Finalize Call','RONA','Unscheduled Picklist','Payment Processing','Social Media','Mass Issue','Project'] else 0, axis=1)/3600\n",
    "\n",
    "## add session date\n",
    "aht_eps['Session login date'] = pd.to_datetime(aht_eps['Session login date'], format='mixed').dt.date\n",
    "aht_eps['Session login date-1'] = aht_eps['Session login date'] - pd.Timedelta(days=1)\n",
    "aht_eps = pd.merge(aht_eps, schedule[['Emp ID', 'Date', 'Shift_type']], left_on=['EID', 'Session login date-1'], right_on=['Emp ID', 'Date'], how='left')\n",
    "\n",
    "def session_date(x):\n",
    "    if x['Shift_type'] == 'NS' and x['Session login time'] <= t(12, 0, 0):\n",
    "        return x['Session login date-1']\n",
    "    else:\n",
    "        return x['Session login date']\n",
    "    \n",
    "aht_eps['Session login time'] = pd.to_datetime(aht_eps['Session login time'], format='mixed').dt.time\n",
    "aht_eps['Session date'] = aht_eps.apply(session_date, axis=1)\n",
    "\n",
    "aht_eps = aht_eps.groupby(['EID', 'Session date'], as_index=False)[['phone_time', 'nonphone_time', 'productive_time']].sum()\n",
    "aht_eps = aht_eps.rename(columns={'Session date': 'Date'})\n",
    "\n",
    "aht_eps['Date'] = pd.to_datetime(aht_eps['Date'], format = 'mixed').dt.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "## add aht_eps to main frame\n",
    "main_frame = pd.merge(main_frame, aht_eps, left_on =['Emp ID', 'Date'], right_on=['EID', 'Date'], how='left')\n",
    "main_frame = main_frame.drop(columns={'EID'})\n",
    "main_frame[['phone_time', 'nonphone_time', 'productive_time']] = main_frame[['phone_time', 'nonphone_time', 'productive_time']].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_frame['Date'] = pd.to_datetime(main_frame['Date'], format='mixed').dt.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "quality = quality.rename(columns={' score_question_weight': 'score_question_weight'})\n",
    "quality[['score_n', 'score_question_weight']] = quality[['score_n', 'score_question_weight']].fillna(0)\n",
    "\n",
    "quality['customer_score'] = quality.apply(lambda x: x['score_n'] if x['sections'] == 'CUSTOMER' else 0, axis=1)\n",
    "quality['customer_weight'] = quality.apply(lambda x: x['score_question_weight'] if x['sections'] == 'CUSTOMER' else 0, axis=1)\n",
    "\n",
    "quality['business_score'] = quality.apply(lambda x: x['score_n'] if x['sections'] == 'BUSINESS' else 0, axis=1)\n",
    "quality['business_weight'] = quality.apply(lambda x: x['score_question_weight'] if x['sections'] == 'BUSINESS' else 0, axis=1)\n",
    "\n",
    "quality['compliance_score'] = quality.apply(lambda x: x['score_n'] if x['sections'] == 'COMPLIANCE' else 0, axis=1)\n",
    "quality['compliance_weight'] = quality.apply(lambda x: x['score_question_weight'] if x['sections'] == 'COMPLIANCE' else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by quality\n",
    "quality = quality.groupby(['agent_username', 'eval_date'], as_index=False)[['customer_score', 'customer_weight', 'business_score', 'business_weight', 'compliance_score', 'compliance_weight']].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add quality to main frame\n",
    "\n",
    "main_frame = pd.merge(main_frame, quality, left_on=['Booking Login ID', 'Date'], right_on=['agent_username', 'eval_date'], how='left')\n",
    "main_frame[['customer_score', 'customer_weight', 'business_score', 'business_weight', 'compliance_score', 'compliance_weight']] = main_frame[['customer_score', 'customer_weight', 'business_score', 'business_weight', 'compliance_score', 'compliance_weight']].fillna(0)\n",
    "main_frame = main_frame.drop(columns=['agent_username', 'eval_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change datatype mainframe['Date'] to json\n",
    "main_frame['Date'] = pd.to_datetime(main_frame['Date'], format='mixed').dt.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSAT\n",
    "if update_less == True:\n",
    "    csat = pd.read_json(os.path.join(user_credential, r'DB\\filejson\\csat.json'))\n",
    "else:\n",
    "    csat = pd.read_json(os.path.join(user_credential, r'DB\\filejson\\csat_full.json'))\n",
    "    \n",
    "csat['Date'] = csat['Date'].dt.date\n",
    "## get LOB\n",
    "csat = pd.merge(csat, schedule[['Emp ID', 'Date', 'LOB']], left_on=['Employee_ID', 'Date'], right_on=['Emp ID', 'Date'], how='left')\n",
    "csat = csat.drop(columns={'Emp ID'})\n",
    "csat = csat.dropna(subset=['LOB'])\n",
    "\n",
    "# count phone survey\n",
    "def phone_surveycount_overall(x):\n",
    "    if x['Channel'] == 'phone':\n",
    "        if x['LOB'] != 'VICSG':\n",
    "            return 1\n",
    "        else:\n",
    "            if x['Language'] == 'Vietnamese':\n",
    "                return 1\n",
    "            else:\n",
    "                return 0\n",
    "    else:\n",
    "        return 0\n",
    "# count phone csat\n",
    "def phone_csatcount_overall(x):\n",
    "    if x['Channel'] == 'phone':\n",
    "        if x['Csat 2.0 Score'] in ['Satisfied', 'Very Satisfied']:\n",
    "            if x['LOB'] != 'VICSG':\n",
    "                return 1\n",
    "            else:\n",
    "                if x['Language'] == 'Vietnamese':\n",
    "                    return 1\n",
    "                else:\n",
    "                    return 0\n",
    "        else:\n",
    "            return 0\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# count non phone survey\n",
    "def nonphone_surveycount_overall(x):\n",
    "    if x['Channel'] != 'phone':\n",
    "        if x['LOB'] != 'VICSG':\n",
    "            return 1\n",
    "        else:\n",
    "            if x['Language'] == 'Vietnamese':\n",
    "                return 1\n",
    "            else:\n",
    "                return 0\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def nonphone_csatcount_overall(x):\n",
    "    if x['Channel'] != 'phone':\n",
    "        if x['Csat 2.0 Score'] in ['Satisfied', 'Very Satisfied']:\n",
    "            if x['LOB'] != 'VICSG':\n",
    "                return 1\n",
    "            else:\n",
    "                if x['Language'] == 'Vietnamese':\n",
    "                    return 1\n",
    "                else:\n",
    "                    return 0\n",
    "        else:\n",
    "            return 0\n",
    "    else:\n",
    "        return 0\n",
    "        \n",
    "csat['phone_survey'] = csat.apply(phone_surveycount_overall, axis=1)\n",
    "csat['nonphone_survey'] = csat.apply(nonphone_surveycount_overall, axis=1)\n",
    "csat['phone_csat'] = csat.apply(phone_csatcount_overall, axis=1)\n",
    "csat['nonphone_csat'] = csat.apply(nonphone_csatcount_overall, axis=1)\n",
    "csat['Date'] = pd.to_datetime(csat['Date'], format='mixed').dt.strftime('%Y-%m-%d')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarise csat\n",
    "csat = csat.groupby(['Employee_ID', 'Date'], as_index=False)[['phone_survey', 'nonphone_survey', 'phone_csat', 'nonphone_csat']].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add csat to main frame\n",
    "main_frame = pd.merge(main_frame, csat, left_on=['Emp ID', 'Date'], right_on=['Employee_ID', 'Date'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSAT_reso Reso\n",
    "csat_reso = pd.read_json(os.path.join(user_credential, r'DB\\filejson\\csat_reso_full.json'))\n",
    "csat_reso['Date'] = csat_reso['Date'].dt.date\n",
    "\n",
    "## get LOB\n",
    "csat_reso = pd.merge(csat_reso, schedule[['Emp ID', 'Date', 'LOB']], left_on=['Employee_ID', 'Date'], right_on=['Emp ID', 'Date'], how='left')\n",
    "csat_reso = csat_reso.drop(columns={'Emp ID'})\n",
    "csat_reso = csat_reso.dropna(subset=['LOB'])\n",
    "\n",
    "# count phone survey\n",
    "def phone_surveycount_overall(x):\n",
    "    if x['Channel'] == 'phone':\n",
    "        if x['LOB'] != 'VICSG':\n",
    "            return 1\n",
    "        else:\n",
    "            if x['Language'] == 'Vietnamese':\n",
    "                return 1\n",
    "            else:\n",
    "                return 0\n",
    "    else:\n",
    "        return 0\n",
    "# count phone csat_reso\n",
    "def phone_csat_resocount_overall(x):\n",
    "    if x['Channel'] == 'phone':\n",
    "        if x['Csat 2.0 Score'] in ['Satisfied', 'Very Satisfied']:\n",
    "            if x['LOB'] != 'VICSG':\n",
    "                return 1\n",
    "            else:\n",
    "                if x['Language'] == 'Vietnamese':\n",
    "                    return 1\n",
    "                else:\n",
    "                    return 0\n",
    "        else:\n",
    "            return 0\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# count non phone survey\n",
    "def nonphone_surveycount_overall(x):\n",
    "    if x['Channel'] != 'phone':\n",
    "        if x['LOB'] != 'VICSG':\n",
    "            return 1\n",
    "        else:\n",
    "            if x['Language'] == 'Vietnamese':\n",
    "                return 1\n",
    "            else:\n",
    "                return 0\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def nonphone_csat_resocount_overall(x):\n",
    "    if x['Channel'] != 'phone':\n",
    "        if x['Csat 2.0 Score'] in ['Satisfied', 'Very Satisfied']:\n",
    "            if x['LOB'] != 'VICSG':\n",
    "                return 1\n",
    "            else:\n",
    "                if x['Language'] == 'Vietnamese':\n",
    "                    return 1\n",
    "                else:\n",
    "                    return 0\n",
    "        else:\n",
    "            return 0\n",
    "    else:\n",
    "        return 0\n",
    "        \n",
    "csat_reso['phone_survey_reso'] = csat_reso.apply(phone_surveycount_overall, axis=1)\n",
    "csat_reso['nonphone_survey_reso'] = csat_reso.apply(nonphone_surveycount_overall, axis=1)\n",
    "csat_reso['phone_csat_reso'] = csat_reso.apply(phone_csat_resocount_overall, axis=1)\n",
    "csat_reso['nonphone_csat_reso'] = csat_reso.apply(nonphone_csat_resocount_overall, axis=1)\n",
    "csat_reso['Date'] = pd.to_datetime(csat_reso['Date'], format='mixed').dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# summarise csat_reso\n",
    "csat_reso = csat_reso.groupby(['Employee_ID', 'Date'], as_index=False)[['phone_survey_reso', 'nonphone_survey_reso', 'phone_csat_reso', 'nonphone_csat_reso']].sum()\n",
    "\n",
    "# add csat_reso to main frame\n",
    "main_frame = main_frame.drop(columns={'Employee_ID'})\n",
    "main_frame = pd.merge(main_frame, csat_reso, left_on=['Emp ID', 'Date'], right_on=['Employee_ID', 'Date'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PSAT\n",
    "psat = pd.read_json(os.path.join(user_credential, r'DB\\filejson\\psat.json'))\n",
    "\n",
    "def survey_count(x):\n",
    "    if x['Agent understood my question'] != 'No Answer':\n",
    "        q1 = 1\n",
    "    else:\n",
    "        q1 = 0\n",
    "    if x['Agent did everything possible to help me'] != 'No Answer':\n",
    "        q2 = 1\n",
    "    else:\n",
    "        q2 = 0\n",
    "    survey_count = q1 + q2\n",
    "    return survey_count\n",
    "\n",
    "def survey_count_vnese(x):\n",
    "    if x['Agent understood my question'] != 'No Answer' and x['Language'] == 'Vietnamese':\n",
    "        q1 = 1\n",
    "    else:\n",
    "        q1 = 0\n",
    "    if x['Agent did everything possible to help me'] != 'No Answer' and x['Language'] == 'Vietnamese':\n",
    "        q2 = 1\n",
    "    else:\n",
    "        q2 = 0\n",
    "    survey_count = q1 + q2\n",
    "    return survey_count\n",
    "\n",
    "def survey_count_american(x):\n",
    "    if x['Agent understood my question'] != 'No Answer' and x['Language'] == 'English (American)':\n",
    "        q1 = 1\n",
    "    else:\n",
    "        q1 = 0\n",
    "    if x['Agent did everything possible to help me'] != 'No Answer' and x['Language'] == 'English (American)':\n",
    "        q2 = 1\n",
    "    else:\n",
    "        q2 = 0\n",
    "    survey_count = q1 + q2\n",
    "    return survey_count\n",
    "\n",
    "def survey_count_britain(x):\n",
    "    if x['Agent understood my question'] != 'No Answer' and x['Language'] == 'English (Great Britain)':\n",
    "        q1 = 1\n",
    "    else:\n",
    "        q1 = 0\n",
    "    if x['Agent did everything possible to help me'] != 'No Answer' and x['Language'] == 'English (Great Britain)':\n",
    "        q2 = 1\n",
    "    else:\n",
    "        q2 = 0\n",
    "    survey_count = q1 + q2\n",
    "    return survey_count\n",
    "\n",
    "\n",
    "def psat_count(x):\n",
    "    if x['Agent understood my question'] in ['Satisfied', 'Very Satisfied']:\n",
    "        q1 = 1\n",
    "    else:\n",
    "        q1 = 0\n",
    "    if x['Agent did everything possible to help me'] in ['Satisfied', 'Very Satisfied']:\n",
    "        q2 = 1\n",
    "    else:\n",
    "        q2 = 0\n",
    "    psat_count = q1 + q2\n",
    "    return psat_count\n",
    "\n",
    "def psat_count_vnese(x):\n",
    "    if x['Agent understood my question'] in ['Satisfied', 'Very Satisfied'] and x['Language'] == 'Vietnamese':\n",
    "        q1 = 1\n",
    "    else:\n",
    "        q1 = 0\n",
    "    if x['Agent did everything possible to help me'] in ['Satisfied', 'Very Satisfied'] and x['Language'] == 'Vietnamese':\n",
    "        q2 = 1\n",
    "    else:\n",
    "        q2 = 0\n",
    "    psat_count = q1 + q2\n",
    "    return psat_count\n",
    "\n",
    "def psat_count_american(x):\n",
    "    if x['Agent understood my question'] in ['Satisfied', 'Very Satisfied'] and x['Language'] == 'English (American)':\n",
    "        q1 = 1\n",
    "    else:\n",
    "        q1 = 0\n",
    "    if x['Agent did everything possible to help me'] in ['Satisfied', 'Very Satisfied'] and x['Language'] == 'English (American)':\n",
    "        q2 = 1\n",
    "    else:\n",
    "        q2 = 0\n",
    "    psat_count = q1 + q2\n",
    "    return psat_count\n",
    "\n",
    "def psat_count_britain(x):\n",
    "    if x['Agent understood my question'] in ['Satisfied', 'Very Satisfied'] and x['Language'] == 'English (Great Britain)':\n",
    "        q1 = 1\n",
    "    else:\n",
    "        q1 = 0\n",
    "    if x['Agent did everything possible to help me'] in ['Satisfied', 'Very Satisfied'] and x['Language'] == 'English (Great Britain)':\n",
    "        q2 = 1\n",
    "    else:\n",
    "        q2 = 0\n",
    "    psat_count = q1 + q2\n",
    "    return psat_count\n",
    "\n",
    "psat['psat_survey'] = psat.apply(survey_count, axis=1)\n",
    "psat['psat_count'] = psat.apply(psat_count, axis=1)\n",
    "\n",
    "psat['psat_survey_vnese'] = psat.apply(survey_count_vnese, axis=1)\n",
    "psat['psat_count_vnese'] = psat.apply(psat_count_vnese, axis=1)\n",
    "\n",
    "psat['psat_survey_american'] = psat.apply(survey_count_american, axis=1)\n",
    "psat['psat_count_american'] = psat.apply(psat_count_american, axis=1)\n",
    "\n",
    "psat['psat_survey_britain'] = psat.apply(survey_count_britain, axis=1)\n",
    "psat['psat_count_britain'] = psat.apply(psat_count_britain, axis=1)\n",
    "# add ID\n",
    "psat = pd.merge(psat, masterroster[['Employee_ID', 'TED Name']], left_on='Staff Name', right_on='TED Name', how='left')\n",
    "psat = psat.drop(columns=['TED Name'])\n",
    "psat['Date'] = pd.to_datetime(psat['Date'], format='mixed').dt.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarise psat\n",
    "psat = psat.groupby(['Employee_ID', 'Date'], as_index=False)[['psat_survey', 'psat_count', 'psat_survey_vnese', 'psat_count_vnese', 'psat_survey_american', 'psat_count_american', 'psat_survey_britain', 'psat_count_britain']].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add psat to main frame\n",
    "main_frame = pd.merge(main_frame, psat, left_on=['Emp ID', 'Date'], right_on=['Employee_ID', 'Date'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove abundant cols\n",
    "main_frame = main_frame.drop(columns={'Employee_ID_x', 'Employee_ID_y'})\n",
    "# fillna\n",
    "main_frame[['psat_survey', 'psat_count', 'phone_survey', 'nonphone_survey', 'phone_csat', 'nonphone_csat']] = main_frame[['psat_survey', 'psat_count', 'phone_survey', 'nonphone_survey', 'phone_csat', 'nonphone_csat']].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get kpi_target\n",
    "kpi_target = pd.read_json(os.path.join(user_credential, r'DB\\filejson\\kpi_target.json'))\n",
    "main_frame['Week'] = main_frame['Week'].astype('int64')\n",
    "main_frame = pd.merge(main_frame, kpi_target, on=['Week', 'Tenure days', 'LOB Group'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get attendance\n",
    "attendance = pd.read_json(os.path.join(user_credential, r'DB\\filejson\\booking_attendance.json'))\n",
    "attendance['Date'] = pd.to_datetime(attendance['Date'], format='mixed').dt.strftime('%Y-%m-%d')\n",
    "# add attendance to main frame\n",
    "main_frame = pd.merge(main_frame, attendance[['Emp ID', 'Date', 'Actual Leave', 'Attendance', 'Total scheduled']], on=['Emp ID', 'Date'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get RONA\n",
    "rona = pd.read_json(os.path.join(user_credential, r'DB\\filejson\\rona.json'))\n",
    "rona = rona.groupby(['Session Date', 'Employee_ID'], as_index=False)['RONA'].sum()\n",
    "rona['Session Date'] = pd.to_datetime(rona['Session Date'], format='mixed').dt.strftime('%Y-%m-%d')\n",
    "\n",
    "## Add Rona to main frame\n",
    "main_frame = pd.merge(main_frame, rona, left_on=['Emp ID', 'Date'], right_on=['Employee_ID', 'Session Date'], how='left')\n",
    "main_frame = main_frame.drop(columns={'Employee_ID', 'Session Date'})\n",
    "main_frame['RONA'] = main_frame['RONA'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_frame['PST_Start_Date'] = pd.to_datetime(main_frame['PST_Start_Date'], format='mixed').dt.strftime('%Y-%m-%d')\n",
    "main_frame['Date'] = pd.to_datetime(main_frame['Date'], format='mixed').dt.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to json\n",
    "if update_less is False:\n",
    "    main_frame.loc[(pd.to_datetime(main_frame['Date'], format='mixed')<time_reset)&(pd.to_datetime(main_frame['Date'], format='mixed')>dt(year=2023, month=1, day=1))].to_json(os.path.join(user_credential, r'DB\\filejson\\kpi_storage.json'), orient='records')\n",
    "else:\n",
    "    main_storage = pd.read_json(os.path.join(user_credential, r'DB\\filejson\\kpi_storage.json'))\n",
    "    main_frame = pd.concat([main_storage, main_frame.loc[pd.to_datetime(main_frame['Date'], format='mixed')>=time_reset]])\n",
    "    main_frame['Date'] = pd.to_datetime(main_frame['Date'], format='mixed').dt.strftime('%Y-%m-%d')\n",
    "    # main_frame.to_json(os.path.join(user_credential, r'DB\\filejson\\kpi.json'), orient='records')\n",
    "    main_frame.to_csv(os.path.join(user_credential, r'DB\\filecsv\\[BcomDB] KPI.csv'), index=False)\n",
    "    main_frame.to_csv(os.path.join(personal_path, r'Concentrix Corporation\\Tung Quan Le - BKN\\AgentDetail\\[BcomDB] KPI.csv'), index=False)\n",
    "# main_frame.to_csv(os.path.join(r'C:', user_credential, r'DB\\filecsv\\kpi.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ha Thanh Le Xinh Dep\n",
      "Toi that pro\n"
     ]
    }
   ],
   "source": [
    "print(\"Ha Thanh Le Xinh Dep 10 dim\")\n",
    "print(\"Toi that pro\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
