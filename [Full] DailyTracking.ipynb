{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ae32ce3-3d55-4e23-815b-09b824609d00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime as dt\n",
    "from datetime import time as t\n",
    "from datetime import timedelta\n",
    "from pandas.tseries.offsets import MonthEnd\n",
    "from IPython.display import display\n",
    "import sqlite3\n",
    "import json\n",
    "import numpy as np\n",
    "import re\n",
    "from openpyxl import load_workbook\n",
    "import xlsxwriter\n",
    "import requests\n",
    "from requests.auth import HTTPBasicAuth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfb472b5-2204-461b-bf5f-9a8cfd867110",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FUNCTION TO IMPORT FOLDERS\n",
    "def import_csv(path):\n",
    "    raw = []\n",
    "    for file in os.listdir(path):\n",
    "        if file.endswith(\".csv\"):\n",
    "            file_path = os.path.join(path, file)\n",
    "            file_data = pd.read_csv(file_path)\n",
    "            file_data[\"filename\"] = file\n",
    "            raw.append(file_data)\n",
    "            final_raw = pd.concat(raw, ignore_index=True)\n",
    "    return final_raw\n",
    "    \n",
    "def import_xlsx(path, sheet_name):\n",
    "    raw = []\n",
    "    for file in os.listdir(path):\n",
    "        if file.endswith(\".xlsx\"):\n",
    "            file_path = os.path.join(path, file)\n",
    "            file_data = pd.read_excel(file_path, engine=\"openpyxl\", sheet_name = sheet_name)\n",
    "            file_data[\"filename\"] = file\n",
    "            raw.append(file_data)\n",
    "            final_raw = pd.concat(raw, ignore_index=True)\n",
    "    return final_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3d1b915-ff20-47d6-bb75-631d76a6ad75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# source\n",
    "personal_path = os.environ['USERPROFILE']\n",
    "if personal_path in ['C:\\\\Users\\\\dinhhoang.nguyen.CONCENTRIX', 'C:\\\\Users\\\\ADMIN']:\n",
    "    middle_path = r'OneDrive - Concentrix Corporation\\WFM-internal'\n",
    "else:\n",
    "    middle_path = r'Concentrix Corporation\\Dinh Hoang Nguyen - WFM-internal'\n",
    "user_credential = os.path.join(os.environ['USERPROFILE'], middle_path)\n",
    "# EPS path\n",
    "eps_path = os.path.join(\"C:\", user_credential, r\"Data\\EPS Tableau\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d3d4d5a-7336-418e-91c7-fae0a4962133",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_20908\\242608621.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  masterroster_daily['Employee_ID'] = masterroster_daily['Employee_ID'].astype(\"Int64\")\n"
     ]
    }
   ],
   "source": [
    "# IMPORT MASTER ROSTER\n",
    "masterroster = pd.read_json(os.path.join(user_credential, r'DB\\filejson\\masterroster.json'))\n",
    "masterroster_daily=masterroster[['Employee_ID','TED Name', 'PST_Start_Date', 'Role','Booking Login ID','Full name','Wave #']]\n",
    "masterroster_daily['Employee_ID'] = masterroster_daily['Employee_ID'].astype(\"Int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5194b706-8b6c-4068-a856-25ec608a1896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT OT\n",
    "ot = pd.read_json(os.path.join(user_credential, r'DB\\filejson\\ot_full.json'))\n",
    "ot_daily=ot[['Emp ID','Date','OT']]\n",
    "ot_daily=ot_daily.groupby(['Emp ID','Date'], as_index=False).sum()\n",
    "ot_daily['Emp ID']=ot_daily['Emp ID'].astype(\"Int64\")\n",
    "ot_daily['Date'] = pd.to_datetime(ot_daily['Date'], format=\"mixed\").dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91103c03-eb6a-45fb-ac19-80c75abbcfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT RAMCO\n",
    "ramco_daily = pd.read_json(os.path.join(user_credential, r'DB\\filejson\\ramco_full.json'))\n",
    "ramco_daily['Date']=pd.to_datetime(ramco_daily['Date'],format='mixed').dt.date\n",
    "ramco_daily['EID'] = ramco_daily['EID'].astype(\"Int64\")\n",
    "ramco_daily['Value']=ramco_daily['Value'].fillna(0)\n",
    "ramco_daily=ramco_daily.rename(columns={'Value':'RAMCO'})\n",
    "ramco_ot_daily=pd.merge(ramco_daily,ot_daily,left_on=['EID','Date'],right_on=['Emp ID','Date'],how='left')\n",
    "def OTREGISTERED_func(x):\n",
    "    if x['RAMCO'] =='PO' or x['RAMCO'] =='PH' :\n",
    "        return x['OT']/24\n",
    "    elif x['RAMCO'] =='WO' or x['RAMCO'] =='AL' or x['RAMCO'] =='SL' or x['RAMCO'] =='HO':\n",
    "        return 0 \n",
    "    elif x['RAMCO'] =='HAL' :\n",
    "        return 3.75/24\n",
    "    else:\n",
    "        return x['OT']/24+7.5/24\n",
    "ramco_ot_daily['OT Registered'] = ramco_ot_daily.apply(OTREGISTERED_func, axis=1)\n",
    "ramco_ot_daily=ramco_ot_daily[['EID','Date','RAMCO','OT','OT Registered']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b2075d5-e146-4373-8ddb-a9d658ec38ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT RAMCOOT\n",
    "ramcoot = pd.read_json(os.path.join(user_credential, r'DB\\filejson\\ramcoot_full.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab1aee0d-54e8-46d2-90bf-d55a28e00126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT SCHEDULE\n",
    "schedule = pd.read_json(os.path.join(user_credential, r'DB\\filejson\\schedule_full.json'))\n",
    "schedule['Date']=pd.to_datetime(schedule['Date']).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "948f082a-2766-4f51-a409-43b873183d92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#IMPORT CUIC\n",
    "cuic = pd.read_json(os.path.join(user_credential, r'DB\\filejson\\cuic_full.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6f12ca0-a388-4e30-9183-1b318dcbbc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORT CPI\n",
    "cpi = pd.read_json(os.path.join(user_credential, r'DB\\filejson\\cpi_full.json'))\n",
    "cpi_daily=cpi[['Staff Name', 'Employee_ID', 'Date', 'Channel', 'Number of Records']]\n",
    "\n",
    "channel_list = ['phone','email','messaging','Live Chat']\n",
    "for i in channel_list:\n",
    "    cpi_daily[i] = cpi_daily.apply(lambda x: x['Number of Records'] if x['Channel'] == i else 0, axis=1)\n",
    "cpi_daily['Other channels Cases #'] = cpi_daily.apply(lambda x: x['Number of Records'] if x['Channel'] not in channel_list else 0, axis=1)\n",
    "\n",
    "non_phone_channel_list=['email','message','Live Chat']\n",
    "cpi_daily['Non-phone Cases #']= cpi_daily.apply(lambda x: x['Number of Records'] if x['Channel'] in non_phone_channel_list else 0, axis=1)\n",
    "\n",
    "cpi_daily=cpi_daily.rename(columns={'Number of Records':'Cases #',\n",
    "                                   'phone':'Phone Cases #',\n",
    "                                   'email':'Email Cases #',\n",
    "                                   'messaging':'Messaging Cases #',\n",
    "                                   'Live Chat':'Live Chat Cases #'})\n",
    "cpi_daily=cpi_daily.drop(columns=['Staff Name','Channel'])\n",
    "cpi_daily['Date']=pd.to_datetime(cpi_daily['Date'],format='mixed').dt.date\n",
    "cpi_daily=cpi_daily.groupby(['Employee_ID','Date'], as_index=False).sum()\n",
    "cpi_daily['Employee_ID'] = cpi_daily['Employee_ID'].astype(\"Int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2aa144ad-6215-4c85-8b10-288f5e0beece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT TL\n",
    "tl = pd.read_json(os.path.join(user_credential, r'DB\\filejson\\tl.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e5c8dd2-3ef7-4d30-82d9-3cb44321f1ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_20908\\2637013935.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  exception_daily['Exception request \\n(Minute)'] = exception_daily['Exception request \\n(Minute)'].astype(\"float\")\n",
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_20908\\2637013935.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  exception_daily['Exception request \\n(Minute)']=exception['Exception request \\n(Minute)'].fillna(0)\n"
     ]
    }
   ],
   "source": [
    "# IMPORT EXCEPTION\n",
    "exception = pd.read_json(os.path.join(user_credential, r'DB\\filejson\\exceptional_hrs.json'))\n",
    "exception['Date']=pd.to_datetime(exception['Date'],format='mixed').dt.date\n",
    "exception_daily=exception[['Emp ID','Date','Exception request \\n(Minute)']]\n",
    "exception_daily['Exception request \\n(Minute)'] = exception_daily['Exception request \\n(Minute)'].astype(\"float\")\n",
    "exception_daily['Exception request \\n(Minute)']=exception['Exception request \\n(Minute)'].fillna(0)\n",
    "exception_daily=exception_daily.rename(columns={'Exception request \\n(Minute)':'Exception request Hours'})\n",
    "exception_daily=exception_daily.groupby(['Emp ID','Date'], as_index=False).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae4091d7-c48d-44ba-9d0e-99ba635b840a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#IMPORT EPS\n",
    "eps_raw = import_csv(path = eps_path)\n",
    "eps = eps_raw.drop(columns=['Index', 'filename', 'Date'])\n",
    "eps['Session Login'] = pd.to_datetime(eps['Session Login'], errors='coerce')\n",
    "eps['Session Login'] = eps['Session Login'].dt.tz_localize('Europe/Berlin', ambiguous=True).dt.tz_convert('UTC')\n",
    "eps['Session Logout'] = pd.to_datetime(eps['Session Logout'], errors='coerce')\n",
    "eps['Session Logout'] = eps['Session Logout'].dt.tz_localize('Europe/Berlin', ambiguous=True).dt.tz_convert('UTC')\n",
    "eps['Session Login'] =pd.to_datetime(eps['Session Login'], errors='coerce').dt.tz_localize(None)\n",
    "eps['Session Logout'] =pd.to_datetime(eps['Session Logout'], errors='coerce').dt.tz_localize(None)\n",
    "\n",
    "eps['Session login VN'] = pd.to_datetime(eps['Session Login'], format ='mixed') + pd.Timedelta(hours=7)\n",
    "eps['Session logout VN'] = pd.to_datetime(eps['Session Logout'], format ='mixed') + pd.Timedelta(hours=7)\n",
    "eps['Session login date'] = pd.to_datetime(eps['Session login VN'], format ='mixed').dt.date\n",
    "eps['Session login time'] = pd.to_datetime(eps['Session login VN'], format ='mixed').dt.time\n",
    "eps['Session login hour'] = pd.to_datetime(eps['Session login VN'], format ='mixed').dt.strftime('%H')\n",
    "eps['Session logout date'] = pd.to_datetime(eps['Session logout VN'], format ='mixed').dt.date\n",
    "eps['Session logout time'] = pd.to_datetime(eps['Session logout VN'], format ='mixed').dt.time\n",
    "eps['Session logout hour'] = pd.to_datetime(eps['Session logout VN'], format ='mixed').dt.strftime('%H')\n",
    "eps['Session login hour']=eps['Session login hour'].astype(\"Int64\")\n",
    "eps['Session logout hour']=eps['Session logout hour'].astype(\"Int64\")\n",
    "nighthour_23h=\"23:00:00\"\n",
    "nighthour_7h=\"07:00:00\"\n",
    "nighthour_24h=\"00:00:00\"\n",
    "eps['Session login 23h'] = pd.to_datetime(eps['Session login date'].astype(str) + nighthour_23h, format = '%Y-%m-%d%H:%M:%S', errors='coerce')\n",
    "eps['Session logout 23h'] = pd.to_datetime(eps['Session logout date'].astype(str) + nighthour_23h, format = '%Y-%m-%d%H:%M:%S', errors='coerce')\n",
    "eps['Session login 7h'] = pd.to_datetime(eps['Session login date'].astype(str) + nighthour_7h, format = '%Y-%m-%d%H:%M:%S', errors='coerce')\n",
    "eps['Session logout 7h'] = pd.to_datetime(eps['Session logout date'].astype(str) + nighthour_7h, format = '%Y-%m-%d%H:%M:%S', errors='coerce')\n",
    "eps['Session login 24h'] = pd.to_datetime(eps['Session login date'].astype(str) + nighthour_24h, format = '%Y-%m-%d%H:%M:%S', errors='coerce')+pd.Timedelta(days=1)\n",
    "eps['Session logout 24h'] = pd.to_datetime(eps['Session logout date'].astype(str) + nighthour_24h, format = '%Y-%m-%d%H:%M:%S', errors='coerce')+pd.Timedelta(days=0)\n",
    "eps=eps[eps['EID'].isnull() == False]\n",
    "def night_func(x):\n",
    "    if (x['Session login hour']>=23 and x['Session logout hour']>=23) or (x['Session login hour']>=23 and x['Session logout hour']<7) or (x['Session login hour']<7 and x['Session logout hour']<7):\n",
    "        return x['Total Time']\n",
    "    elif x['Session login hour']>=23 and x['Session logout hour']>=7:\n",
    "        if ((x['Session login 24h']-x['Session login VN'])+pd.Timedelta(hours=7)).total_seconds()<x['Total Time']:\n",
    "            return ((x['Session login 24h']-x['Session login VN'])+pd.Timedelta(hours=7)).total_seconds()\n",
    "        else :\n",
    "            return x['Total Time']\n",
    "    elif x['Session login hour']<7 and x['Session logout hour']>=7 and x['Session logout hour']<23:\n",
    "        if (x['Session login 7h']-x['Session login VN']).total_seconds()<x['Total Time']:\n",
    "            return (x['Session login 7h']-x['Session login VN']).total_seconds()\n",
    "        else :\n",
    "            return x['Total Time']\n",
    "    elif x['Session login hour']<7 and x['Session logout hour']>=23:\n",
    "        if ((x['Session login 7h']-x['Session login VN'])+(x['Session logout VN']-x['Session logout 23h'])).total_seconds()<x['Total Time']:\n",
    "            return ((x['Session login 7h']-x['Session login VN'])+(x['Session logout VN']-x['Session logout 23h'])).total_seconds()\n",
    "        else :\n",
    "            return x['Total Time']\n",
    "    elif x['Session login hour']<23 and x['Session logout hour']>=23:\n",
    "        if (x['Session logout VN']-x['Session logout 23h']).total_seconds()<x['Total Time']:\n",
    "            return (x['Session logout VN']-x['Session logout 23h']).total_seconds()\n",
    "        else :\n",
    "            return x['Total Time']\n",
    "    elif x['Session login hour']<23 and x['Session logout hour']<7:\n",
    "        if (x['Session logout VN']-x['Session login 23h']).total_seconds()<x['Total Time']:\n",
    "            return (x['Session logout VN']-x['Session login 23h']).total_seconds()\n",
    "        else :\n",
    "            return x['Total Time']\n",
    "    else:\n",
    "        return (x['Session login VN']-x['Session login VN']).total_seconds()\n",
    "eps['night']= eps.apply(night_func, axis=1)\n",
    "\n",
    "eps = eps.drop(columns=['Session login VN', 'Session logout VN', 'Username', 'manager_username', 'sitecode', 'Session Time',\n",
    "                        'Session login hour','Session logout hour','Session login 23h','Session login 7h','Session login 24h'\n",
    "                       ,'Session logout 23h','Session logout 7h','Session logout 24h'])\n",
    "eps['EID']=eps['EID'].astype(\"Int64\")\n",
    "# 1. Merge EPS and Schedule on EID and Date to get Shift_type, Shift, Session Date and Duration and change Date into VN Date\n",
    "eps_schedule=pd.merge(eps, schedule, left_on=['EID','Session login date'], right_on=['Emp ID','Date'], how='left')\n",
    "eps_schedule=eps_schedule[['EID','Session Login','Session Logout','BPE Code','Total Time','Session login date','Session login time',\n",
    "                           'Session logout date','Session logout time','LOB','Shift_type','Shift','night']]\n",
    "eps_schedule['Date-1']=pd.to_datetime(eps_schedule['Session login date'], format ='mixed') - pd.Timedelta(1,\"d\")\n",
    "eps_schedule['Date-1']=pd.to_datetime(eps_schedule['Date-1'], format ='mixed').dt.date\n",
    "eps_schedule = pd.merge(eps_schedule, schedule, left_on=['EID','Date-1'], right_on =['Emp ID','Date'], how='left')\n",
    "mytime=t(12,0,0)\n",
    "condition=(eps_schedule['Shift_type_x']!='DS')&(eps_schedule['Shift_type_y']=='NS')&(eps_schedule['Session login time']<mytime)\n",
    "eps_schedule=eps_schedule.rename(columns={'LOB_x': 'LOB','Shift_type_x':'Shift_type','Shift_x':'Shift'})\n",
    "eps_schedule['Session Date'] = np.where(condition, eps_schedule['Date-1'], eps_schedule['Session login date'])\n",
    "eps_schedule['Duration']=eps_schedule['Total Time']/3600\n",
    "eps_schedule['night']=eps_schedule['night']/3600\n",
    "eps_schedule=eps_schedule[['EID','Session Login','Session Logout','BPE Code','Total Time','Session login date','Session login time',\n",
    "                           'Session logout date','Session logout time','LOB','Session Date','Duration','night']]\n",
    "eps_schedule = pd.merge(eps_schedule, schedule, left_on=['EID','Session Date'], right_on =['Emp ID','Date'], how='left')\n",
    "eps_schedule=eps_schedule.rename(columns={'LOB_y': 'LOB'})\n",
    "eps_schedule=eps_schedule[['EID','Session Login','Session Logout','BPE Code','Total Time','Session login date','Session login time',\n",
    "                           'Session logout date','Session logout time','LOB','Shift_type','Session Date','Duration','Shift','night']]\n",
    "\n",
    "# 2. Add Week & Day Name and BPE Code Duration and then group by EID, Session Date\n",
    "eps_dailytracking=eps_schedule\n",
    "eps_dailytracking['Session Date'] = pd.to_datetime(eps_dailytracking['Session Date'],errors ='coerce')\n",
    "# Add Week & Day Name column\n",
    "eps_dailytracking['Week'] = eps_dailytracking['Session Date'].dt.strftime('%Y%W')\n",
    "eps_dailytracking['Day Name'] = eps_dailytracking['Session Date'].dt.day_name()\n",
    "\n",
    "# Add Picklist,Ready or Talking,..BPE Code\n",
    "bpe_code=['Picklist - off Phone','Ready or Talking','Finalize Call','Meeting','Training','New Hire Training','Lunch',\n",
    "          'Break','RONA','Unscheduled Picklist','Payment Processing','Social Media','Mass Issue','Project']\n",
    "for i in bpe_code:\n",
    "    eps_dailytracking[i] = eps_dailytracking.apply(lambda x: x['Duration'] if x['BPE Code'] == i else 0, axis=1)\n",
    "eps_dailytracking['Other codes'] = eps_dailytracking.apply(lambda x: x['Duration'] if x['BPE Code'] not in bpe_code else 0, axis=1)\n",
    "\n",
    "night_bpe_code=['Picklist - off Phone','Ready or Talking','Finalize Call','Meeting','Training']\n",
    "for i in night_bpe_code:\n",
    "    eps_dailytracking['Night '+i] = eps_dailytracking.apply(lambda x: x['night'] if x['BPE Code'] == i else 0, axis=1)\n",
    "\n",
    "eps_dailytracking['Night Productive Hours']=eps_dailytracking['Night Picklist - off Phone']+eps_dailytracking['Night Ready or Talking']+eps_dailytracking['Night Finalize Call']\n",
    "eps_dailytracking['Night Downtime Hours']=eps_dailytracking['Night Training']+eps_dailytracking['Night Meeting']\n",
    "eps_dailytracking=eps_dailytracking.drop(columns=['Session Login','Session Logout','BPE Code','Total Time','Session login date',\n",
    "                                                  'Session login time','Session logout date','Session logout time','night'])\n",
    "eps_dailytracking=eps_dailytracking.groupby(['EID','LOB','Shift_type','Session Date','Shift','Week','Day Name'], as_index=False).sum()\n",
    "eps_dailytracking['Session Date']=pd.to_datetime(eps_dailytracking['Session Date'],format='mixed').dt.date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57cfa0b9-130f-45db-8143-8237cb2e12b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Login_Logout Time\n",
    "login_logout=eps_schedule[['EID','Session Date','Shift_type','Session login time','Session logout time']]\n",
    "\n",
    "# Login_Logout Time: filter !=NS\n",
    "login_logout_ds=login_logout.loc[(login_logout['Shift_type'] !='NS')]\n",
    "login_logout_ds=login_logout_ds.groupby(['EID','Session Date','Shift_type'], as_index=False).agg(min=('Session login time', 'min'), max=('Session logout time', 'max'))\n",
    "login_logout_ds=login_logout_ds.rename(columns={'min':'Login Time','max':'Logout Time'})\n",
    "\n",
    "# Login_Logout Time: filter NS (condition: login sau 15h & logout >15h)\n",
    "validate_time=t(15,0,0)\n",
    "login_ns=login_logout.loc[(login_logout['Shift_type'] =='NS')&(login_logout['Session login time'] > validate_time)]\n",
    "login_ns=login_ns.groupby(['EID','Session Date','Shift_type'], as_index=False).agg(min=('Session login time', 'min'))\n",
    "logout_ns=login_logout.loc[(login_logout['Shift_type'] =='NS')&(login_logout['Session logout time'] < validate_time)]\n",
    "logout_ns=logout_ns.groupby(['EID','Session Date','Shift_type'], as_index=False).agg(max=('Session logout time', 'max'))\n",
    "login_logout_ns=pd.merge(login_ns,logout_ns,left_on=['EID','Session Date','Shift_type'],right_on=['EID','Session Date','Shift_type'],how='left')\n",
    "login_logout_ns=login_logout_ns.rename(columns={'min':'Login Time','max':'Logout Time'})\n",
    "\n",
    "# Login_Logout Time:Combine DS & NS login logout time\n",
    "login_logout=pd.concat([login_logout_ds, login_logout_ns], ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98ac5314-490c-4fa7-972e-9aa7472b8a0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Daily tracking\n",
    "# Merge CPI to get Case #\n",
    "dailytracking=pd.merge(eps_dailytracking,cpi_daily,left_on=['EID','Session Date'],right_on=['Employee_ID','Date'],how='left')\n",
    "dailytracking=dailytracking.drop(columns=['Employee_ID','Date'])\n",
    "\n",
    "# Merge Exception to get Exception minute\n",
    "dailytracking=pd.merge(dailytracking,exception_daily,left_on=['EID','Session Date'],right_on=['Emp ID','Date'],how='left')\n",
    "dailytracking=dailytracking.drop(columns=['Emp ID','Date'])\n",
    "\n",
    "# Merge Ramco & OT to get Ramco, OT, OT Registered\n",
    "dailytracking=pd.merge(dailytracking,ramco_ot_daily,left_on=['EID','Session Date'],right_on=['EID','Date'],how='left')\n",
    "dailytracking=dailytracking.drop(columns=['Date'])\n",
    "\n",
    "# Merge Master Roster to get Full name, Booking Login ID, TED Name, Wave #, Employee_ID\n",
    "dailytracking=pd.merge(dailytracking,masterroster_daily,left_on=['EID'],right_on=['Employee_ID'],how='left')\n",
    "dailytracking=dailytracking.drop(columns=['Employee_ID'])\n",
    "\n",
    "# Merge TL to get Supervisor\n",
    "dailytracking=pd.merge(dailytracking,tl,left_on=['EID'],right_on=['Emp ID'],how='left')\n",
    "dailytracking=dailytracking.drop(columns=['Emp ID'])\n",
    "\n",
    "# Merge Login Logout Time\n",
    "login_logout['Session Date']=pd.to_datetime(login_logout['Session Date']).dt.date\n",
    "dailytracking=pd.merge(dailytracking,login_logout,left_on=['EID','Session Date','Shift_type'],right_on=['EID','Session Date','Shift_type'],how='left')\n",
    "\n",
    "dailytracking['Cases #']=dailytracking['Cases #'].fillna(0)\n",
    "dailytracking['Phone Cases #']=dailytracking['Phone Cases #'].fillna(0)\n",
    "dailytracking['Non-phone Cases #']=dailytracking['Non-phone Cases #'].fillna(0)\n",
    "dailytracking['RAMCO']=dailytracking['RAMCO'].fillna(0)\n",
    "dailytracking['OT']=dailytracking['OT'].fillna(0)\n",
    "dailytracking['Exception request Hours']=dailytracking['Exception request Hours']/60\n",
    "dailytracking['Exception request Hours']=dailytracking['Exception request Hours'].fillna(0)\n",
    "\n",
    "#Productive Hours including: Picklist - off Phone + Ready or Talking + Finalize Call\n",
    "dailytracking['Productive hours']=dailytracking['Picklist - off Phone']+dailytracking['Ready or Talking']+dailytracking['Finalize Call']\n",
    "#Downtime Hours including: Meeting + Training\n",
    "dailytracking['Downtime Hours']=dailytracking['Meeting']+dailytracking['Training']\n",
    "#Delivery Hours including: Productive Hours + Downtime Hours + New Hire Training\n",
    "dailytracking['Delivery hours']=dailytracking['Productive hours']+dailytracking['Downtime Hours']+dailytracking['New Hire Training']\n",
    "dailytracking=dailytracking.rename(columns={'Duration':'Staffed Hours'})\n",
    "#CPH = sum(Cases #)/sum(Ready or Talking','Picklist - off Phone','Finalize Call',\n",
    "#RONA,'Unscheduled Picklist','Payment Processing','Social Media','Mass Issue','Project')\n",
    "dailytracking['CPH - Agent']=dailytracking['Cases #']/(dailytracking['Ready or Talking']+dailytracking['Picklist - off Phone']+\n",
    "                                                        dailytracking['Finalize Call']+dailytracking['RONA']+\n",
    "                                                        dailytracking['Unscheduled Picklist']+dailytracking['Payment Processing']+\n",
    "                                                        dailytracking['Social Media']+ dailytracking['Mass Issue']+\n",
    "                                                        dailytracking['Project'])\n",
    "def standardtime_func(x):\n",
    "    if x['RAMCO'] =='PR' or x['RAMCO'] =='PH' :\n",
    "        return x['OT']+8\n",
    "    elif x['RAMCO'] =='PO':\n",
    "        return x['OT']\n",
    "    else:\n",
    "        return 0\n",
    "dailytracking['Standard time']= dailytracking.apply(standardtime_func, axis=1)\n",
    "dailytracking['Extra rendered hours']=(dailytracking['Delivery hours']+dailytracking['Break']+(dailytracking['Exception request Hours']/(60*24)))-dailytracking['Standard time']\n",
    "def approvedovertime_func(x):\n",
    "    if x['OT']<=0:\n",
    "        return 0\n",
    "    elif x['RAMCO'] not in ['PR','PO','PH']:\n",
    "        return 0\n",
    "    elif x['Extra rendered hours'] >= 0:\n",
    "        return  x['OT']\n",
    "    elif (x['OT']+x['Extra rendered hours']-0.25) < 0 :\n",
    "        return  0\n",
    "    else:         \n",
    "        return x['OT']+x['Extra rendered hours']-0.25\n",
    "dailytracking['Approved Overtime']= dailytracking.apply(approvedovertime_func, axis=1)\n",
    "dailytracking['Approved Overtime']=dailytracking['Approved Overtime'].round(0)\n",
    "dailytracking['Day Productive Hours']=dailytracking['Productive hours']-dailytracking['Night Productive Hours']\n",
    "dailytracking['Day Downtime Hours']=dailytracking['Downtime Hours']-dailytracking['Night Downtime Hours']\n",
    "dailytracking['Session Date'] = pd.to_datetime(dailytracking['Session Date'])\n",
    "dailytracking=dailytracking.sort_values(by='Session Date',ascending=True)\n",
    "#ATD MM\n",
    "def atdmm_shift_func(x):\n",
    "    if x['Shift'] in ['0400-1300','0500-1400','0600-1500','0700-1600','0800-1700','0900-1800','1000-1900','1100-2000',\n",
    "                      '1200-2100','1300-2200','1400-2300','1500-2400','1600-0100','1700-0200',\n",
    "                      '1800-0300','1900-0400','2000-0500','2100-0600','2200-0700','HAL','Training','PEGA']:\n",
    "        return 'WORK'\n",
    "    else:         \n",
    "        return 'OFF'\n",
    "dailytracking['ATD MM Shift']= dailytracking.apply(atdmm_shift_func, axis=1)\n",
    "def atdmm_ramco_func(x):\n",
    "    if x['RAMCO'] in ['PH','PO','PR','PI','POWH','HAL','HLWP','HSL']:\n",
    "        return 'WORK'\n",
    "    else:         \n",
    "        return 'OFF'\n",
    "dailytracking['ATD MM Ramco']= dailytracking.apply(atdmm_ramco_func, axis=1)\n",
    "def atdmm_func(x):\n",
    "    if x['EID'] =='':\n",
    "        return ''\n",
    "    elif x['RAMCO']=='PO' and x['Shift']=='OFF':\n",
    "        return 'Valid'   \n",
    "    elif x['RAMCO']=='' and x['Shift']!='':\n",
    "        return '' \n",
    "    elif x['RAMCO']!='' and x['Shift']=='':\n",
    "        return ''     \n",
    "    elif x['RAMCO']=='' and x['Shift']=='':\n",
    "        return 'Valid'  \n",
    "    elif x['RAMCO']=='AB' and x['ATD MM Shift']=='WORK':\n",
    "        return 'Valid' \n",
    "    elif x['ATD MM Ramco'] == x['ATD MM Shift']:\n",
    "        return 'Valid' \n",
    "    else:         \n",
    "        return 'ATD MM'\n",
    "dailytracking['ATD MM']= dailytracking.apply(atdmm_func, axis=1)\n",
    "#PO (MTD)\n",
    "def po_func(x):\n",
    "    if x['RAMCO'] in ['PO']:\n",
    "        return 1\n",
    "    else:         \n",
    "        return 0\n",
    "dailytracking['PO']= dailytracking.apply(po_func, axis=1)\n",
    "dailytracking['Session Date'] = pd.to_datetime(dailytracking['Session Date'])\n",
    "dailytracking['#PO (MTD)'] = dailytracking.groupby([dailytracking['Session Date'].dt.to_period('m'),'EID'])['PO'].cumsum()\n",
    "#POHrs (MTD)\n",
    "def pohour_func(x):\n",
    "    if x['RAMCO'] in ['PO']:\n",
    "        return x['Approved Overtime']\n",
    "    else:         \n",
    "        return 0\n",
    "dailytracking['PO Hour']= dailytracking.apply(pohour_func, axis=1)\n",
    "dailytracking['POHrs(MTD)'] = dailytracking.groupby([dailytracking['Session Date'].dt.to_period('m'),'EID'])['PO Hour'].cumsum()\n",
    "#OT (MTD)\n",
    "dailytracking['OT (MTD)'] = dailytracking.groupby([dailytracking['Session Date'].dt.to_period('m'),'EID'])['Approved Overtime'].cumsum()\n",
    "# Final OT\n",
    "def finalOT_func(x):\n",
    "    if x['OT (MTD)'] <= 40 :\n",
    "        return x['Approved Overtime']\n",
    "    else:         \n",
    "        return 0\n",
    "dailytracking['Final OT']= dailytracking.apply(finalOT_func, axis=1)\n",
    "#OT OTP\n",
    "def OT_OTP_func(x):\n",
    "    if x['OT (MTD)'] > 40 :\n",
    "        return x['Approved Overtime']\n",
    "    else:         \n",
    "        return 0\n",
    "dailytracking['OT OTP']= dailytracking.apply(OT_OTP_func, axis=1)\n",
    "#OT-LessDelivery\n",
    "def OT_LessDelivery_func(x):\n",
    "    if x['Approved Overtime'] > x['OT'] :\n",
    "        return 1\n",
    "    else:         \n",
    "        return 0\n",
    "dailytracking['OT-LessDelivery']= dailytracking.apply(OT_LessDelivery_func, axis=1)\n",
    "#OT>4Hrs On PR & OT>8Hrs On PO\n",
    "def OT_on_PO_func(x):\n",
    "    if x['RAMCO'] =='PR' and x['Approved Overtime']>4 :\n",
    "        return 1\n",
    "    elif x['RAMCO'] =='PO' and x['Approved Overtime']>8 :\n",
    "        return 1 \n",
    "    else:         \n",
    "        return 0\n",
    "dailytracking['OT>4Hrs On PR \\n OT>8Hrs On PO']= dailytracking.apply(OT_on_PO_func, axis=1)\n",
    "#PR<8.75\n",
    "def PR_func(x):\n",
    "    if (x['Staffed Hours'] + x['Exception request Hours'])<8.75 :\n",
    "        return 1\n",
    "    else:         \n",
    "        return 0\n",
    "dailytracking['PR < 8.75']= dailytracking.apply(PR_func, axis=1)\n",
    "#PR (MTD)\n",
    "def PRMTD_func(x):\n",
    "    if x['EID']=='' :\n",
    "        return 0\n",
    "    else:         \n",
    "        return 1\n",
    "dailytracking['PR count']= dailytracking.apply(PRMTD_func, axis=1)\n",
    "dailytracking['PR (MTD)'] = dailytracking.groupby([dailytracking['Session Date'].dt.to_period('m'),'EID'])['PR count'].cumsum()\n",
    "#Low PerF\n",
    "def LowPerF_func(x):\n",
    "    if x['CPH - Agent']<2 :\n",
    "        return 1\n",
    "    else:         \n",
    "        return 0\n",
    "dailytracking['Low PerF']= dailytracking.apply(LowPerF_func, axis=1)\n",
    "#Login On Dayoff\n",
    "def LoginonDayoff_func(x):\n",
    "    if x['ATD MM Shift'] =='OFF' and x['ATD MM Ramco']=='OFF' and x['Staffed Hours']>0:\n",
    "        return 1\n",
    "    else:         \n",
    "        return 0\n",
    "dailytracking['Login on Dayoff']= dailytracking.apply(LoginonDayoff_func, axis=1)\n",
    "\n",
    "#Not Logout\n",
    "import re\n",
    "def split1_it(startshift):\n",
    "    return re.findall('(\\d{4})-', startshift)\n",
    "dailytracking['Shift1'] = dailytracking['Shift'].apply(split1_it)\n",
    "dailytracking['Shift1']=dailytracking['Shift1'].astype(str)\n",
    "dailytracking['Shift1'] = dailytracking['Shift1'] .str.replace(\"['\", \"\")\n",
    "dailytracking['Shift1'] =dailytracking['Shift1'] .str.replace(\"']\", \"\")\n",
    "dailytracking['Shift1'] =dailytracking['Shift1'] .str.replace(\"00\", \"\")\n",
    "dailytracking['Shift1'] =dailytracking['Shift1'] .str.replace(\"[]\", '')\n",
    "def split_it(endshift):\n",
    "    return re.findall('\\d{4}-(\\d{4})', endshift)\n",
    "dailytracking['Shift2'] = dailytracking['Shift'].apply(split_it)\n",
    "dailytracking['Shift2']=dailytracking['Shift2'].astype(str)\n",
    "dailytracking['Shift2'] = dailytracking['Shift2'] .str.replace(\"['\", \"\")\n",
    "dailytracking['Shift2'] =dailytracking['Shift2'] .str.replace(\"']\", \"\")\n",
    "dailytracking['Shift2'] =dailytracking['Shift2'] .str.replace(\"00\", \"\")\n",
    "dailytracking['Shift2'] =dailytracking['Shift2'] .str.replace(\"[]\", '')\n",
    "def shift1_func(x):\n",
    "    if x['Shift1'] =='':\n",
    "        return 0\n",
    "    else:         \n",
    "        return x['Shift1']\n",
    "dailytracking['Shift1']= dailytracking.apply(shift1_func, axis=1)\n",
    "dailytracking['Shift1']=dailytracking['Shift1'].astype('Float64')\n",
    "dailytracking['Shift1']=dailytracking['Shift1'].astype('Int64')\n",
    "def shift2_func(x):\n",
    "    if x['Shift2'] =='':\n",
    "        return 0\n",
    "    else:         \n",
    "        return x['Shift2']\n",
    "dailytracking['Shift2']= dailytracking.apply(shift2_func, axis=1)\n",
    "dailytracking['Shift2']=dailytracking['Shift2'].astype('Float64')\n",
    "dailytracking['Shift2']=dailytracking['Shift2'].astype('Int64')\n",
    "def time1_func(x):\n",
    "    if x['Shift1'] =='':\n",
    "        return t(0,0,0)\n",
    "    elif x['Shift1'] ==24:\n",
    "        return t(23,59,59)\n",
    "    else:         \n",
    "        return t(x['Shift1'],0,0)\n",
    "dailytracking['Time1']= dailytracking.apply(time1_func, axis=1)\n",
    "def time_func(x):\n",
    "    if x['Shift2'] =='':\n",
    "        return t(0,0,0)\n",
    "    elif x['Shift2'] ==24:\n",
    "        return t(23,59,59)\n",
    "    else:         \n",
    "        return t(x['Shift2'],0,0)\n",
    "dailytracking['Time2']= dailytracking.apply(time_func, axis=1)\n",
    "dailytracking['Time1'] = pd.to_datetime(dailytracking['Time1'], format='%H:%M:%S', errors='coerce').dt.time\n",
    "dailytracking['Time2'] = pd.to_datetime(dailytracking['Time2'], format='%H:%M:%S', errors='coerce').dt.time\n",
    "def nightshift_func(x):\n",
    "    if x['Shift_type'] ==\"OFF\":\n",
    "        return x['Session Date']\n",
    "    elif x['Shift2'] < 12:\n",
    "        return x['Session Date']+ pd.Timedelta(days=1)\n",
    "    else:         \n",
    "        return x['Session Date']\n",
    "dailytracking['Date']= dailytracking.apply(nightshift_func, axis=1) \n",
    "dailytracking['datetime1'] = pd.to_datetime(dailytracking['Session Date'].astype(str) + dailytracking['Time1'].astype(str), format = '%Y-%m-%d%H:%M:%S')\n",
    "dailytracking['datetime2'] = pd.to_datetime(dailytracking['Date'].astype(str) + dailytracking['Time2'].astype(str), format = '%Y-%m-%d%H:%M:%S')\n",
    "dailytracking['Approved Overtime1']=dailytracking['Approved Overtime'].astype('Float64')\n",
    "dailytracking['Approved Overtime1']=dailytracking['Approved Overtime1'].apply(np.ceil)\n",
    "dailytracking['datetime2'] = pd.to_datetime(dailytracking['datetime2'])\n",
    "dailytracking['Approved Overtime1'] = pd.to_timedelta(dailytracking['Approved Overtime1'],'h')\n",
    "dailytracking['datetime2'] = dailytracking['datetime2']+dailytracking['Approved Overtime1']\n",
    "dailytracking['datetime2'] = dailytracking['datetime2']+ pd.Timedelta(minutes=5)\n",
    "dailytracking['datetime1'] = pd.to_datetime(dailytracking['datetime1'])+ pd.Timedelta(minutes=5)\n",
    "dailytracking['Logout Time']=dailytracking['Logout Time'].fillna(0)\n",
    "dailytracking['datetime_logout'] = pd.to_datetime(dailytracking['Date'].astype(str) + dailytracking['Logout Time'].astype(str), format = '%Y-%m-%d%H:%M:%S', errors='coerce')\n",
    "dailytracking['Login Time']=dailytracking['Login Time'].fillna(0)\n",
    "dailytracking['datetime_login'] = pd.to_datetime(dailytracking['Session Date'].astype(str) + dailytracking['Login Time'].astype(str), format = '%Y-%m-%d%H:%M:%S', errors='coerce')\n",
    "def notlogout_func(x):\n",
    "    if x['Shift'] in {'AL','OFF','Training','HAL','CO','UPL'}:\n",
    "        return \"\"\n",
    "    elif x['datetime_logout'] > x['datetime2']:\n",
    "        return \"not logout after shift end\"       \n",
    "    else:         \n",
    "        return \"\"\n",
    "dailytracking['Not Logout']= dailytracking.apply(notlogout_func, axis=1)\n",
    "\n",
    "# Late-Soon Login Logout\n",
    "def late_func(x):\n",
    "    if x['Shift'] in {'AL','OFF','Training','HAL','CO','UPL'}:\n",
    "        return \"\"\n",
    "    elif x['datetime_login'] > x['datetime1']:\n",
    "        return \"Late\"       \n",
    "    else:         \n",
    "        return \"\"\n",
    "dailytracking['Late']= dailytracking.apply(late_func, axis=1)\n",
    "def soon_func(x):\n",
    "    if x['Shift'] in {'AL','OFF','Training','HAL','CO','UPL'}:\n",
    "        return \"\"\n",
    "    elif x['datetime_logout'] < x['datetime2']- pd.Timedelta(minutes=5):\n",
    "        return \"Soon\"       \n",
    "    else:         \n",
    "        return \"\"\n",
    "dailytracking['Soon']= dailytracking.apply(soon_func, axis=1)\n",
    "def latesoon_func(x):\n",
    "    if x['Late'] ==\"\" and x['Soon']==\"\":\n",
    "        return \"\"\n",
    "    elif x['Late']!=\"\" and x['Soon']==\"\":\n",
    "        return x['Late']       \n",
    "    elif x['Late']==\"\" and x['Soon']!=\"\":\n",
    "        return x['Soon']   \n",
    "    else:         \n",
    "        return x['Late']+'-'+x['Soon']\n",
    "dailytracking['Late-Soon']= dailytracking.apply(latesoon_func, axis=1)\n",
    "\n",
    "# Overconsecutive\n",
    "dailytracking= dailytracking.sort_values(by = ['EID', 'Session Date'])\n",
    "dailytracking['level_1']=(dailytracking['Session Date'] - dailytracking['Session Date'].shift(1)).astype('int64')/86400000000000 #to get the discrepancy between current and previous visible working day\n",
    "dailytracking['pre_ramco']=dailytracking['RAMCO'].shift(1)\n",
    "def level1_func(x):\n",
    "    if x['RAMCO'] in {'MTLX', 'MTLA', 'LWP', 'AL', 'AB', 'WO', 'SL', 'NM', 'MTL', 'CSLA', 'MOE', 'NCH', 'CSLB', 'PTL', 'PTL', 'PNL', 'CAL', 'HO', 'CDH', 'CO', 'CM', 'GM', 'MSL', 'VDH', 'MOC', 'CMLF'}:\n",
    "        return 2\n",
    "    elif x['level_1']==1 and x['pre_ramco'] in {'MTLX', 'MTLA', 'LWP', 'AL', 'AB', 'WO', 'SL', 'NM', 'MTL', 'CSLA', 'MOE', 'NCH', 'CSLB', 'PTL', 'PTL', 'PNL', 'CAL', 'HO', 'CDH', 'CO', 'CM', 'GM', 'MSL', 'VDH', 'MOC', 'CMLF'}:\n",
    "        return 2\n",
    "    else:         \n",
    "        return x['level_1']\n",
    "dailytracking['level_1']= dailytracking.apply(level1_func, axis=1)\n",
    "\n",
    "dailytracking['check_eid'] = (dailytracking['EID'] - dailytracking['EID'].shift(1))\n",
    "\n",
    "dailytracking[ 'level_2'] = ((dailytracking['level_1']!=1) | (dailytracking['check_eid'].isna()) | (dailytracking['check_eid']!=0)).cumsum()\n",
    "\n",
    "dailytracking['OverConsecutive'] = (\n",
    "    dailytracking[['level_2']]\n",
    "    .assign(OverConsecutive=1)\n",
    "    .groupby('level_2')['OverConsecutive']\n",
    "    .transform('cumsum')\n",
    ")\n",
    "dailytracking['OverConsecutive'] = dailytracking.apply(lambda x: 'OverConsecutive' if x['OverConsecutive'] > 6 else x['OverConsecutive'], axis=1)\n",
    "dailytracking['Staffed Hours']=dailytracking['Staffed Hours']\n",
    "\n",
    "limit_date = max(pd.to_datetime(dailytracking['Session Date'], format ='mixed')) - pd.Timedelta(days=1)\n",
    "dailytracking=dailytracking.loc[dailytracking['Session Date'] <= limit_date]\n",
    "\n",
    "dailytracking['Session Date'] = pd.to_datetime(dailytracking['Session Date'], format='mixed').dt.date\n",
    "dailytracking_raw = dailytracking.drop(columns=['ATD MM Shift','ATD MM Ramco','PO','PO Hour','PR count','level_1','pre_ramco','check_eid',\n",
    "                                            'level_2','Shift1','Shift2','Time1','Time2','Date','datetime1','datetime2','Approved Overtime1',\n",
    "                                            'datetime_logout','datetime_login','Late','Soon','CPH - Agent'])\n",
    "dailytracking_raw['Session Date'] = pd.to_datetime(dailytracking_raw['Session Date'], format='mixed').dt.date\n",
    "dailytracking_raw.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "dailytracking_raw=dailytracking_raw.drop(columns=['OT','PST_Start_Date','Role','Standard time','Extra rendered hours'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b79a146a-ffbe-4a6c-83d4-81346beaff1b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_20908\\330151357.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  eps_adherence['Actual Downtime Hours']=eps_adherence['Meeting']+eps_adherence['Training']\n",
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_20908\\330151357.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  eps_adherence['Session Date']=pd.to_datetime(eps_adherence['Session Date']).dt.date\n"
     ]
    }
   ],
   "source": [
    "# ADHERENCE\n",
    "workplan = pd.read_json(os.path.join(r'C:', user_credential, r'DB\\filejson\\workplan_merge_iex.json'))\n",
    "workplan=workplan[['Date','Agent ID','Scheduled Activity','Length','EID']]\n",
    "workplan['Date']=pd.to_datetime(workplan['Date']).dt.date\n",
    "workplan['EID']=workplan['EID'].astype(\"Int64\")\n",
    "\n",
    "workplan['Plotted Downtime Hours']=workplan.apply(lambda x: x['Length'] if x['Scheduled Activity'] in {'Coaching 1:1','Team Meeting'} else 0, axis=1)\n",
    "workplan['Plotted Phone Hours']=workplan.apply(lambda x: x['Length'] if x['Scheduled Activity']=='Open Time' else 0, axis=1)\n",
    "workplan['Plotted Picklist Hours']=workplan.apply(lambda x: x['Length'] if x['Scheduled Activity'] =='Email 1' else 0, axis=1)\n",
    "workplan['Plotted Lunch Hours']=workplan.apply(lambda x: x['Length'] if x['Scheduled Activity'] =='Lunch' else 0, axis=1)\n",
    "workplan['Plotted Break Hours']=workplan.apply(lambda x: x['Length'] if x['Scheduled Activity'] =='Break Offline' else 0, axis=1)\n",
    "\n",
    "workplan['Plotted Downtime Hours']=workplan['Plotted Downtime Hours']*24\n",
    "workplan['Plotted Phone Hours']=workplan['Plotted Phone Hours']*24\n",
    "workplan['Plotted Picklist Hours']=workplan['Plotted Picklist Hours']*24\n",
    "workplan['Plotted Lunch Hours']=workplan['Plotted Lunch Hours']*24\n",
    "workplan['Plotted Break Hours']=workplan['Plotted Break Hours']*24\n",
    "workplan=workplan.groupby(['Date','Agent ID','EID'], as_index=False).sum()\n",
    "workplan['Plotted Producted Hour']=workplan['Plotted Phone Hours']+workplan['Plotted Picklist Hours']\n",
    "\n",
    "eps_adherence=dailytracking[['Session Date','EID','Full name','Booking Login ID','LOB','Supervisor','Wave #',\n",
    "                                 'Picklist - off Phone','Ready or Talking','Meeting','Training','Lunch','Break']]\n",
    "eps_adherence['Actual Downtime Hours']=eps_adherence['Meeting']+eps_adherence['Training']\n",
    "eps_adherence['Session Date']=pd.to_datetime(eps_adherence['Session Date']).dt.date\n",
    "adherence=pd.merge(eps_adherence,workplan,left_on=['Session Date','EID'],right_on=['Date','EID'],how='left')\n",
    "adherence['Actual Producted Hour']=adherence['Picklist - off Phone']+adherence['Ready or Talking']\n",
    "adherence=adherence.rename(columns={'Agent ID':'IEX ID','Picklist - off Phone':'Actual Picklist Hours','Ready or Talking':'Actual Phone Hours',\n",
    "                                    'Lunch':'Actual Lunch Hours','Break':'Actual Break Hours'})\n",
    "adherence=adherence[['Session Date','EID','Full name','IEX ID','Booking Login ID','LOB','Supervisor','Wave #',\n",
    "                     'Plotted Downtime Hours','Actual Downtime Hours','Plotted Producted Hour','Actual Producted Hour',\n",
    "                     'Plotted Phone Hours','Actual Phone Hours','Plotted Picklist Hours','Actual Picklist Hours',\n",
    "                     'Plotted Lunch Hours','Actual Lunch Hours','Plotted Break Hours','Actual Break Hours']]\n",
    "def downtimedeliveryper(x):\n",
    "    if x['Plotted Downtime Hours']==0 and x['Actual Downtime Hours']!=0:\n",
    "        return 0\n",
    "    elif x['Plotted Downtime Hours']==0 and x['Actual Downtime Hours']==0:\n",
    "        return 1\n",
    "    else:         \n",
    "        return x['Actual Downtime Hours']/x['Plotted Downtime Hours']\n",
    "adherence['%Downtime Delivery']= adherence.apply(downtimedeliveryper, axis=1)\n",
    "\n",
    "def producteddeliveryper(x):\n",
    "    if x['Plotted Producted Hour']==0 and x['Actual Producted Hour']!=0:\n",
    "        return 0\n",
    "    elif x['Plotted Producted Hour']==0 and x['Actual Producted Hour']==0:\n",
    "        return 1\n",
    "    else:         \n",
    "        return x['Actual Producted Hour']/x['Plotted Producted Hour']\n",
    "adherence['%Producted Delivery']= adherence.apply(producteddeliveryper, axis=1)\n",
    "adherence['Lunch variance']=(adherence['Actual Lunch Hours']-adherence['Plotted Lunch Hours'])/adherence['Plotted Lunch Hours']\n",
    "adherence['Break variance']=(adherence['Actual Break Hours']-adherence['Plotted Break Hours'])/adherence['Plotted Break Hours']\n",
    "adherence=adherence[['Session Date','EID','IEX ID',\n",
    "                     'Plotted Downtime Hours','Actual Downtime Hours','%Downtime Delivery','Plotted Producted Hour','Actual Producted Hour',\n",
    "                     '%Producted Delivery','Plotted Phone Hours','Actual Phone Hours','Plotted Picklist Hours','Actual Picklist Hours',\n",
    "                     'Plotted Lunch Hours','Actual Lunch Hours','Lunch variance','Plotted Break Hours','Actual Break Hours','Break variance']]\n",
    "adherence.replace([np.inf, -np.inf], 0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f40e6ea-3b20-4a9f-a98b-0dc2dcee8356",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "daily_adherence=pd.merge(dailytracking_raw,adherence,left_on=['Session Date','EID'],right_on=['Session Date','EID'],how='left')\n",
    "daily_adherence.to_csv(os.path.join(personal_path,r'Concentrix Corporation\\Tung Quan Le - BKN\\DailyTracking\\[BcomDB] Dailytracking.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
